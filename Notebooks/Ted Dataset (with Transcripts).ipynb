{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d473637-2043-4877-8a17-aa523a2cd5da",
   "metadata": {},
   "source": [
    "# What Makes A Good Speech?\n",
    "\n",
    "From csv ted_talks_en.csv\n",
    "\n",
    "URL:  https://www.kaggle.com/datasets/miguelcorraljr/ted-ultimate-dataset/data\n",
    "\n",
    "Columns = 'talk_id', 'title', 'speaker_1', 'all_speakers', 'occupations', 'about_speakers', 'views', 'recorded_date', 'published_date', 'event', 'native_lang', 'available_lang', 'comments', 'duration', 'topics', 'related_talks', 'url', 'description', 'transcript'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513cb8fb",
   "metadata": {},
   "source": [
    "Still Needed:\n",
    "- Intro\n",
    "- Data sets used\n",
    "- Data Dictionary\n",
    "\n",
    "\n",
    "Intro:\n",
    "# we have two csv files, one with the transcripts and one with the likes data.\n",
    "# we will import them both here and merge them into one dataframe\n",
    "transcript_df = pd.read_csv(\"TED Dataset #1 (n-4003) with Transcripts.csv\")\n",
    "likes_df = pd.read_csv(\"TED Dataset #2 (n=5701).csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104f497-45c5-4b81-89ac-02ca27bdc98e",
   "metadata": {},
   "source": [
    "# Next Steps:\n",
    "(as of January 23rd, 2023)\n",
    "\n",
    "- Clean up the notebook for maximum transparency of workflow\n",
    "- Reassess next steps based on feedback and re-assessment of options given the scope of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad451ab",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661dafc6",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "1. Merging the DataFrames\n",
    "2. Data Cleaning\n",
    "3. Initial EDA\n",
    "4. Feature Engineering (Vectorizing Text)\n",
    "5. Model Building & Determining the Features of Highest Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b312ef91-a5ed-49e1-bbdc-b8f2377076d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import text \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4316e",
   "metadata": {},
   "source": [
    "## 1. Merging the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3d8cf46-7001-4967-9ce6-123da80ec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two csv files, one with the transcripts and one with the likes data.\n",
    "# we will import them both here and merge them into one dataframe\n",
    "transcript_df = pd.read_csv(\"TED Dataset #1 (n-4003) with Transcripts.csv\")\n",
    "likes_df = pd.read_csv(\"TED Dataset #2 (n=5701).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dd55cd2-7e44-45ab-8958-9ca5292833af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options to display all columns and rows\n",
    "pd.options.display.max_rows = 5\n",
    "pd.options.display.max_columns = 30\n",
    "pd.options.display.max_colwidth = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88957fd8-ed49-4e4d-9b32-bf3261d1dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>views</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gor...</td>\n",
       "      <td>3523392</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', '...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>{243: 'New thinking on the...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>With the same humor and hu...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>{0: 'In Hans Rosling’s han...</td>\n",
       "      <td>14501685</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', '...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>{2056: \"Own your body's da...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>You've never seen data pre...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>{0: 'David Pogue'}</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>{0: 'David Pogue is the pe...</td>\n",
       "      <td>1920832</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'de', 'el', '...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainme...</td>\n",
       "      <td>{1725: '10 top time-saving...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>New York Times columnist D...</td>\n",
       "      <td>(Music: \"The Sound of Sile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                          title     speaker_1         all_speakers  \\\n",
       "0        1    Averting the climate crisis       Al Gore       {0: 'Al Gore'}   \n",
       "1       92  The best stats you've ever...  Hans Rosling  {0: 'Hans Rosling'}   \n",
       "2        7               Simplicity sells   David Pogue   {0: 'David Pogue'}   \n",
       "\n",
       "                     occupations                 about_speakers     views  \\\n",
       "0      {0: ['climate advocate']}  {0: 'Nobel Laureate Al Gor...   3523392   \n",
       "1  {0: ['global health expert...  {0: 'In Hans Rosling’s han...  14501685   \n",
       "2  {0: ['technology columnist']}  {0: 'David Pogue is the pe...   1920832   \n",
       "\n",
       "  recorded_date published_date    event native_lang  \\\n",
       "0    2006-02-25     2006-06-27  TED2006          en   \n",
       "1    2006-02-22     2006-06-27  TED2006          en   \n",
       "2    2006-02-24     2006-06-27  TED2006          en   \n",
       "\n",
       "                  available_lang  comments  duration  \\\n",
       "0  ['ar', 'bg', 'cs', 'de', '...     272.0       977   \n",
       "1  ['ar', 'az', 'bg', 'bn', '...     628.0      1190   \n",
       "2  ['ar', 'bg', 'de', 'el', '...     124.0      1286   \n",
       "\n",
       "                          topics                  related_talks  \\\n",
       "0  ['alternative energy', 'ca...  {243: 'New thinking on the...   \n",
       "1  ['Africa', 'Asia', 'Google...  {2056: \"Own your body's da...   \n",
       "2  ['computers', 'entertainme...  {1725: '10 top time-saving...   \n",
       "\n",
       "                             url                    description  \\\n",
       "0  https://www.ted.com/talks/...  With the same humor and hu...   \n",
       "1  https://www.ted.com/talks/...  You've never seen data pre...   \n",
       "2  https://www.ted.com/talks/...  New York Times columnist D...   \n",
       "\n",
       "                      transcript  \n",
       "0  Thank you so much, Chris. ...  \n",
       "1  About 10 years ago, I took...  \n",
       "2  (Music: \"The Sound of Sile...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first 3 rows of the transcript dataframe\n",
    "transcript_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92f1fc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>957</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1266</td>\n",
       "      <td>2012797</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>2006-02-26</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1096</td>\n",
       "      <td>3006315</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                        title        speaker recorded_date  \\\n",
       "0        1  Averting the climate crisis        Al Gore    2006-02-25   \n",
       "1        7             Simplicity sells    David Pogue    2006-02-24   \n",
       "2       53          Greening the ghetto  Majora Carter    2006-02-26   \n",
       "\n",
       "  published_date    event  duration    views   likes  \n",
       "0     2006-06-27  TED2006       957  3681537  110000  \n",
       "1     2006-06-27  TED2006      1266  2012797   60000  \n",
       "2     2006-06-27  TED2006      1096  3006315   90000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first 3 rows of the likes dataframe\n",
    "likes_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcea0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4005, 19)\n",
      "(5701, 9)\n"
     ]
    }
   ],
   "source": [
    "print(transcript_df.shape)\n",
    "print(likes_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bbedb",
   "metadata": {},
   "source": [
    "There are 4005 rows in the transcipts dataframe.  As this dataframe has the transcript data we wish to use, we will be limited to at least that number of samples after the merge.\n",
    "\n",
    "We will merge the dataframes to obtain [from the larger 'likes' dataframe] the likes and (updated) views columns. \n",
    "\n",
    "Lets investigate how many times each dataframe contains the same primary key to merge on - this will tell us how many rows of data we will actually have to work with after the merge.  \n",
    "\n",
    "#### Investigating how our data will look after merging:\n",
    "\n",
    "Calculating the matches of talk_id (our primary key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9223718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The talk_id's are not unique in both dataframes\n",
      "There are a total of: 3996 matching unique talk_id's in the likes dataframe.  This is how many rows we will have in our merged dataframe.\n",
      "There are a total of:  9 Missing in likes_df: {323, 45412, 2405, 2127, 3632, 2577, 2453, 2102, 347}\n",
      "There are a total of:  1705 Missing in transcripts_df: {40965, 98324, 24, 8225, 57377, 57378, 81960, 81961, 81962, 81963, 90154, 90162, 81988, 98381, 98383, 81999, 82000, 82001, 82002, 82003, 82004, 65622, 82005, 82006, 73824, 73825, 82027, 57461, 41093, 82056, 82057, 138, 82058, 169, 90282, 49324, 82092, 82094, 82095, 82093, 90287, 90288, 73908, 186, 90330, 73953, 73954, 8424, 8425, 8426, 8427, 8428, 8429, 49391, 49392, 49394, 49395, 49399, 98559, 82179, 265, 74002, 74003, 74006, 98590, 98591, 65825, 290, 90404, 90405, 49450, 82218, 24874, 24876, 65856, 74051, 65876, 65877, 65878, 65879, 90453, 65881, 98662, 82289, 41330, 82290, 65915, 82299, 82300, 82301, 82302, 16778, 16779, 8590, 82318, 8592, 98706, 98707, 74131, 82323, 65962, 74155, 16820, 16827, 65984, 65986, 82380, 74189, 74191, 74192, 74199, 478, 66033, 66034, 90637, 25109, 66072, 98843, 541, 66085, 66088, 74281, 74282, 66092, 90672, 74296, 90685, 66113, 581, 82506, 16983, 66136, 90739, 74357, 82549, 631, 74360, 82557, 82558, 82559, 17035, 17038, 82590, 672, 74405, 82609, 66235, 66238, 66239, 90821, 720, 721, 722, 90833, 90834, 730, 732, 733, 737, 745, 746, 747, 74478, 756, 66299, 8955, 775, 90887, 784, 795, 33565, 798, 806, 66344, 82732, 82733, 816, 66356, 66357, 66358, 66366, 832, 840, 90954, 90955, 857, 50009, 50010, 66401, 870, 82791, 82792, 82797, 74616, 17280, 74634, 50061, 50062, 66455, 66457, 66458, 923, 91039, 931, 74667, 943, 41903, 41904, 41905, 41906, 74676, 41907, 41908, 41909, 41911, 41910, 953, 41912, 41913, 41914, 41915, 41916, 91066, 91078, 66505, 74697, 91082, 982, 82909, 82920, 33777, 82946, 66563, 66564, 82956, 1038, 82964, 74773, 66614, 66626, 66642, 83026, 74838, 83031, 66648, 74840, 66650, 66654, 42084, 42086, 42087, 83053, 66681, 1151, 58498, 33923, 1157, 58515, 66711, 66719, 74913, 74915, 66725, 83110, 83111, 66733, 91334, 66761, 1225, 66762, 25805, 83167, 1254, 83177, 83178, 83179, 83180, 91371, 91373, 66800, 66801, 9465, 9466, 9467, 9468, 9469, 9470, 9471, 9472, 66817, 9474, 66819, 66820, 9475, 83205, 66828, 66829, 83223, 66840, 66841, 9500, 9501, 9502, 9503, 9504, 9505, 9506, 9507, 1316, 9508, 9509, 9510, 9512, 50473, 75050, 91428, 66869, 66870, 66872, 83259, 1340, 83262, 83263, 66881, 83265, 83266, 1358, 66907, 91495, 91496, 66921, 66922, 66923, 66924, 66925, 91497, 75119, 91509, 66939, 66940, 66942, 66943, 66944, 66945, 66946, 66947, 66948, 66949, 66950, 66951, 91521, 91524, 66954, 91525, 66956, 91526, 9614, 91528, 50576, 58762, 66962, 66963, 66964, 25999, 66966, 26010, 83359, 75168, 83364, 75173, 75174, 75175, 66987, 42422, 91602, 83413, 83420, 67043, 67046, 67047, 75257, 75268, 67078, 67083, 75276, 75277, 75294, 91679, 83493, 83495, 91710, 91711, 50758, 75337, 83530, 83531, 83536, 83537, 83538, 83539, 83540, 18011, 67172, 67186, 67188, 67189, 67192, 1662, 67208, 26256, 91794, 67235, 67238, 67239, 67240, 67241, 67242, 67243, 67268, 75479, 91866, 91867, 67293, 75488, 83686, 75498, 59157, 83756, 83757, 10032, 10038, 83767, 67384, 10039, 67382, 10041, 10042, 10043, 10044, 10045, 10046, 75585, 59202, 91980, 75605, 91991, 91995, 75615, 67426, 67427, 67428, 67429, 67430, 34675, 67471, 67478, 83879, 92073, 92074, 51149, 83931, 75762, 67581, 67583, 67584, 75778, 67588, 67592, 10263, 75824, 75825, 75831, 92223, 75845, 84056, 92254, 92266, 92282, 10363, 10364, 10365, 10366, 10367, 10368, 10369, 10370, 10371, 10372, 10373, 75901, 10375, 10377, 84107, 84108, 26767, 84121, 84122, 67740, 67741, 67748, 84145, 92343, 75973, 84182, 67799, 84183, 84187, 84188, 84189, 84216, 84223, 76064, 67872, 26919, 26920, 10546, 10548, 92468, 67894, 67898, 92474, 10556, 67900, 92477, 10561, 18755, 10565, 10569, 18762, 10572, 10574, 10576, 18769, 18768, 2386, 10578, 51540, 18774, 76129, 76130, 18802, 18808, 18809, 18810, 18811, 18812, 18813, 10622, 18814, 18815, 18816, 18817, 92547, 27022, 84368, 84369, 84370, 43411, 10644, 43414, 18845, 76207, 76208, 76209, 76210, 76211, 76212, 76213, 76214, 76215, 76216, 76217, 76218, 76219, 76220, 76221, 76222, 76223, 92611, 92616, 68072, 68078, 76271, 76272, 51699, 68118, 68119, 68120, 68121, 68122, 84503, 68125, 68126, 68127, 27172, 76335, 51780, 68165, 51783, 68177, 27220, 84571, 19041, 19042, 19043, 19044, 68197, 19045, 19048, 19057, 92787, 19061, 92790, 92791, 19072, 43649, 84611, 84612, 68236, 19092, 2710, 2717, 19101, 68257, 19115, 84652, 84651, 60085, 19126, 19129, 19133, 84669, 84670, 19136, 92863, 19138, 92864, 35526, 51936, 51937, 51938, 27376, 27378, 27379, 27380, 27381, 27382, 76541, 68351, 35607, 35611, 84765, 84766, 35620, 35622, 84818, 76634, 52064, 76647, 68457, 68458, 84850, 84885, 60319, 76707, 76708, 68519, 84912, 84913, 19408, 84953, 84954, 84955, 52189, 93188, 93192, 68647, 68648, 76841, 27691, 62494, 76863, 60479, 93269, 93270, 93271, 60504, 93272, 93273, 93274, 93281, 68725, 35958, 68727, 68728, 68726, 68729, 68739, 76948, 93333, 93334, 27801, 60581, 93350, 93349, 93352, 60589, 68803, 27845, 19659, 93388, 3280, 77010, 85220, 77043, 19702, 68856, 52476, 85259, 85260, 19729, 85266, 85267, 19752, 77097, 27953, 77111, 19768, 68920, 68921, 19772, 68927, 68928, 52545, 19784, 19785, 77143, 68952, 77144, 77145, 77146, 19799, 19805, 19808, 19810, 44387, 44388, 19816, 19822, 68975, 68976, 19827, 19828, 93560, 68987, 77207, 77209, 77210, 77211, 77212, 77213, 77214, 77216, 77218, 69036, 85424, 85425, 19891, 19892, 19893, 36284, 78861, 69094, 93675, 3584, 69139, 77338, 77339, 36405, 36407, 85568, 44608, 52807, 93770, 85588, 3696, 3699, 85658, 77478, 61113, 11974, 69330, 69333, 77552, 69383, 69384, 69385, 77594, 85786, 77606, 69418, 77628, 61253, 53086, 53087, 53088, 53089, 53090, 53099, 53100, 61300, 61304, 77702, 77709, 77711, 85905, 36760, 36765, 4003, 53155, 53156, 36809, 94157, 77795, 69606, 77800, 20461, 20462, 85999, 86000, 20463, 20464, 20465, 20466, 20467, 20468, 20469, 20470, 53235, 69647, 69659, 69661, 69662, 86061, 86062, 86063, 4144, 86064, 94273, 12356, 36933, 53326, 69712, 45137, 94293, 61548, 61550, 61551, 77949, 86145, 4233, 37004, 86167, 69784, 69785, 77981, 94368, 78004, 78005, 69869, 45300, 86267, 53502, 86285, 86287, 20756, 78106, 69931, 69932, 69933, 53581, 53586, 53587, 53588, 94546, 78167, 78168, 78169, 78170, 45409, 45410, 86387, 61812, 70037, 94615, 70043, 61863, 94631, 94633, 94637, 70086, 70091, 61900, 61902, 61903, 61904, 61905, 94694, 78312, 70124, 94717, 86532, 86534, 86535, 86536, 12811, 12812, 12814, 12816, 12818, 12824, 86567, 78378, 78380, 94784, 70229, 70235, 86619, 94837, 78455, 94839, 94843, 62085, 12936, 12946, 21152, 12963, 12966, 12971, 12972, 12979, 70327, 12988, 86722, 78537, 78543, 13014, 13015, 70360, 70361, 70362, 70363, 70364, 13017, 13018, 13019, 13020, 13021, 13026, 13027, 13024, 13025, 13028, 70380, 86764, 94959, 4854, 62199, 70403, 45839, 70428, 62238, 62265, 62272, 62273, 95046, 95047, 62313, 21354, 78705, 21381, 95122, 78775, 75902, 86973, 78804, 37851, 37852, 37870, 87042, 87043, 29702, 62470, 5129, 5130, 5131, 5132, 5133, 5134, 5135, 5136, 5137, 5138, 5139, 5140, 5141, 5142, 5143, 5144, 5145, 5146, 5147, 5148, 5149, 5150, 5151, 5152, 5153, 5154, 5155, 5156, 5157, 5158, 5159, 5160, 5161, 13345, 62503, 62504, 78894, 54322, 62542, 87126, 95350, 95351, 70777, 70778, 70779, 62592, 95364, 70789, 95365, 87202, 87203, 54443, 38077, 87245, 87246, 62679, 95451, 87265, 70887, 70888, 21743, 95500, 5392, 62738, 95520, 79143, 79152, 62790, 62791, 87379, 95583, 87396, 95588, 95599, 95601, 46455, 62845, 71043, 71046, 21903, 62865, 21906, 62866, 21909, 21911, 21916, 21922, 21924, 21925, 95654, 95655, 21928, 87464, 21930, 79275, 21933, 21936, 21937, 21940, 87481, 87482, 87483, 87484, 87485, 79294, 62914, 46532, 46533, 5575, 79305, 46540, 21970, 95708, 95709, 95710, 95711, 95714, 62947, 95723, 46579, 46584, 13830, 30217, 71182, 62997, 95765, 87584, 71205, 71210, 71211, 71212, 71213, 71214, 79408, 71231, 79424, 71233, 71234, 71235, 79425, 71237, 71238, 30298, 87645, 30307, 95866, 63106, 63120, 71355, 54971, 63172, 87756, 95948, 95949, 79570, 71385, 71407, 71409, 87806, 87807, 63241, 63242, 30484, 55061, 96034, 87853, 63280, 63294, 38719, 71487, 63295, 87878, 87879, 63318, 71516, 71521, 5991, 55143, 63345, 87933, 6017, 6018, 6019, 79747, 6021, 79748, 63363, 6027, 79756, 6032, 79766, 79767, 79768, 6056, 63401, 6059, 96171, 6061, 6063, 6069, 30664, 96209, 63459, 96254, 96255, 79873, 79874, 96257, 79878, 63502, 55319, 71706, 88119, 88120, 88121, 88135, 96335, 63575, 79961, 63589, 79987, 79996, 79998, 63622, 96395, 96396, 6292, 88219, 88220, 63652, 63654, 63655, 63666, 88243, 88247, 80056, 63673, 63674, 88251, 88259, 88261, 63685, 96462, 71900, 80095, 80103, 80104, 96491, 63727, 63728, 63729, 80115, 96515, 96516, 63749, 80136, 14609, 14611, 14612, 39192, 63775, 63786, 96563, 96575, 63812, 63813, 63815, 63817, 96589, 96590, 96591, 96592, 72025, 88427, 63852, 63853, 96622, 63893, 63894, 80282, 80283, 72094, 63918, 63919, 63920, 96686, 88515, 88516, 6598, 39384, 80355, 80356, 63989, 72185, 72186, 63996, 63997, 31234, 31236, 31237, 31238, 31239, 31241, 31242, 31243, 31244, 31245, 80405, 88598, 88608, 64034, 64035, 64036, 64037, 64040, 80431, 72243, 72244, 72245, 64051, 80453, 72306, 88690, 80509, 31361, 88741, 72363, 64173, 64182, 96950, 64185, 96953, 64196, 64206, 64207, 64208, 88795, 6880, 88833, 88834, 88835, 72454, 23306, 88842, 23308, 88843, 23313, 23314, 23315, 23318, 23324, 23325, 72493, 72494, 80685, 80686, 88883, 88884, 88889, 88890, 97086, 97089, 64338, 47957, 88919, 80733, 80734, 23393, 64353, 64354, 72552, 64360, 64361, 88952, 23419, 80768, 97159, 97160, 7050, 97168, 64405, 64407, 64418, 64427, 64428, 80818, 80820, 64437, 64439, 80824, 80827, 64443, 64458, 80843, 31691, 89043, 89044, 97240, 7150, 64504, 64511, 80899, 64516, 64520, 89110, 64534, 97314, 97315, 64548, 64549, 64550, 80940, 89147, 64571, 31810, 64584, 64585, 31827, 97364, 64598, 97368, 72797, 64613, 72807, 89208, 72829, 97407, 97408, 97410, 97411, 97413, 72870, 64679, 64686, 89264, 89265, 64693, 64723, 64730, 64731, 64732, 23776, 72933, 97510, 89319, 23792, 97536, 64769, 64771, 97539, 64774, 81160, 64776, 23823, 15640, 23833, 64792, 72988, 72989, 72994, 32034, 89394, 64822, 64823, 64824, 81212, 73025, 89409, 73027, 23875, 64835, 64836, 15693, 15694, 15696, 15697, 23888, 15699, 15702, 15703, 15707, 15716, 73063, 89448, 81258, 64886, 97661, 97662, 23943, 64911, 64912, 64914, 64915, 64916, 23959, 23969, 97698, 89514, 64938, 81336, 81338, 23995, 23997, 64966, 89545, 64970, 89559, 81368, 89562, 89568, 81385, 81386, 81387, 81388, 81389, 81390, 89582, 24051, 81396, 97780, 81405, 24062, 89599, 97791, 97793, 97794, 65030, 73225, 89610, 73231, 89615, 65043, 81428, 24084, 65044, 65045, 24088, 65046, 65047, 65048, 24096, 65056, 65057, 65058, 65059, 65060, 65061, 65062, 65063, 65064, 65065, 81451, 65066, 73261, 65067, 65068, 65069, 65070, 65073, 65074, 65075, 81461, 89664, 81477, 97862, 89673, 89676, 81501, 24157, 89707, 73325, 89709, 89710, 65136, 65137, 65139, 97915, 97916, 73346, 73347, 24200, 24203, 7825, 32413, 65188, 81573, 81574, 65189, 81576, 89768, 65191, 65193, 81580, 24250, 89789, 81609, 24269, 65233, 24289, 73443, 73444, 65257, 65272, 65273, 65279, 81664, 65280, 40709, 73480, 73481, 65292, 65294, 81681, 65297, 24341, 24346, 89893, 73511, 81706, 57131, 40753, 57139, 89909, 81718, 73530, 89915, 81727, 81728, 81731, 73540, 81732, 81733, 65351, 65354, 65355, 65356, 73553, 73555, 24411, 24412, 81757, 24415, 24420, 24423, 24424, 24425, 24426, 65384, 24428, 32617, 65389, 89967, 24432, 65390, 89970, 89971, 65391, 65392, 65393, 65394, 65396, 65397, 73594, 81786, 81787, 81788, 81789, 81791, 73599, 81790, 81792, 81793, 73604, 65404, 89992, 8079, 65429, 90008, 65432, 81821, 65437, 65438, 65439, 65444, 65445, 65446, 65447, 8107, 8108, 57260, 24500, 81847, 98250, 13016, 8147, 8148, 8149, 98260, 8152, 8153, 8154, 49115, 8156, 8158, 73703, 81896, 24555, 90094, 8179, 73716, 98295, 73722}\n"
     ]
    }
   ],
   "source": [
    "# the dataframe with the transcripts has 4003 rows and 3 columns.  How many rows will we have in our merged dataframe?\n",
    "# to do this, lets check to make sure that the talk_id's are unique in the likes dataframe, \n",
    "# and check how many talk_id's in our smaller \"likes_df\" match those in our larger \"transcript_df\".  This whill show us, assuming all other information is there, how many rows we will have in our merged dataframe.\n",
    "\n",
    "# extracting the unique talk_id's from both dataframes\n",
    "unique_likes = set(likes_df['talk_id'].unique())\n",
    "unique_transcripts = set(transcript_df['talk_id'].unique())\n",
    "matching_talk_ids = unique_likes & unique_transcripts\n",
    "\n",
    "# checking to see if the talk_id's are unique in the likes dataframe\n",
    "if unique_likes == unique_transcripts:\n",
    "    print(\"The talk_id's are unique in both dataframes\")\n",
    "    print(\"There are a total of:\", len(matching_talk_ids), \"matching unique talk_id's in the likes dataframe.  This is how many rows we will have in our merged dataframe.\")\n",
    "else:\n",
    "    print(\"The talk_id's are not unique in both dataframes\")\n",
    "    print(\"There are a total of:\", len(matching_talk_ids), \"matching unique talk_id's in the likes dataframe.  This is how many rows we will have in our merged dataframe.\")\n",
    "\n",
    "    # finding out which 'talk_id's are different between the two dataframes\n",
    "    missing_in_likes = unique_transcripts - unique_likes\n",
    "    missing_in_transcripts = unique_likes - unique_transcripts\n",
    "\n",
    "    print(\"There are a total of: \", len(missing_in_likes), \"Missing in likes_df:\", missing_in_likes)\n",
    "    print(\"There are a total of: \", len(missing_in_transcripts), \"Missing in transcripts_df:\", missing_in_transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b3945",
   "metadata": {},
   "source": [
    "Since there are 3996 matching talk ID's this is how many talks we have to analyze (prior to data cleaning and pre-processing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1420a",
   "metadata": {},
   "source": [
    "#### Merging the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba10d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title_from_likes_df</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recorded_date_from_likes_df</th>\n",
       "      <th>published_date_from_likes_df</th>\n",
       "      <th>event_from_likes_df</th>\n",
       "      <th>duration_from_likes_df</th>\n",
       "      <th>views_from_likes_df</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>957</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1266</td>\n",
       "      <td>2012797</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>2006-02-26</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1096</td>\n",
       "      <td>3006315</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id          title_from_likes_df        speaker  \\\n",
       "0        1  Averting the climate crisis        Al Gore   \n",
       "1        7             Simplicity sells    David Pogue   \n",
       "2       53          Greening the ghetto  Majora Carter   \n",
       "\n",
       "  recorded_date_from_likes_df published_date_from_likes_df  \\\n",
       "0                  2006-02-25                   2006-06-27   \n",
       "1                  2006-02-24                   2006-06-27   \n",
       "2                  2006-02-26                   2006-06-27   \n",
       "\n",
       "  event_from_likes_df  duration_from_likes_df  views_from_likes_df   likes  \n",
       "0             TED2006                     957              3681537  110000  \n",
       "1             TED2006                    1266              2012797   60000  \n",
       "2             TED2006                    1096              3006315   90000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will add a suffix of \"_new\" to this more updated dataset, so that I know which columns are from which dataset after merging them.\n",
    "# Select the columns you want to rename\n",
    "columns_to_modify = ['duration', 'event', 'recorded_date', 'views', 'title', 'published_date']\n",
    "\n",
    "# Create a dictionary where the keys are the old column names and the values are the new column names\n",
    "renamed_columns = {col: col + '_from_likes_df' for col in columns_to_modify}\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "likes_df.rename(columns=renamed_columns, inplace=True)\n",
    "likes_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d42e6",
   "metadata": {},
   "source": [
    "### Ready to merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c3b9584-bcbf-4fc3-8e64-ebf0523c10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>views</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "      <th>title_from_likes_df</th>\n",
       "      <th>speaker</th>\n",
       "      <th>recorded_date_from_likes_df</th>\n",
       "      <th>published_date_from_likes_df</th>\n",
       "      <th>event_from_likes_df</th>\n",
       "      <th>duration_from_likes_df</th>\n",
       "      <th>views_from_likes_df</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gor...</td>\n",
       "      <td>3523392</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', '...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>{243: 'New thinking on the...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>With the same humor and hu...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>957</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>{0: 'In Hans Rosling’s han...</td>\n",
       "      <td>14501685</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', '...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>{2056: \"Own your body's da...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>You've never seen data pre...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1176</td>\n",
       "      <td>15432904</td>\n",
       "      <td>462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>{0: 'David Pogue'}</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>{0: 'David Pogue is the pe...</td>\n",
       "      <td>1920832</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'de', 'el', '...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainme...</td>\n",
       "      <td>{1725: '10 top time-saving...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>New York Times columnist D...</td>\n",
       "      <td>(Music: \"The Sound of Sile...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1266</td>\n",
       "      <td>2012797</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                          title     speaker_1         all_speakers  \\\n",
       "0        1    Averting the climate crisis       Al Gore       {0: 'Al Gore'}   \n",
       "1       92  The best stats you've ever...  Hans Rosling  {0: 'Hans Rosling'}   \n",
       "2        7               Simplicity sells   David Pogue   {0: 'David Pogue'}   \n",
       "\n",
       "                     occupations                 about_speakers     views  \\\n",
       "0      {0: ['climate advocate']}  {0: 'Nobel Laureate Al Gor...   3523392   \n",
       "1  {0: ['global health expert...  {0: 'In Hans Rosling’s han...  14501685   \n",
       "2  {0: ['technology columnist']}  {0: 'David Pogue is the pe...   1920832   \n",
       "\n",
       "  recorded_date published_date    event native_lang  \\\n",
       "0    2006-02-25     2006-06-27  TED2006          en   \n",
       "1    2006-02-22     2006-06-27  TED2006          en   \n",
       "2    2006-02-24     2006-06-27  TED2006          en   \n",
       "\n",
       "                  available_lang  comments  duration  \\\n",
       "0  ['ar', 'bg', 'cs', 'de', '...     272.0       977   \n",
       "1  ['ar', 'az', 'bg', 'bn', '...     628.0      1190   \n",
       "2  ['ar', 'bg', 'de', 'el', '...     124.0      1286   \n",
       "\n",
       "                          topics                  related_talks  \\\n",
       "0  ['alternative energy', 'ca...  {243: 'New thinking on the...   \n",
       "1  ['Africa', 'Asia', 'Google...  {2056: \"Own your body's da...   \n",
       "2  ['computers', 'entertainme...  {1725: '10 top time-saving...   \n",
       "\n",
       "                             url                    description  \\\n",
       "0  https://www.ted.com/talks/...  With the same humor and hu...   \n",
       "1  https://www.ted.com/talks/...  You've never seen data pre...   \n",
       "2  https://www.ted.com/talks/...  New York Times columnist D...   \n",
       "\n",
       "                      transcript            title_from_likes_df       speaker  \\\n",
       "0  Thank you so much, Chris. ...    Averting the climate crisis       Al Gore   \n",
       "1  About 10 years ago, I took...  The best stats you've ever...  Hans Rosling   \n",
       "2  (Music: \"The Sound of Sile...               Simplicity sells   David Pogue   \n",
       "\n",
       "  recorded_date_from_likes_df published_date_from_likes_df  \\\n",
       "0                  2006-02-25                   2006-06-27   \n",
       "1                  2006-02-22                   2006-06-27   \n",
       "2                  2006-02-24                   2006-06-27   \n",
       "\n",
       "  event_from_likes_df  duration_from_likes_df  views_from_likes_df   likes  \n",
       "0             TED2006                     957              3681537  110000  \n",
       "1             TED2006                    1176             15432904  462000  \n",
       "2             TED2006                    1266              2012797   60000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will now merge the two dataframes together, using the talk_id as the key.\n",
    "merged_df = transcript_df.merge(likes_df, on='talk_id')\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1b1cd",
   "metadata": {},
   "source": [
    "#### Removing duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5ff6417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['talk_id', 'title', 'speaker_1', 'all_speakers', 'occupations',\n",
       "       'about_speakers', 'views', 'recorded_date', 'published_date', 'event',\n",
       "       'native_lang', 'available_lang', 'comments', 'duration', 'topics',\n",
       "       'related_talks', 'url', 'description', 'transcript',\n",
       "       'title_from_likes_df', 'speaker', 'recorded_date_from_likes_df',\n",
       "       'published_date_from_likes_df', 'event_from_likes_df',\n",
       "       'duration_from_likes_df', 'views_from_likes_df', 'likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see which columns are redundant, and which ones we can drop.\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc47a486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>views_from_likes_df</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gor...</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', '...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>{243: 'New thinking on the...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>With the same humor and hu...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>{0: 'In Hans Rosling’s han...</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', '...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>{2056: \"Own your body's da...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>You've never seen data pre...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>15432904</td>\n",
       "      <td>462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>62784</td>\n",
       "      <td>The electrifying speeches ...</td>\n",
       "      <td>{0: 'Daina Ramey Berry'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>en</td>\n",
       "      <td>['en']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>['TED-Ed', 'education', 'a...</td>\n",
       "      <td>{20973: 'The breathtaking ...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>Isabella Baumfree was born...</td>\n",
       "      <td>In early 1828, Sojourner T...</td>\n",
       "      <td>Daina Ramey Berry</td>\n",
       "      <td>402898</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>62794</td>\n",
       "      <td>The most important anus in...</td>\n",
       "      <td>{0: 'Cella Wright'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>en</td>\n",
       "      <td>['en']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>['animals', 'TED-Ed', 'ani...</td>\n",
       "      <td>{62347: 'The bug that poop...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>Is it a fuzzy sock? An ove...</td>\n",
       "      <td>Can you guess what you’re ...</td>\n",
       "      <td>Cella Wright</td>\n",
       "      <td>436255</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3996 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      talk_id                          title              all_speakers  \\\n",
       "0           1    Averting the climate crisis            {0: 'Al Gore'}   \n",
       "1          92  The best stats you've ever...       {0: 'Hans Rosling'}   \n",
       "...       ...                            ...                       ...   \n",
       "3994    62784  The electrifying speeches ...  {0: 'Daina Ramey Berry'}   \n",
       "3995    62794  The most important anus in...       {0: 'Cella Wright'}   \n",
       "\n",
       "                        occupations                 about_speakers  \\\n",
       "0         {0: ['climate advocate']}  {0: 'Nobel Laureate Al Gor...   \n",
       "1     {0: ['global health expert...  {0: 'In Hans Rosling’s han...   \n",
       "...                             ...                            ...   \n",
       "3994                            NaN                            NaN   \n",
       "3995                            NaN                            NaN   \n",
       "\n",
       "     recorded_date published_date    event native_lang  \\\n",
       "0       2006-02-25     2006-06-27  TED2006          en   \n",
       "1       2006-02-22     2006-06-27  TED2006          en   \n",
       "...            ...            ...      ...         ...   \n",
       "3994    2020-04-28     2020-04-30   TED-Ed          en   \n",
       "3995    2020-04-30     2020-04-30   TED-Ed          en   \n",
       "\n",
       "                     available_lang  comments  duration  \\\n",
       "0     ['ar', 'bg', 'cs', 'de', '...     272.0       977   \n",
       "1     ['ar', 'az', 'bg', 'bn', '...     628.0      1190   \n",
       "...                             ...       ...       ...   \n",
       "3994                         ['en']       NaN       257   \n",
       "3995                         ['en']       NaN       281   \n",
       "\n",
       "                             topics                  related_talks  \\\n",
       "0     ['alternative energy', 'ca...  {243: 'New thinking on the...   \n",
       "1     ['Africa', 'Asia', 'Google...  {2056: \"Own your body's da...   \n",
       "...                             ...                            ...   \n",
       "3994  ['TED-Ed', 'education', 'a...  {20973: 'The breathtaking ...   \n",
       "3995  ['animals', 'TED-Ed', 'ani...  {62347: 'The bug that poop...   \n",
       "\n",
       "                                url                    description  \\\n",
       "0     https://www.ted.com/talks/...  With the same humor and hu...   \n",
       "1     https://www.ted.com/talks/...  You've never seen data pre...   \n",
       "...                             ...                            ...   \n",
       "3994  https://www.ted.com/talks/...  Isabella Baumfree was born...   \n",
       "3995  https://www.ted.com/talks/...  Is it a fuzzy sock? An ove...   \n",
       "\n",
       "                         transcript            speaker  views_from_likes_df  \\\n",
       "0     Thank you so much, Chris. ...            Al Gore              3681537   \n",
       "1     About 10 years ago, I took...       Hans Rosling             15432904   \n",
       "...                             ...                ...                  ...   \n",
       "3994  In early 1828, Sojourner T...  Daina Ramey Berry               402898   \n",
       "3995  Can you guess what you’re ...       Cella Wright               436255   \n",
       "\n",
       "       likes  \n",
       "0     110000  \n",
       "1     462000  \n",
       "...      ...  \n",
       "3994   12000  \n",
       "3995   13000  \n",
       "\n",
       "[3996 rows x 20 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we'll remove duplicate columns\n",
    "merged_cleaved_df = merged_df.drop([\"speaker_1\", \"title_from_likes_df\", \"views\", \"recorded_date_from_likes_df\", \"published_date_from_likes_df\", \"event_from_likes_df\", \"duration_from_likes_df\"], axis=1)\n",
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a34ef",
   "metadata": {},
   "source": [
    "#### Clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "574317eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gor...</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', '...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>{243: 'New thinking on the...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>With the same humor and hu...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>{0: 'In Hans Rosling’s han...</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', '...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>{2056: \"Own your body's da...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>You've never seen data pre...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>15432904</td>\n",
       "      <td>462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>62784</td>\n",
       "      <td>The electrifying speeches ...</td>\n",
       "      <td>{0: 'Daina Ramey Berry'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>en</td>\n",
       "      <td>['en']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>['TED-Ed', 'education', 'a...</td>\n",
       "      <td>{20973: 'The breathtaking ...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>Isabella Baumfree was born...</td>\n",
       "      <td>In early 1828, Sojourner T...</td>\n",
       "      <td>Daina Ramey Berry</td>\n",
       "      <td>402898</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>62794</td>\n",
       "      <td>The most important anus in...</td>\n",
       "      <td>{0: 'Cella Wright'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>en</td>\n",
       "      <td>['en']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>['animals', 'TED-Ed', 'ani...</td>\n",
       "      <td>{62347: 'The bug that poop...</td>\n",
       "      <td>https://www.ted.com/talks/...</td>\n",
       "      <td>Is it a fuzzy sock? An ove...</td>\n",
       "      <td>Can you guess what you’re ...</td>\n",
       "      <td>Cella Wright</td>\n",
       "      <td>436255</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3996 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      talk_id                          title              all_speakers  \\\n",
       "0           1    Averting the climate crisis            {0: 'Al Gore'}   \n",
       "1          92  The best stats you've ever...       {0: 'Hans Rosling'}   \n",
       "...       ...                            ...                       ...   \n",
       "3994    62784  The electrifying speeches ...  {0: 'Daina Ramey Berry'}   \n",
       "3995    62794  The most important anus in...       {0: 'Cella Wright'}   \n",
       "\n",
       "                        occupations                 about_speakers  \\\n",
       "0         {0: ['climate advocate']}  {0: 'Nobel Laureate Al Gor...   \n",
       "1     {0: ['global health expert...  {0: 'In Hans Rosling’s han...   \n",
       "...                             ...                            ...   \n",
       "3994                            NaN                            NaN   \n",
       "3995                            NaN                            NaN   \n",
       "\n",
       "     recorded_date published_date    event native_lang  \\\n",
       "0       2006-02-25     2006-06-27  TED2006          en   \n",
       "1       2006-02-22     2006-06-27  TED2006          en   \n",
       "...            ...            ...      ...         ...   \n",
       "3994    2020-04-28     2020-04-30   TED-Ed          en   \n",
       "3995    2020-04-30     2020-04-30   TED-Ed          en   \n",
       "\n",
       "                     available_lang  comments  duration  \\\n",
       "0     ['ar', 'bg', 'cs', 'de', '...     272.0       977   \n",
       "1     ['ar', 'az', 'bg', 'bn', '...     628.0      1190   \n",
       "...                             ...       ...       ...   \n",
       "3994                         ['en']       NaN       257   \n",
       "3995                         ['en']       NaN       281   \n",
       "\n",
       "                             topics                  related_talks  \\\n",
       "0     ['alternative energy', 'ca...  {243: 'New thinking on the...   \n",
       "1     ['Africa', 'Asia', 'Google...  {2056: \"Own your body's da...   \n",
       "...                             ...                            ...   \n",
       "3994  ['TED-Ed', 'education', 'a...  {20973: 'The breathtaking ...   \n",
       "3995  ['animals', 'TED-Ed', 'ani...  {62347: 'The bug that poop...   \n",
       "\n",
       "                                url                    description  \\\n",
       "0     https://www.ted.com/talks/...  With the same humor and hu...   \n",
       "1     https://www.ted.com/talks/...  You've never seen data pre...   \n",
       "...                             ...                            ...   \n",
       "3994  https://www.ted.com/talks/...  Isabella Baumfree was born...   \n",
       "3995  https://www.ted.com/talks/...  Is it a fuzzy sock? An ove...   \n",
       "\n",
       "                         transcript            speaker      view   likes  \n",
       "0     Thank you so much, Chris. ...            Al Gore   3681537  110000  \n",
       "1     About 10 years ago, I took...       Hans Rosling  15432904  462000  \n",
       "...                             ...                ...       ...     ...  \n",
       "3994  In early 1828, Sojourner T...  Daina Ramey Berry    402898   12000  \n",
       "3995  Can you guess what you’re ...       Cella Wright    436255   13000  \n",
       "\n",
       "[3996 rows x 20 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we're removing the '_y' from any column names that have it\n",
    "# merged_cleaved_df.columns = [col.rstrip('_y') if col.endswith('_y') else col for col in merged_cleaved_df.columns]\n",
    "merged_cleaved_df.columns = [col.rstrip('_from_likes_df') if col.endswith('_from_likes_df') else col for col in merged_cleaved_df.columns]\n",
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ade8a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['talk_id', 'title', 'all_speakers', 'occupations', 'about_speakers',\n",
      "       'recorded_date', 'published_date', 'event', 'native_lang',\n",
      "       'available_lang', 'comments', 'duration', 'topics', 'related_talks',\n",
      "       'url', 'description', 'transcript', 'speaker', 'view', 'likes'],\n",
      "      dtype='object')\n",
      "(3996, 20)\n"
     ]
    }
   ],
   "source": [
    "# There are no more duplicate columns\n",
    "print(merged_cleaved_df.columns)\n",
    "print(merged_cleaved_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db265090",
   "metadata": {},
   "source": [
    "There are no more duplicate columns.  \n",
    "\n",
    "The dataset has 3996 rows and 20 columns in the merged_df dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e727c33",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "- dealing with nulls\n",
    "- addressing datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2fcc2",
   "metadata": {},
   "source": [
    "### WHAT TO DO WITH THESE HEADINGS?  Where we'll go from here:\n",
    "\n",
    "- Exclude the transcript from a dataframe for initial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf5a98",
   "metadata": {},
   "source": [
    "### Dealing with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dacbaef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talk_id             0\n",
       "title               0\n",
       "all_speakers        4\n",
       "occupations       522\n",
       "about_speakers    503\n",
       "recorded_date       1\n",
       "published_date      0\n",
       "event               0\n",
       "native_lang         0\n",
       "available_lang      0\n",
       "comments          654\n",
       "duration            0\n",
       "topics              0\n",
       "related_talks       0\n",
       "url                 0\n",
       "description         0\n",
       "transcript          0\n",
       "speaker             0\n",
       "view                0\n",
       "likes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many nulls do we have now?\n",
    "pd.options.display.max_rows = 25\n",
    "merged_cleaved_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bdaccc",
   "metadata": {},
   "source": [
    "For the moment, while removing nulls will result in ((3996-3331) / 3996 = 0.1664) 16.4% of the data being thrown out, scraping additional data from the TED website is beyond the scope of this project, so we will continue without this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa811675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what happens to the 3996 rows when we drop the null values\n",
    "merged_cleaved_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd641cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3330, 20)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65ac24",
   "metadata": {},
   "source": [
    "### Addressing Datatypes\n",
    "\n",
    "We're going to, one by one, determine what to do with each of the \"object\" columns. \n",
    "Options include:\n",
    "- Change into numerical values\n",
    "- Clean for CountVectorization\n",
    "- Clean for Dummy / Multi-Label-Binarizing\n",
    "- Drop\n",
    "\n",
    "#### Columns to address, and what was done to them:\n",
    "\n",
    "- all_speakers      3331 non-null   object **DROPPED / multiple_speakers variable created**\n",
    "- occupations       3331 non-null   object **ready for dummy variables - May Drop**\n",
    "- about_speakers    3331 non-null   object **DROPPING**\n",
    "- native_lang       3331 non-null   object **DROPPED**\n",
    "- available_lang    3331 non-null   object  **DROPPED**\n",
    "- comments          3331 non-null   float64 **Ready for analysis**\n",
    "- topics            3331 non-null   object **Create  (via MultiLabel Binarizer)**\n",
    "- related_talks     3331 non-null   object **Possible Future CountVectorization**\n",
    "- url               3331 non-null   object **DROPPED**\n",
    "- description       3331 non-null   object **Possible Future CountVectorization**\n",
    "- transcript        3331 non-null   object **CountVectorize**\n",
    "- title             3331 non-null   object **Possible Future CountVectorization**\n",
    "- speaker           3331 non-null   object **DROPPED**\n",
    "- recorded_date     3331 non-null   object **Changed to DateTime**\n",
    "- published_date    3331 non-null   object **Changed to DateTime**\n",
    "- event             3331 non-null   object **ted_mainstage variable created**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26bf70",
   "metadata": {},
   "source": [
    " #### Addressing 'object' columns - changing them into numerical values, or dropping them altogether.\n",
    "\n",
    "We'll start with \"all_speakers\" (for this section of the notebook, the column we are addressing in the section below will be made a headline, as is \"all_speakers\" below)\n",
    "\n",
    "#### - all_speakers      3331 non-null   object **DROPPED / multiple_speakers variable created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0be12e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_speakers\n",
       "{0: 'Hans Rosling'}            9\n",
       "{0: 'Greg Gage'}               9\n",
       "{0: 'Juan Enriquez'}           9\n",
       "{0: 'Marco Tempest'}           7\n",
       "{0: ' Rives'}                  6\n",
       "                              ..\n",
       "{0: 'Ryan Merkley'}            1\n",
       "{0: 'Pankaj Ghemawat'}         1\n",
       "{0: 'David Pizarro'}           1\n",
       "{0: 'Lemn Sissay'}             1\n",
       "{0: 'Dick M. Carpenter II'}    1\n",
       "Name: count, Length: 2851, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"all_speakers\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c05d6a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dictionaries with a key '1': 103\n"
     ]
    }
   ],
   "source": [
    "# Let's find out how many talks have multiple speakers\n",
    "# Assuming all_speakers is a list of dictionaries\n",
    "all_speakers = merged_cleaved_df[\"all_speakers\"]\n",
    "\n",
    "# Initialize a counter\n",
    "count = 0\n",
    "\n",
    "# Iterate through each dictionary in the list\n",
    "for speaker_dict in all_speakers:\n",
    "    # Check if the key \"1\" exists in the dictionary\n",
    "    if \"1\" in speaker_dict:\n",
    "        count += 1\n",
    "\n",
    "# Output the result\n",
    "print(f\"Number of dictionaries with a key '1': {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ac870",
   "metadata": {},
   "source": [
    "There are 103 talks with multiple speakers in them.  \n",
    "As much of the data in 'all_speakers' is redundant as it repeats the value of the main speaker, we will drop this column.\n",
    "\n",
    "We will, however, create a dummy column \"multiple_speakers\" to see if the presence of multiple speakers impacts the outcome of the speech.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3a98467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_cleaved_df is your existing DataFrame\n",
    "all_speakers = merged_cleaved_df[\"all_speakers\"]\n",
    "\n",
    "# Using list comprehension to create a one-hot encoded column\n",
    "merged_cleaved_df['multiple_speakers'] = [1 if \"1\" in speaker_dict else 0 for speaker_dict in all_speakers]\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'multiple_speakers' with one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c120b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"all_speakers\" column, as it is not useful for our analysis\n",
    "merged_cleaved_df.drop([\"all_speakers\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be28d86",
   "metadata": {},
   "source": [
    "#### - occupations       3331 non-null   object **ready for dummy variables - May Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f937196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupations\n",
       "{0: ['writer']}                                   52\n",
       "{0: ['journalist']}                               43\n",
       "{0: ['entrepreneur']}                             42\n",
       "{0: ['artist']}                                   40\n",
       "{0: ['designer']}                                 37\n",
       "                                                  ..\n",
       "{0: ['bow designer']}                              1\n",
       "{0: ['explorer and filmmaker']}                    1\n",
       "{0: ['human-computer interaction researcher']}     1\n",
       "{0: ['composer', 'inventor'], 1: ['musician']}     1\n",
       "{0: ['law researcher']}                            1\n",
       "Name: count, Length: 1982, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"occupations\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54f21f",
   "metadata": {},
   "source": [
    "Let's clean these by removing them from their current dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c325cd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformed_occupations\n",
       "writer                             54\n",
       "journalist                         44\n",
       "entrepreneur                       43\n",
       "artist                             41\n",
       "designer                           37\n",
       "                                   ..\n",
       "former_prime_minister_of_greece     1\n",
       "graphic_artist director             1\n",
       "dolphin_researcher                  1\n",
       "undercover_journalist               1\n",
       "law_researcher                      1\n",
       "Name: count, Length: 1924, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we're going to split the \"occupations\" column into a list of occupations\n",
    "\n",
    "def transform_occupation(occupation_str):\n",
    "    # Extracting the part after \"{0: \" and before the first occurrence of \"],\"\n",
    "    match = re.search(r\"\\{0: \\[([^\\]]*)\\]\", occupation_str)\n",
    "    if match:\n",
    "        occupations = match.group(1)\n",
    "        # Remove quotes and split by comma to get individual occupations\n",
    "        occupations = occupations.replace(\"'\", \"\").split(\", \")\n",
    "        # Replace spaces within occupations with underscores\n",
    "        occupations = [occupation.replace(\" \", \"_\") for occupation in occupations]\n",
    "        # Join the occupations back with a space\n",
    "        return \" \".join(occupations)\n",
    "    else:\n",
    "        # Return an empty string or some default value if the pattern is not found\n",
    "        return \"\"\n",
    "\n",
    "# Apply the function to the 'occupations' column\n",
    "merged_cleaved_df['transformed_occupations'] = merged_cleaved_df['occupations'].apply(transform_occupation)\n",
    "merged_cleaved_df['transformed_occupations'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e114d5f",
   "metadata": {},
   "source": [
    "### Transforming Occupations Into Dummies?\n",
    "\n",
    "The following code is hashed-out as we are trying to limit variables in our modelling (as there are only 3330 rows in the dataset, creating too many variables will risk creating more columns then there are variables).  We can consider including it at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50676c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load your actual DataFrame here\n",
    "# # merged_cleaved_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# # Convert 'transformed_occupations' into dummy variables\n",
    "# occupation_dummies = pd.get_dummies(merged_cleaved_df['transformed_occupations'], drop_first=True)\n",
    "\n",
    "# # Define X and y\n",
    "# X = occupation_dummies\n",
    "# y = merged_cleaved_df['percent_likes']\n",
    "\n",
    "# # Splitting the data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Adding a constant to the model for the training data\n",
    "# X_train = sm.add_constant(X_train)\n",
    "\n",
    "# # Linear Regression on Training Data\n",
    "# model = sm.OLS(y_train, X_train)\n",
    "# result = model.fit()\n",
    "\n",
    "# # Optionally: Evaluate model performance on test data\n",
    "# X_test = sm.add_constant(X_test)\n",
    "# predictions = result.predict(X_test)\n",
    "\n",
    "\n",
    "# # Getting the coefficients from the trained model\n",
    "# coefficients = result.params\n",
    "\n",
    "# # Dropping the constant for the purpose of this analysis\n",
    "# coefficients = coefficients.drop('const', errors='ignore')\n",
    "\n",
    "# # Sorting the coefficients\n",
    "# sorted_coefficients = coefficients.sort_values()\n",
    "\n",
    "# # Selecting the top 10 positive and negative coefficients\n",
    "# top_10_positive = sorted_coefficients.tail(10)\n",
    "# top_10_negative = sorted_coefficients.head(10)\n",
    "\n",
    "# # Plotting\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "# # Plot for top 10 positive coefficients\n",
    "# top_10_positive.plot(kind='barh', ax=axes[0], color='green')\n",
    "# axes[0].set_title('Top 10 Positive Coefficients')\n",
    "# axes[0].set_xlabel('Coefficient Value')\n",
    "# axes[0].set_ylabel('Occupations')\n",
    "\n",
    "# # Plot for top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a291f264",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'occupation_dummies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# again, the above code is hashed out as it creates too many columns. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43moccupation_dummies\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'occupation_dummies' is not defined"
     ]
    }
   ],
   "source": [
    "# again, the above code is hashed out as it creates too many columns. \n",
    "occupation_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e198c",
   "metadata": {},
   "source": [
    "#### - about_speakers  3331 non-null   object **DROPPING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c52b0c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {0: 'Nobel Laureate Al Gor...\n",
       "1       {0: 'In Hans Rosling’s han...\n",
       "2       {0: 'David Pogue is the pe...\n",
       "3       {0: 'Majora Carter redefin...\n",
       "4       {0: \"Creativity expert Sir...\n",
       "                    ...              \n",
       "3985    {0: 'A political strategis...\n",
       "3986    {0: 'With a style that cra...\n",
       "3990    {0: \"TED Prize winner Larr...\n",
       "3991    {0: 'Nancy Lublin, cofound...\n",
       "3993    {0: 'Dick M. Carpenter II ...\n",
       "Name: about_speakers, Length: 3330, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df['about_speakers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b268915",
   "metadata": {},
   "source": [
    "For the scope of this analyses, we will drop this column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35765c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"all_speakers\" column, as it is not useful for our analysis\n",
    "merged_cleaved_df.drop([\"about_speakers\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa55e9d",
   "metadata": {},
   "source": [
    "#### - native_lang       3331 non-null   object DROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b97da500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "native_lang\n",
       "en       3298\n",
       "es         15\n",
       "fr          7\n",
       "hi          2\n",
       "de          1\n",
       "pt          1\n",
       "ko          1\n",
       "zh-cn       1\n",
       "ar          1\n",
       "pt-br       1\n",
       "ja          1\n",
       "it          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"native_lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344830e",
   "metadata": {},
   "source": [
    "As the vast majority of this column represents English (\"en\") as being the native language, we will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60843a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df = merged_cleaved_df.drop(\"native_lang\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8a87e",
   "metadata": {},
   "source": [
    "#### - available_lang    3331 non-null   object DROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acccbb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "available_lang\n",
       "['en']                                                                                                                                                                                                    14\n",
       "['ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'he', 'it', 'ja', 'ko', 'nl', 'pl', 'pt-br', 'ro', 'ru', 'tr', 'vi', 'zh-cn', 'zh-tw']                                                                          6\n",
       "['ar', 'bg', 'de', 'en', 'es', 'fr', 'he', 'it', 'ja', 'ko', 'nl', 'pl', 'pt-br', 'ro', 'ru', 'tr', 'vi', 'zh-cn', 'zh-tw']                                                                                4\n",
       "['ar', 'bg', 'de', 'en', 'es', 'fr', 'he', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'sr', 'tr', 'vi', 'zh-cn', 'zh-tw']                                                                    4\n",
       "['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'he', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'sk', 'sr', 'sv', 'th', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']        3\n",
       "                                                                                                                                                                                                          ..\n",
       "['ar', 'bg', 'da', 'de', 'en', 'es', 'fr', 'he', 'hu', 'it', 'ja', 'ko', 'nb', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'sr', 'th', 'tr', 'vi', 'zh-cn', 'zh-tw']                                            1\n",
       "['ar', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'fa', 'fr', 'fr-ca', 'he', 'hr', 'it', 'ja', 'ko', 'lt', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'sq', 'sr', 'th', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']     1\n",
       "['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'he', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']                                                  1\n",
       "['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr', 'fr-ca', 'he', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'ku', 'nl', 'pl', 'pt', 'pt-br', 'ro', 'ru', 'sq', 'sr', 'th', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']     1\n",
       "['en', 'es', 'it', 'pt-br']                                                                                                                                                                                1\n",
       "Name: count, Length: 3266, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"available_lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e84c3",
   "metadata": {},
   "source": [
    "As we are attempting to limit features, I will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ef02f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df = merged_cleaved_df.drop(\"available_lang\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5f687",
   "metadata": {},
   "source": [
    "#### - comments          3331 non-null   float64   **leave as-is**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d49379",
   "metadata": {},
   "source": [
    "The comments are ready for processing as they are already numerically represented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f5646",
   "metadata": {},
   "source": [
    "#### - topics            3331 non-null   object **Turn into dummy variables via Multi Label Binarizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics\n",
       "['art', 'creativity']                                                                                                                                                                                                        2\n",
       "['TED Fellows', 'photography', 'war']                                                                                                                                                                                        2\n",
       "['charter for compassion', 'compassion', 'global issues', 'religion']                                                                                                                                                        2\n",
       "['design', 'entertainment', 'live music', 'music', 'technology']                                                                                                                                                             2\n",
       "['architecture', 'cities', 'design', 'infrastructure']                                                                                                                                                                       2\n",
       "                                                                                                                                                                                                                            ..\n",
       "['TED Fellows', 'TED-Ed', 'brain', 'life', 'neuroscience', 'science', 'technology', 'biology', 'physiology', 'insects', 'nature', 'sound', 'humor']                                                                          1\n",
       "['TED-Ed', 'education', 'mind', 'science', 'philosophy', 'space', 'Planets', 'consciousness', 'math', 'physics', 'extraterrestrial life', 'curiosity', 'cosmos', 'universe', 'String theory', 'dark matter', 'nanoscale']    1\n",
       "['TED-Ed', 'biology', 'deextinction', 'exploration', 'science', 'oceans', 'submarine', 'environment', 'ecology', 'marine biology']                                                                                           1\n",
       "['TED-Ed', 'creativity', 'education', 'science', 'simplicity', 'technology', 'exploration', 'Nobel Prize', 'ancient world', 'curiosity', 'innovation', 'space', 'physics', 'Planets', 'history', 'math']                     1\n",
       "['society', 'law', 'policy', 'justice system', 'TEDx']                                                                                                                                                                       1\n",
       "Name: count, Length: 3321, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"topics\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eafe1",
   "metadata": {},
   "source": [
    "We will turn these into dummy variables via a MultiLabelBinarizer in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65003bd",
   "metadata": {},
   "source": [
    "#### - related_talks     3331 non-null   object  DROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0fd0787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related_talks\n",
       "{243: 'New thinking on the climate crisis', 547: 'The business logic of sustainability', 2093: 'The state of the climate — and what we might do about it', 54715: 'How we can turn the tide on climate', 29968: 'The most important thing you can do to fight climate change: talk about it', 2339: \"Climate change is happening. Here's how we adapt\"}                  1\n",
       "{2387: 'The untapped genius that could change science for the better', 2504: 'Good news in the fight against pancreatic cancer', 2821: 'A simple new blood test that can catch cancer early', 53671: 'How does chemotherapy work?', 2467: 'A new superweapon in the fight against cancer', 20919: 'How cancer cells communicate -- and how we can slow them down'}       1\n",
       "{40727: 'How to revive your belief in democracy', 2104: 'How to upgrade democracy for the Internet era', 2060: 'Why ordinary people need to understand power', 29521: \"What's needed to bring the US voting system into the 21st century\", 51845: 'Why do Americans vote on Tuesdays?', 2714: \"Who would the rest of the world vote for in your country's election?\"}    1\n",
       "{1040: 'Why we have too few women leaders', 2384: 'The US needs paid family leave -- for the sake of its future', 2272: 'The single biggest reason why start-ups succeed', 31235: 'This is what makes employees happy at work', 33778: '8 lessons on building a company people enjoy working for', 49359: 'What productive conflict can offer a workplace'}              1\n",
       "{2582: 'How to raise successful kids -- without over-parenting', 1965: 'Teach teachers how to create magic', 2579: \"Let's teach for mastery -- not test scores\", 2276: 'How to fix a broken school? Lead fearlessly, love hard', 2775: 'A summer school kids actually want to attend', 46386: 'The \"opportunity gap\" in US public education -- and how to close it'}     1\n",
       "                                                                                                                                                                                                                                                                                                                                                                        ..\n",
       "{1269: 'The shared experience of absurdity', 1151: 'Gotta share!', 60: 'Four American characters', 37346: 'The beautiful future of solar power', 5116: 'Lessons from a solar storm chaser', 2368: 'Forget Wi-Fi. Meet the new Li-Fi Internet'}                                                                                                                           1\n",
       "{1340: 'Hedonistic sustainability', 1065: 'We are makers', 891: 'Intricate beauty by design', 1793: 'DJ decks made of ... paper', 1347: 'The secret structure of great talks', 1706: 'What makes us feel good about our work?'}                                                                                                                                          1\n",
       "{1126: 'On being wrong', 605: 'A kinder, gentler philosophy of success', 947: 'Keep your goals to yourself', 2582: 'How to raise successful kids -- without over-parenting', 1687: 'To This Day ... for the bullied and beautiful', 70: '8 secrets of success'}                                                                                                          1\n",
       "{1267: 'A map of the brain', 1146: 'A light switch for neurons', 1000: 'Re-engineering the brain', 2244: \"How to control someone else's arm with your brain\", 2557: \"A new way to study the brain's invisible secrets\", 2495: 'This is your brain on communication'}                                                                                                     1\n",
       "{2406: 'I love being a police officer, but we need reform', 60315: 'How forgiveness can create a more just legal system', 8421: \"How to put the power of law in people's hands\", 2675: 'How jails extort the poor', 2149: 'The small and surprisingly dangerous detail the police track about you', 2453: \"A prosecutor's vision for a better justice system\"}           1\n",
       "Name: count, Length: 3330, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"related_talks\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493d65a",
   "metadata": {},
   "source": [
    "For the scope of this project, we will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4019bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df = merged_cleaved_df.drop(\"related_talks\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac288d5",
   "metadata": {},
   "source": [
    "#### - url               3331 non-null   object **DROPPED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a577330",
   "metadata": {},
   "source": [
    "We will drop the URL column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d530ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the URL column\n",
    "merged_cleaved_df.drop([\"url\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690c83a",
   "metadata": {},
   "source": [
    "#### - description       3331 non-null   object DROPPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d09af7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description\n",
       "With the same humor and humanity he exuded in \"An Inconvenient Truth,\" Al Gore spells out 15 ways that individuals can address climate change immediately, from buying a hybrid to inventing a new, hotter brand name for global warming.                                                                                                                                                                                                                                                                               1\n",
       "After decades of research and billions spent in clinical trials, we still have a problem with cancer drug delivery, says biomedical engineer Elizabeth Wayne. Chemotherapy kills cancer -- but it kills the rest of your body, too. Instead of using human design to fight cancer, why not use nature's? In this quick talk, Wayne explains how her lab is creating nanoparticle treatments that bind to immune cells, your body's first responders, to precisely target cancer cells without damaging healthy ones.    1\n",
       "Many people like to talk about how important voting is, how it's your civic duty and responsibility as an adult. Eric Liu agrees with all that, but he also thinks it's time to bring joy back to the ballot box. The former political speechwriter details how he and his team are fostering the culture around voting in the 2016 US presidential election -- and closes with a powerful analysis of why anyone eligible should show up on Election Day.                                                              1\n",
       "How much do you get paid? How does it compare to the people you work with? You should know, and so should they, says management researcher David Burkus. In this talk, Burkus questions our cultural assumptions around keeping salaries secret and makes a compelling case for why sharing them could benefit employees, organizations and society.                                                                                                                                                                    1\n",
       "Our kids are our future, and it's crucial they believe it themselves. That's why Nadia Lopez opened an academic oasis in Brownsville, Brooklyn, one of the most underserved and violent neighborhoods in New York -- because she believes in every child's brilliance and capabilities. In this short, energizing talk, the founding principal of Mott Hall Bridges Academy (and a star of Humans of New York) shares how she helps her scholars envision a brighter future for themselves and their families.          1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ..\n",
       "Colin Robertson had 3 minutes on the TED stage to tell the world about his solar-powered crowdsourced health care solution. And then...                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Kelli Anderson shatters our expectations about reality by injecting humor and surprise into everyday objects. She shares her disruptive and clever designs.                                                                                                                                                                                                                                                                                                                                                             1\n",
       "In this funny and blunt talk, Larry Smith pulls no punches when he calls out the absurd excuses people invent when they fail to pursue their passions.                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "By dissecting a cockroach ... yes, live on stage ... TED Fellow and neuroscientist Greg Gage shows how brains receive and deliver electric impulses -- and how legs can respond. This talk comes from the TED-Ed project.                                                                                                                                                                                                                                                                                               1\n",
       "Many countries have an active, centuries-old law that allows government agencies to take your things -- your house, your car, your business -- without ever convicting you of a crime. Law researcher Dick M. Carpenter II exposes how this practice of civil forfeiture threatens your rights and creates a huge monetary incentive for law enforcement to pocket your possessions -- and he lays out a path to end \"policing for profit\" once and for all.                                                            1\n",
       "Name: count, Length: 3330, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"description\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba2de7",
   "metadata": {},
   "source": [
    "As this column has little to do with the giving of the speech itself, we will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba0e3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the description column\n",
    "merged_cleaved_df.drop([\"description\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc97b5",
   "metadata": {},
   "source": [
    "#### - transcript        3331 non-null   object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c9ee415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript\n",
       "Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful. I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night. And I say that sincerely, partly because (Mock sob) I need that. (Laughter) Put yourselves in my position. (Laughter) I flew on Air Force Two for eight years. (Laughter) Now I have to take off my shoes or boots to get on an airplane! (Laughter) (Applause) I'll tell you one quick story to illustrate what that's been like for me. (Laughter) It's a true story — every bit of this is true. Soon after Tipper and I left the — (Mock sob) White House — (Laughter) we were driving from our home in Nashville to a little farm we have 50 miles east of Nashville. Driving ourselves. (Laughter) I know it sounds like a little thing to you, but — (Laughter) I looked in the rear-view mirror and all of a sudden it just hit me. There was no motorcade back there. (Laughter) You've heard of phantom limb pain? (Laughter) This was a rented Ford Taurus. (Laughter) It was dinnertime, and we started looking for a place to eat. We were on I-40. We got to Exit 238, Lebanon, Tennessee. We got off the exit, we found a Shoney's restaurant. Low-cost family restaurant chain, for those of you who don't know it. We went in and sat down at the booth, and the waitress came over, made a big commotion over Tipper. (Laughter) She took our order, and then went to the couple in the booth next to us, and she lowered her voice so much, I had to really strain to hear what she was saying. And she said \"Yes, that's former Vice President Al Gore and his wife, Tipper.\" And the man said, \"He's come down a long way, hasn't he?\" (Laughter) (Applause) There's been kind of a series of epiphanies. (Laughter) The very next day, continuing the totally true story, I got on a G-V to fly to Africa to make a speech in Nigeria, in the city of Lagos, on the topic of energy. And I began the speech by telling them the story of what had just happened the day before in Nashville. And I told it pretty much the same way I've just shared it with you: Tipper and I were driving ourselves, Shoney's, low-cost family restaurant chain, what the man said — they laughed. I gave my speech, then went back out to the airport to fly back home. I fell asleep on the plane until, during the middle of the night, we landed on the Azores Islands for refueling. I woke up, they opened the door, I went out to get some fresh air, and I looked, and there was a man running across the runway. And he was waving a piece of paper, and he was yelling, \"Call Washington! Call Washington!\" And I thought to myself, in the middle of the night, in the middle of the Atlantic, what in the world could be wrong in Washington? Then I remembered it could be a bunch of things. (Laughter) But what it turned out to be, was that my staff was extremely upset because one of the wire services in Nigeria had already written a story about my speech, and it had already been printed in cities all across the United States of America. It was printed in Monterey, I checked. (Laughter) And the story began, \"Former Vice President Al Gore announced in Nigeria yesterday,\" quote: 'My wife Tipper and I have opened a low-cost family restaurant'\" — (Laughter) \"'named Shoney's, and we are running it ourselves.'\" (Laughter) Before I could get back to U.S. soil, David Letterman and Jay Leno had already started in on — one of them had me in a big white chef's hat, Tipper was saying, \"One more burger with fries!\" (Laughter) Three days later, I got a nice, long, handwritten letter from my friend and partner and colleague Bill Clinton, saying, \"Congratulations on the new restaurant, Al!\" (Laughter) We like to celebrate each other's successes in life. (Laughter) I was going to talk about information ecology. But I was thinking that, since I plan to make a lifelong habit of coming back to TED, that maybe I could talk about that another time. (Applause) Chris Anderson: It's a deal! (Applause) Al Gore: I want to focus on what many of you have said you would like me to elaborate on: What can you do about the climate crisis? I want to start with a couple of — I'm going to show some new images, and I'm going to recapitulate just four or five. Now, the slide show. I update the slide show every time I give it. I add new images, because I learn more about it every time I give it. It's like beach-combing, you know? Every time the tide comes in and out, you find some more shells. Just in the last two days, we got the new temperature records in January. This is just for the United States of America. Historical average for Januarys is 31 degrees; last month was 39.5 degrees. Now, I know that you wanted some more bad news about the environment — I'm kidding. But these are the recapitulation slides, and then I'm going to go into new material about what you can do. But I wanted to elaborate on a couple of these. First of all, this is where we're projected to go with the U.S. contribution to global warming, under business as usual. Efficiency in end-use electricity and end-use of all energy is the low-hanging fruit. Efficiency and conservation — it's not a cost; it's a profit. The sign is wrong. It's not negative; it's positive. These are investments that pay for themselves. But they are also very effective in deflecting our path. Cars and trucks — I talked about that in the slideshow, but I want you to put it in perspective. It's an easy, visible target of concern — and it should be — but there is more global warming pollution that comes from buildings than from cars and trucks. Cars and trucks are very significant, and we have the lowest standards in the world. And so we should address that. But it's part of the puzzle. Other transportation efficiency is as important as cars and trucks. Renewables at the current levels of technological efficiency can make this much difference. And with what Vinod, and John Doerr and others, many of you here — there are a lot of people directly involved in this — this wedge is going to grow much more rapidly than the current projection shows it. Carbon Capture and Sequestration — that's what CCS stands for — is likely to become the killer app that will enable us to continue to use fossil fuels in a way that is safe. Not quite there yet. OK. Now, what can you do? Reduce emissions in your home. Most of these expenditures are also profitable. Insulation, better design. Buy green electricity where you can. I mentioned automobiles — buy a hybrid. Use light rail. Figure out some of the other options that are much better. It's important. Be a green consumer. You have choices with everything you buy, between things that have a harsh effect, or a much less harsh effect on the global climate crisis. Consider this: Make a decision to live a carbon-neutral life. Those of you who are good at branding, I'd love to get your advice and help on how to say this in a way that connects with the most people. It is easier than you think. It really is. A lot of us in here have made that decision, and it is really pretty easy. It means reduce your carbon dioxide emissions with the full range of choices that you make, and then purchase or acquire offsets for the remainder that you have not completely reduced. And what it means is elaborated at climatecrisis.net. There is a carbon calculator. Participant Productions convened — with my active involvement — the leading software writers in the world, on this arcane science of carbon calculation, to construct a consumer-friendly carbon calculator. You can very precisely calculate what your CO2 emissions are, and then you will be given options to reduce. And by the time the movie comes out in May, this will be updated to 2.0, and we will have click-through purchases of offsets. Next, consider making your business carbon-neutral. Again, some of us have done that, and it's not as hard as you think. Integrate climate solutions into all of your innovations, whether you are from the technology, or entertainment, or design and architecture community. Invest sustainably. Majora mentioned this. Listen, if you have invested money with managers who you compensate on the basis of their annual performance, don't ever again complain about quarterly report CEO management. Over time, people do what you pay them to do. And if they judge how much they're going to get paid on your capital that they've invested, based on the short-term returns, you're going to get short-term decisions. A lot more to be said about that. Become a catalyst of change. Teach others, learn about it, talk about it. The movie is a movie version of the slideshow I gave two nights ago, except it's a lot more entertaining. And it comes out in May. Many of you here have the opportunity to ensure that a lot of people see it. Consider sending somebody to Nashville. Pick well. And I am personally going to train people to give this slideshow — re-purposed, with some of the personal stories obviously replaced with a generic approach, and it's not just the slides, it's what they mean. And it's how they link together. And so I'm going to be conducting a course this summer for a group of people that are nominated by different folks to come and then give it en masse, in communities all across the country, and we're going to update the slideshow for all of them every single week, to keep it right on the cutting edge. Working with Larry Lessig, it will be, somewhere in that process, posted with tools and limited-use copyrights, so that young people can remix it and do it in their own way. (Applause) Where did anybody get the idea that you ought to stay arm's length from politics? It doesn't mean that if you're a Republican, that I'm trying to convince you to be a Democrat. We need Republicans as well. This used to be a bipartisan issue, and I know that in this group it really is. Become politically active. Make our democracy work the way it's supposed to work. Support the idea of capping carbon dioxide emissions — global warming pollution — and trading it. Here's why: as long as the United States is out of the world system, it's not a closed system. Once it becomes a closed system, with U.S. participation, then everybody who's on a board of directors — how many people here serve on the board of directors of a corporation? Once it's a closed system, you will have legal liability if you do not urge your CEO to get the maximum income from reducing and trading the carbon emissions that can be avoided. The market will work to solve this problem — if we can accomplish this. Help with the mass persuasion campaign that will start this spring. We have to change the minds of the American people. Because presently, the politicians do not have permission to do what needs to be done. And in our modern country, the role of logic and reason no longer includes mediating between wealth and power the way it once did. It's now repetition of short, hot-button, 30-second, 28-second television ads. We have to buy a lot of those ads. Let's re-brand global warming, as many of you have suggested. I like \"climate crisis\" instead of \"climate collapse,\" but again, those of you who are good at branding, I need your help on this. Somebody said the test we're facing now, a scientist told me, is whether the combination of an opposable thumb and a neocortex is a viable combination. (Laughter) That's really true. I said the other night, and I'll repeat now: this is not a political issue. Again, the Republicans here — this shouldn't be partisan. You have more influence than some of us who are Democrats do. This is an opportunity. Not just this, but connected to the ideas that are here, to bring more coherence to them. We are one. Thank you very much, I appreciate it. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "After decades of research and billions of dollars spent in clinical trials, we still have a problem with cancer drug delivery. We still give patients chemotherapy, which is so non-specific that even though it kills the cancer cells, it kind of kills the rest of your body, too. And yes, we have developed more selective drugs, but it's still a challenge to get them into the tumor, and they end up accumulating in the other organs as well or passing through your urine, which is a total waste. And fields like mine have emerged where we try to encapsulate these drugs to protect them as they travel through the body. But these modifications cause problems that we make more modifications to fix. So what I'm really trying to say is we need a better drug delivery system. And I propose, rather than using solely human design, why not use nature's? Immune cells are these versatile vehicles that travel throughout our body, patrolling for signs of disease and arriving at a wound mere minutes after injury. So I ask you guys: If immune cells are already traveling to places of injury or disease in our bodies, why not add an extra passenger? Why not use immune cells to deliver drugs to cure some of our biggest problems in disease? I am a biomedical engineer, and I want to tell you guys a story about how I use immune cells to target one of the largest problems in cancer. Did you know that over 90 percent of cancer deaths can be attributed to its spread? So if we can stop these cancer cells from going from the primary tumor to a distant site, we can stop cancer right in its tracks and give people more of their lives back. To do this special mission, we decided to deliver a nanoparticle made of lipids, which are the same materials that compose your cell membrane. And we've added two special molecules. One is called e-selectin, which acts as a glue that binds the nanoparticle to the immune cell. And the second one is called trail. Trail is a therapeutic drug that kills cancer cells but not normal cells. Now, when you put both of these together, you have a mean killing machine on wheels. To test this, we ran an experiment in a mouse. So what we did was we injected the nanoparticles, and they bound almost immediately to the immune cells in the bloodstream. And then we injected the cancer cells to mimic a process through which cancer cells spread throughout our bodies. And we found something very exciting. We found that in our treated group, over 75 percent of the cancer cells we initially injected were dead or dying, in comparison to only around 25 percent. So just imagine: these fewer amount of cells were available to actually be able to spread to a different part of the body. And this is only after two hours of treatment. Our results were amazing, and we had some pretty interesting press. My favorite title was actually, \"Sticky balls may stop the spread of cancer.\" (Laughter) I can't tell you just how smug my male colleagues were, knowing that their sticky balls might one day cure cancer. (Laughter) But I can tell you they made some pretty, pretty, exciting, pretty ballsy t-shirts. This was also my first experience talking to patients where they asked how soon our therapy would be available. And I keep these stories with me to remind me of the importance of the science, the scientists and the patients. Now, our fast-acting results were pretty interesting, but we still had one lingering question: Can our sticky balls, our particles actually attached to the immune cells, actually stop the spread of cancer? So we went to our animal model, and we found three important parts. Our primary tumors were smaller in our treated animals, there were fewer cells in circulation, and there was little to no tumor burden in the distant organs. Now, this wasn't just a victory for us and our sticky balls. This was also a victory to me in drug delivery, and it represents a paradigm shift, a revolution — to go from just using drugs, just injecting them and hoping they go to the right places in the body, to using immune cells as special delivery drivers in your body. For this example, we used two molecules, e-selectin and trail, but really, the possibility of drugs you can use are endless. And I talked about cancer, but where disease goes, so do immune cells. So this could be used for any disease. Imagine using immune cells to deliver crucial wound-healing agents after a spinal cord injury, or using immune cells to deliver drugs past the blood-brain barrier to treat Parkinson's or Alzheimer's disease. These are the ideas that excite me about science the most. And from where I stand, I see so much promise and opportunity. Thank you. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
       "Why bother? The game is rigged. My vote won't count. The choices are terrible. Voting is for suckers. Perhaps you've thought some of these things. Perhaps you've even said them. And if so, you wouldn't be alone, and you wouldn't be entirely wrong. The game of public policy today is rigged in many ways. How else would more than half of federal tax breaks flow up to the wealthiest five percent of Americans? And our choices indeed are often terrible. For many people across the political spectrum, Exhibit A is the 2016 presidential election. But in any year, you can look up and down the ballot and find plenty to be uninspired about. But in spite of all this, I still believe voting matters. And crazy as it may sound, I believe we can revive the joy of voting. Today, I want to talk about how we can do that, and why. There used to be a time in American history when voting was fun, when it was much more than just a grim duty to show up at the polls. That time is called \"most of American history.\" (Laughter) From the Revolution to the Civil Rights Era, the United States had a vibrant, robustly participatory and raucous culture of voting. It was street theater, open-air debates, fasting and feasting and toasting, parades and bonfires. During the 19th century, immigrants and urban political machines helped fuel this culture of voting. That culture grew with each successive wave of new voters. During Reconstruction, when new African-American voters, new African-American citizens, began to exercise their power, they celebrated in jubilee parades that connected emancipation with their newfound right to vote. A few decades later, the suffragettes brought a spirit of theatricality to their fight, marching together in white dresses as they claimed the franchise. And the Civil Rights Movement, which sought to redeem the promise of equal citizenship that had been betrayed by Jim Crow, put voting right at the center. From Freedom Summer to the march in Selma, that generation of activists knew that voting matters, and they knew that spectacle and the performance of power is key to actually claiming power. But it's been over a half century since Selma and the Voting Rights Act, and in the decades since, this face-to-face culture of voting has just about disappeared. It's been killed by television and then the internet. The couch has replaced the commons. Screens have made citizens into spectators. And while it's nice to share political memes on social media, that's a rather quiet kind of citizenship. It's what the sociologist Sherry Turkle calls \"being alone together.\" What we need today is an electoral culture that is about being together together, in person, in loud and passionate ways, so that instead of being \"eat your vegetables\" or \"do you duty,\" voting can feel more like \"join the club\" or, better yet, \"join the party.\" Imagine if we had, across the country right now, in local places but nationwide, a concerted effort to revive a face-to-face set of ways to engage and electioneer: outdoor shows in which candidates and their causes are mocked and praised in broad satirical style; soapbox speeches by citizens; public debates held inside pubs; streets filled with political art and handmade posters and murals; battle of the band concerts in which competing performers rep their candidates. Now, all of this may sound a little bit 18th century to you, but in fact, it doesn't have to be any more 18th century than, say, Broadway's \"Hamilton,\" which is to say vibrantly contemporary. And the fact is that all around the world, today, millions of people are voting like this. In India, elections are colorful, communal affairs. In Brazil, election day is a festive, carnival-type atmosphere. In Taiwan and Hong Kong, there is a spectacle, eye-popping, eye-grabbing spectacle to the street theater of elections. You might ask, well, here in America, who has time for this? And I would tell you that the average American watches five hours of television a day. You might ask, who has the motivation? And I'll tell you, any citizen who wants to be seen and heard not as a prop, not as a talking point, but as a participant, as a creator. Well, how do we make this happen? Simply by making it happen. That's why a group of colleagues and I launched a new project called \"The Joy of Voting.\" In four cities across the United States — Philadelphia, Miami, Akron, Ohio, and Wichita, Kansas — we've gathered together artists and activists, educators, political folks, neighbors, everyday citizens to come together and create projects that can foster this culture of voting in a local way. In Miami, that means all-night parties with hot DJs where the only way to get in is to show that you're registered to vote. In Akron, it means political plays being performed in the bed of a flatbed truck that moves from neighborhood to neighborhood. In Philadelphia, it's a voting-themed scavenger hunt all throughout colonial old town. And in Wichita, it's making mixtapes and live graffiti art in the North End to get out the vote. There are 20 of these projects, and they are remarkable in their beauty and their diversity, and they are changing people. Let me tell you about a couple of them. In Miami, we've commissioned and artist, a young artist named Atomico, to create some vivid and vibrant images for a new series of \"I voted\" stickers. But the thing is, Atomico had never voted. He wasn't even registered. So as he got to work on creating this artwork for these stickers, he also began to get over his sense of intimidation about politics. He got himself registered, and then he got educated about the upcoming primary election, and on election day he was out there not just passing out stickers, but chatting up voters and encouraging people to vote, and talking about the election with passersby. In Akron, a theater company called the Wandering Aesthetics has been putting on these pickup truck plays. And to do so, they put out an open call to the public asking for speeches, monologues, dialogues, poems, snippets of anything that could be read aloud and woven into a performance. They got dozens of submissions. One of them was a poem written by nine students in an ESL class, all of them Hispanic migrant workers from nearby Hartville, Ohio. I want to read to you from this poem. It's called \"The Joy of Voting.\" \"I would like to vote for the first time because things are changing for Hispanics. I used to be afraid of ghosts. Now I am afraid of people. There's more violence and racism. Voting can change this. The border wall is nothing. It's just a wall. The wall of shame is something. It's very important to vote so we can break down this wall of shame. I have passion in my heart. Voting gives me a voice and power. I can stand up and do something.\" \"The Joy of Voting\" project isn't just about joy. It's about this passion. It's about feeling and belief, and it isn't just our organization's work. All across this country right now, immigrants, young people, veterans, people of all different backgrounds are coming together to create this kind of passionate, joyful activity around elections, in red and blue states, in urban and rural communities, people of every political background. What they have in common is simply this: their work is rooted in place. Because remember, all citizenship is local. When politics becomes just a presidential election, we yell and we scream at our screens, and then we collapse, exhausted. But when politics is about us and our neighbors and other people in our community coming together to create experiences of collective voice and imagination, then we begin to remember that this stuff matters. We begin to remember that this is the stuff of self-government. Which brings me back to where I began. Why bother? There's one way to answer this question. Voting matters because it is a self-fulfilling act of belief. It feeds the spirit of mutual interest that makes any society thrive. When we vote, even if it is in anger, we are part of a collective, creative leap of faith. Voting helps us generate the very power that we wish we had. It's no accident that democracy and theater emerged around the same time in ancient Athens. Both of them yank the individual out of the enclosure of her private self. Both of them create great public experiences of shared ritual. Both of them bring the imagination to life in ways that remind us that all of our bonds in the end are imagined, and can be reimagined. This moment right now, when we think about the meaning of imagination, is so fundamentally important, and our ability to take that spirit and to take that sense that there is something greater out there, is not just a matter of technical expertise. It's not just a matter of making the time or having the know-how. It is a matter of spirit. But let me give you an answer to this question, \"Why bother?\" that is maybe a little less spiritual and a bit more pointed. Why bother voting? Because there is no such thing as not voting. Not voting is voting, for everything that you may detest and oppose. Not voting can be dressed up as an act of principled, passive resistance, but in fact not voting is actively handing power over to those whose interests are counter to your own, and those who would be very glad to take advantage of your absence. Not voting is for suckers. Imagine where this country would be if all the folks who in 2010 created the Tea Party had decided that, you know, politics is too messy, voting is too complicated. There is no possibility of our votes adding up to anything. They didn't preemptively silence themselves. They showed up, and in the course of showing up, they changed American politics. Imagine if all of the followers of Donald Trump and Bernie Sanders had decided not to upend the political status quo and blow apart the frame of the previously possible in American politics. They did that by voting. We live in a time right now, divided, often very dark, where across the left and the right, there's a lot of talk of revolution and the need for revolution to disrupt everyday democracy. Well, here's the thing: everyday democracy already gives us a playbook for revolution. In the 2012 presidential election, young voters, Latino voters, Asian-American voters, low-income voters, all showed up at less than 50 percent. In the 2014 midterm elections, turnout was 36 percent, which was a 70-year low. And in your average local election, turnout hovers somewhere around 20 percent. I invite you to imagine 100 percent. Picture 100 percent. Mobilize 100 percent, and overnight, we get revolution. Overnight, the policy priorities of this country change dramatically, and every level of government becomes radically more responsive to all the people. What would it take to mobilize 100 percent? Well, we do have to push back against efforts afoot all across the country right now to make voting harder. But at the same time, we have to actively create a positive culture of voting that people want to belong to, be part of, and experience together. We have to make purpose. We have to make joy. So yes, let's have that revolution, a revolution of spirit, of ideas, of policy and participation, a revolution against cynicism, a revolution against the self-fulfilling sense of powerlessness. Let's vote this revolution into existence, and while we're at it, let's have some fun. Thank you very much. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "How much do you get paid? Don't answer that out loud. But put a number in your head. Now: How much do you think the person sitting next to you gets paid? Again, don't answer out loud. (Laughter) At work, how much do you think the person sitting in the cubicle or the desk next to you gets paid? Do you know? Should you know? Notice, it's a little uncomfortable for me to even ask you those questions. But admit it — you kind of want to know. Most of us are uncomfortable with the idea of broadcasting our salary. We're not supposed to tell our neighbors, and we're definitely not supposed to tell our office neighbors. The assumed reason is that if everybody knew what everybody got paid, then all hell would break loose. There'd be arguments, there'd be fights, there might even be a few people who quit. But what if secrecy is actually the reason for all that strife? And what would happen if we removed that secrecy? What if openness actually increased the sense of fairness and collaboration inside a company? What would happen if we had total pay transparency? For the past several years, I've been studying the corporate and entrepreneurial leaders who question the conventional wisdom about how to run a company. And the question of pay keeps coming up. And the answers keep surprising. It turns out that pay transparency — sharing salaries openly across a company — makes for a better workplace for both the employee and for the organization. When people don't know how their pay compares to their peers', they're more likely to feel underpaid and maybe even discriminated against. Do you want to work at a place that tolerates the idea that you feel underpaid or discriminated against? But keeping salaries secret does exactly that, and it's a practice as old as it is common, despite the fact that in the United States, the law protects an employee's right to discuss their pay. In one famous example from decades ago, the management of Vanity Fair magazine actually circulated a memo entitled: \"Forbidding Discussion Among Employees of Salary Received.\" \"Forbidding\" discussion among employees of salary received. Now that memo didn't sit well with everybody. New York literary figures Dorothy Parker, Robert Benchley and Robert Sherwood, all writers in the Algonquin Round Table, decided to stand up for transparency and showed up for work the next day with their salary written on signs hanging from their neck. (Laughter) Imagine showing up for work with your salary just written across your chest for all to see. But why would a company even want to discourage salary discussions? Why do some people go along with it, while others revolt against it? It turns out that in addition to the assumed reasons, pay secrecy is actually a way to save a lot of money. You see, keeping salaries secret leads to what economists call \"information asymmetry.\" This is a situation where, in a negotiation, one party has loads more information than the other. And in hiring or promotion or annual raise discussions, an employer can use that secrecy to save a lot of money. Imagine how much better you could negotiate for a raise if you knew everybody's salary. Economists warn that information asymmetry can cause markets to go awry. Someone leaves a pay stub on the copier, and suddenly everybody is shouting at each other. In fact, they even warn that information asymmetry can lead to a total market failure. And I think we're almost there. Here's why: first, most employees have no idea how their pay compares to their peers'. In a 2015 survey of 70,000 employees, two-thirds of everyone who is paid at the market rate said that they felt they were underpaid. And of everybody who felt that they were underpaid, 60 percent said that they intended to quit, regardless of where they were — underpaid, overpaid or right at the market rate. If you were part of this survey, what would you say? Are you underpaid? Well, wait — how do you even know, because you're not allowed to talk about it? Next, information asymmetry, pay secrecy, makes it easier to ignore the discrimination that's already present in the market today. In a 2011 report from the Institute for Women's Policy Research, the gender wage gap between men and women was 23 percent. This is where that 77 cents on the dollar comes from. But in the Federal Government, where salaries are pinned to certain levels and everybody knows what those levels are, the gender wage gap shrinks to 11 percent — and this is before controlling for any of the factors that economists argue over whether or not to control for. If we really want to close the gender wage gap, maybe we should start by opening up the payroll. If this is what total market failure looks like, then openness remains the only way to ensure fairness. Now, I realize that letting people know what you make might feel uncomfortable, but isn't it less uncomfortable than always wondering if you're being discriminated against, or if your wife or your daughter or your sister is being paid unfairly? Openness remains the best way to ensure fairness, and pay transparency does that. That's why entrepreneurial leaders and corporate leaders have been experimenting with sharing salaries for years. Like Dane Atkinson. Dane is a serial entrepreneur who started many companies in a pay secrecy condition and even used that condition to pay two equally qualified people dramatically different salaries, depending on how well they could negotiate. And Dane saw the strife that happened as a result of this. So when he started his newest company, SumAll, he committed to salary transparency from the beginning. And the results have been amazing. And in study after study, when people know how they're being paid and how that pay compares to their peers', they're more likely to work hard to improve their performance, more likely to be engaged, and they're less likely to quit. That's why Dane's not alone. From technology start-ups like Buffer, to the tens of thousands of employees at Whole Foods, where not only is your salary available for everyone to see, but the performance data for the store and for your department is available on the company intranet for all to see. Now, pay transparency takes a lot of forms. It's not one size fits all. Some post their salaries for all to see. Some only keep it inside the company. Some post the formula for calculating pay, and others post the pay levels and affix everybody to that level. So you don't have to make signs for all of your employees to wear around the office. And you don't have to be the only one wearing a sign that you made at home. But we can all take greater steps towards pay transparency. For those of you that have the authority to move forward towards transparency: it's time to move forward. And for those of you that don't have that authority: it's time to stand up for your right to. So how much do you get paid? And how does that compare to the people you work with? You should know. And so should they. Thank you. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "When I opened Mott Hall Bridges Academy in 2010, my goal was simple: open a school to close a prison. Now to some, this was an audacious goal, because our school is located in the Brownsville section of Brooklyn — one of the most underserved and violent neighborhoods in all of New York City. Like many urban schools with high poverty rates, we face numerous challenges, like finding teachers who can empathize with the complexities of a disadvantaged community, lack of funding for technology, low parental involvement and neighborhood gangs that recruit children as early as fourth grade. So here I was, the founding principal of a middle school that was a district public school, and I only had 45 kids to start. Thirty percent of them had special needs. Eighty-six percent of them were below grade level in English and in math. And 100 percent were living below the poverty level. If our children are not in our classrooms, how will they learn? And if they're not learning, where would they end up? It was evident when I would ask my 13-year-old, \"Young man, where do you see yourself in five years?\" And his response: \"I don't know if I'm gonna live that long.\" Or to have a young woman say to me that she had a lifelong goal of working in a fast-food restaurant. To me, this was unacceptable. It was also evident that they had no idea that there was a landscape of opportunity that existed beyond their neighborhood. We call our students \"scholars,\" because they're lifelong learners. And the skills that they learn today will prepare them for college and career readiness. I chose the royal colors of purple and black, because I want them to be reminded that they are descendants of greatness, and that through education, they are future engineers, scientists, entrepreneurs and even leaders who can and will take over this world. To date, we have had three graduating classes, at a 98 — (Applause) At a 98-percent graduation rate. This is nearly 200 children, who are now going to some of the most competitive high schools in New York City. (Applause) It was a cold day in January when my scholar, Vidal Chastanet, met Brandon Stanton, the founder of the popular blog \"Humans of New York.\" Brandon shared the story of a young man from Brownsville who had witnessed violence firsthand, by witnessing a man being thrown off of a roof. Yet he can still be influenced by a principal who had opened up a school that believes in all children. Vidal embodies the story of so many of our underprivileged children who are struggling to survive, which is why we must make education a priority. Brandon's post created a global sensation that touched the lives of millions. This resulted in 1.4 million dollars being raised for our scholars to attend field trips to colleges and universities, Summer STEAM programs, as well as college scholarships. You need to understand that when 200 young people from Brownsville visited Harvard, they now understood that a college of their choice was a real possibility. And the impossibilities that had been imposed upon them by a disadvantaged community were replaced by hope and purpose. The revolution in education is happening in our schools, with adults who provide love, structure, support and knowledge. These are the things that inspire children. But it is not an easy task. And there are high demands within an education system that is not perfect. But I have a dynamic group of educators who collaborate as a team to determine what is the best curriculum. They take time beyond their school day, and come in on weekends and even use their own money to often provide resources when we do not have it. And as the principal, I have to inspect what I expect. So I show up in classes and I conduct observations to give feedback, because I want my teachers to be just as successful as the name Mott Hall Bridges Academy. And I give them access to me every single day, which is why they all have my personal cell number, including my scholars and those who graduated — which is probably why I get phone calls and text messages at three o'clock in the morning. (Laughter) But we are all connected to succeed, and good leaders do this. Tomorrow's future is sitting in our classrooms. And they are our responsibility. That means everyone in here, and those who are watching the screen. We must believe in their brilliance, and remind them by teaching them that there indeed is power in education. Thank you. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
       "Today I'm going to talk about unexpected discoveries. Now I work in the solar technology industry. And my small startup is looking to force ourselves into the environment by paying attention to ... ... paying attention to crowd-sourcing. It's just a quick video of what we do. Huh. Hang on a moment. It might take a moment to load. (Laughter) We'll just — we can just skip — I'll just skip through the video instead ... (Laughter) No. (Laughter) (Laughter) (Music) This is not ... (Laughter) Okay. (Laughter) Solar technology is ... Oh, that's all my time? Okay. Thank you very much. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
       "I'm Kelli Anderson. I work as an artist and designer. And I like to try to find the hidden talents of everyday things. So before I get started, I want to show you a fast smattering of some examples of what I do. But this talk today is really less about what I make and is more about why I make these things. So, I get to tinker with everyday experiences. As we go through our everyday lives, visual and experiential things exert this invisible authority over our brains at all times. And they yield this power in subtle and sneaky ways. So visuals, for example, speak volumes through these teeny, tiny details, codified in things like type, shape, color and texture. So these small, picky things form the vocabulary that come together and make the sentences, enabling us to make tangible things like ... a solar-powered Popsicle truck. (Laughter) It educates the public about renewable energy. It's basically a physical infographic on wheels. And this unexpected pairing of sugar, bright colors and the threat of humanity's self-inflicted demise actually makes for a pretty convincing argument for solar. People arrive at experiences like these with expectations. And when we make things, we're actively choosing what to do with those expectations. In my work, I want to create disruptive wonder. I want to confound these expectations, because I think that every day, fundamental things and experiences frame reality in a way that we often take for granted. The small things we make can work to reinforce our assumptions about the world. Or small things can come out of left field and draw us into reassessing our complacent expectations about reality. This doesn't happen often, but when it does, it's awesome. Because then, these small things act as sort of a humble back door into understanding a reality that's infinitely surprising. So, as a little demonstration, back to the most basic and fundamental part of myself again: my name, kellianderson.com, spelled out in block letters. This is how people find me in the world. It means me. But in a more objective sense, it's really just this random jumble of letters that I've confined to the single possibility of making my name. So naturally, I wondered: What else can these letters spell? Turns out, all kinds of interesting phrases, like ... \"Ken doll is near dot com.\" (Laughter) A little bit creepy. And \"A colder melon skin.\" Period. (Laughter) Far better use of those kellianderson.com letters, I'm sure you'll agree. This is a dumb game, but it underscores a belief I have, that the world is full of order that doesn't necessarily deserve our respect. Sometimes, there's meaning, justice and logic present in the way things are. But sometimes there just isn't. I think that the moment we realize this is the moment we become creative people, because it prompts us to mess things up and do something better with the basic pieces of experience. What I'm after in my work, really, is this: the hidden talents of everyday things — all of those overlooked powers bestowed on the things that surround us by the wonders of physics, the complexities of cultural associations and a gazillion other only partially chartable things. So today, I want to show you three projects that reconsider the vast properties of commonplace experience and try to do something better by doing something more absurd. This first project is a holiday card I made for my friends. My goal in this was to get people to notice this going-through-the-motions holiday thing that I'm sure we've all felt before. And I did that through a holiday card, of course. From the outside, it looks pretty normal. But paper has this memory; paper never forgets how it was bent. I was able to use that material memory to guide the recipient through the experience of the card. So when you first pick it up, while floppy, it's clear it wants to bend in all of these certain ways. As people tinker with it, they discover that bending the card brings them through this simple story. And as you can see, it's a story about itself. (Laughter) This card is literally a four-frame documentary about receiving the card. (Laughter) So it's a recursive experience. (Applause) Oh, well, thank you. This excites me, because it's a recursive experience of a holiday card that gets the viewer to feel this repetitive ritual of all holiday cards. And it begins life as a humble piece of paper that came out of my inkjet printer. I think that's pretty cool. In a sense, that project was all about ritual becoming empty gesture. And it speaks to the fact that the more an experience repeats itself, the less it means — (Laughter) because we begin to take it for granted. And that's why cliches aren't interesting, and why people get in car wrecks near their homes. When we experience things over and over again, they just lose their gravity. So while paper does have all of these astonishing, overlooked capabilities, it takes a hell of a lot of intervention into getting us to see it as new again. This next project I want to show you is a wedding invitation, which is a format practically begging for reinvention. (Laughter) This is a card I made for my friends Mike and Karen, who happen to be really awesome people. Far more awesome, in fact, than the format of wedding invitations. So it was a really good excuse to push the boundaries of this format. And as far as how to push it, the facts of our shared history made it clear that this card should be about music. We're all total music nerds, and Karen and Mike have even recorded songs together. But you know, you also find inspiration in the darnedest of places. And we found some with this guy, Mr. Wizard — (Laughter) who had a much-beloved TV show, teaching kids about the science behind everyday things. And I remembered this episode that demonstrated sound is physical, with this simple experiment. He rolled up a cone of paper, he taped it shut, he taped a needle to the end of it, and — voilà! — it was a record player. I remember seeing this as a kid, and it totally blew my mind. If you can make a record player out of a piece of paper and a sewing needle, what isn't possible out of the world? So I explained this idea to Mike and Karen, and we all decided that it would be way better to make their guests paper record players, rather than traditional, boring invitations. We started getting really, really excited. And I started getting really nervous, because I'm the one who had to actually make it work. So I began spending an inordinate amount of time thinking about needles: Like, would we find needles with the right fidelity? I started calling paper suppliers, looking for the paper with the best audio properties. (Laughter) And they thought I was crazy. Meanwhile, Mike and Karen were recording a song, which they had mastered to a clear flexi disc. I had this black-and-white character printed on it, so that way, when the disc is turned, it completes the couple in all of these different guises. (Laughter) So we did it, we really did it! We made a paper record player — 200 recipient-operated paper record players. This is an actual recording of how it sounds. And then it segues into the real song for comparison. (Music and singing) (Music ends) We were so excited when we finally got that to work. (Laughter) And I was excited that we uncovered this hidden talent of paper in the process. I also love that project because it brings attention to the fact that we approach media with all these expectations that we do not necessarily need. We have assumptions about material experience, like that paper should be silent or that websites should be flat. But we also have these assumptions — (Laughter) that should be a lot scarier in a democracy, because they're like these little thought loopholes. We sleepwalk through our assumptions about the authority in media and assumptions put forth about political realities by media, like newspapers. But I, for one, have faith in these small, hacked experiences to inspire a sense of skepticism at this limited reality we've been handed. And this next project demonstrates just that. Imagine your normal, everyday commuter-newspaper-reading ritual. But what if you are handed a paper filled with stories from an alternate reality? (Laughter) Specifically: What if some crazy person had meticulously recreated a typical paper depicting an alternate reality? This is something we actually did do in the fall of 2008, in a project that was conceptualized by artist Steve Lambert, organized by The Yes Men and executed by many, many people, some of whom are me. We made a perfectly counterfeited \"New York Times.\" We didn't ask anyone for permission, we just did it. (Laughter) We had it mass-produced, and we put it in the hands of hundreds of thousands of commuters on a Thursday morning in New York City. (Laughter) (Applause and cheers) Thanks! (Applause) \"Why?,\" you might ask. \"Why make a fake newspaper?\" Well, quite frankly, because the real newspaper is depressing. We ostensibly live in a democracy where we should have some say in what happens in the world. But the truth is, we never see the stories we want to see in the newspaper. So we made a paper with only good news. (Laughter) We put in all the policy ideas we thought would actually help the world. Years before the withdrawal was even discussed, we ended the war in Iraq. Years before Occupy Wall Street, we put in a maximum wage law — (Laughter) to end the ginormous wage inequities between the lowest and highest income earners. We returned civics class to high school curriculum. (Laughter) See? These are good ideas! So then students would know how their government works again. There's a very important difference between these two papers. (Laughter) While the real \"New York Times\" has this slogan of, \"All the News that's Fit to Print,\" we offered a more forward-thinking message of, \"All the News We Hope to Print.\" (Laughter) And that's because our paper is postdated six months into the future, so when people are handed these on the street, they were literally getting an artifact from the utopian future, sort of a blueprint for an attainably utopian future brought about by this very important idea of popular pressure. And our hoax worked perfectly. We suspended people in this strange mental space, because while the stories in the paper couldn't be real, it just felt so perfectly, impeccably real. Here's a video showing — (Laughter) yes, we did that! — showing the first few seconds of conflicted belief, where people could feel for a moment what — (Laughter) Yes! (Laughter) This guy's good. (Laughter) But in order to get this type of reaction, our paper had to be radically believable. And Daniel Dunnam, my other half, and I formed the believability team. He made sure that the typography, the layout, the smell of the ink — everything — was just like a real \"New York Times.\" And I supplied fake advertisements from the utopian future. (Laughter) We decided that the utopian future would be a perfect venue to help these companies who had done wrong in the past try making amends for that wrongdoing. (Laughter) And we do this through the vocabulary of their own advertising. So for Ikea, what if instead of cheap furniture, you could buy your own wind farm? It comes flat-packed, clearly easy to assemble — (Laughter) with that little zigzag tool and the wooden pegs. That would be awesome, right? More nefarious are companies like De Beers, who are making amends for their sale of blood diamonds by donating prosthetics to war-torn African countries. And this is our take on a used car dealership ad. They're now offering a \"cash for polluters\" program. So now you can trade in your car for a non-polluting type of transportation: a bicycle! (Laughter) And here's my favorite, Dr. Zizmor, who is giving you a beautiful, clear conscience. If you haven't taken a ride on the New York City subway, you may not know Dr. Z. But if you have, then you do, because his cheesy rainbow ads are everywhere. But now he is foregoing these superficial services. He's no longer cleaning up your face, now he's cleaning up our mess in Iraq. (Laughter) So the news of our fake paper made it onto the real news all around the world. These unexpected messages of hope were able to get out there through our sheer brazenness in ripping off the \"New York Times,\" but also because we leveraged this pathway that no one had expected. We pushed our paper beyond its expected role in reporting the news, and we made a blueprint for a better world. With those three projects, I demonstrate that by rejecting normal order, by messing things up and by rearranging the pieces, we can expand our notion of what we demand from reality. So today, I want to put forth this idea that an avenue to better is through a million teeny, tiny disruptions to whatever is sitting in front of you. So go mess with the complacently rational. And you can see more of my work at: I'll snore naked dot com. (Laughter) Thank you. (Applause)    1\n",
       "I want to discuss with you this afternoon why you're going to fail to have a great career. (Laughter) I'm an economist. I do dismal. End of the day, it's ready for dismal remarks. I only want to talk to those of you who want a great career. I know some of you have already decided you want a good career. You're going to fail, too. (Laughter) Because — goodness, you're all cheery about failing. (Laughter) Canadian group, undoubtedly. (Laughter) Those trying to have good careers are going to fail, because, really, good jobs are now disappearing. There are great jobs and great careers, and then there are the high-workload, high-stress, bloodsucking, soul-destroying kinds of jobs, and practically nothing in-between. So people looking for good jobs are going to fail. I want to talk about those looking for great jobs, great careers, and why you're going to fail. First reason is that no matter how many times people tell you, \"If you want a great career, you have to pursue your passion, you have to pursue your dreams, you have to pursue the greatest fascination in your life,\" you hear it again and again, and then you decide not to do it. It doesn't matter how many times you download Steven J.'s Stanford commencement address, you still look at it and decide not to do it. I'm not quite sure why you decide not to do it. You're too lazy to do it. It's too hard. You're afraid if you look for your passion and don't find it, you'll feel like you're an idiot, so then you make excuses about why you're not going to look for your passion. They are excuses, ladies and gentlemen. We're going to go through a whole long list — your creativity in thinking of excuses not to do what you really need to do if you want to have a great career. So, for example, one of your great excuses is: (Sigh) \"Well, great careers are really and truly, for most people, just a matter of luck. So I'm going to stand around, I'm going to try to be lucky, and if I'm lucky, I'll have a great career. If not, I'll have a good career.\" But a good career is an impossibility, so that's not going to work. Then, your other excuse is, \"Yes, there are special people who pursue their passions, but they are geniuses. They are Steven J. I'm not a genius. When I was five, I thought I was a genius, but my professors have beaten that idea out of my head long since.\" (Laughter) \"And now I know I am completely competent.\" Now, you see, if this was 1950, being completely competent — that would have given you a great career. But guess what? This is almost 2012, and saying to the world, \"I am totally, completely competent,\" is damning yourself with the faintest of praise. And then, of course, another excuse: \"Well, I would do this, I would do this, but, but — well, after all, I'm not weird. Everybody knows that people who pursue their passions are somewhat obsessive. A little strange. Hmm? Hmm? Okay? You know, a fine line between madness and genius. \"I'm not weird. I've read Steven J.'s biography. Oh my goodness — I'm not that person. I am nice. I am normal. I'm a nice, normal person, and nice, normal people — don't have passion.\" (Laughter) \"Ah, but I still want a great career. I'm not prepared to pursue my passion, so I know what I'm going to do, because I have a solution. I have a strategy. It's the one Mommy and Daddy told me about. Mommy and Daddy told me that if I worked hard, I'd have a good career. So, if you work hard and have a good career, if you work really, really, really hard, you'll have a great career. Doesn't that, like, mathematically make sense?\" Hmm. Not. But you've managed to talk yourself into that. You know what? Here's a little secret: You want to work? You want to work really, really, really hard? You know what? You'll succeed. The world will give you the opportunity to work really, really, really, really hard. But, are you so sure that that's going to give you a great career, when all the evidence is to the contrary? So let's deal with those of you who are trying to find your passion. You actually understand that you really had better do it, never mind the excuses. You're trying to find your passion — (Sigh) and you're so happy. You found something you're interested in. \"I have an interest! I have an interest!\" You tell me. You say, \"I have an interest!\" I say, \"That's wonderful! And what are you trying to tell me?\" \"Well, I have an interest.\" I say, \"Do you have passion?\" \"I have an interest,\" you say. \"Your interest is compared to what?\" \"Well, I'm interested in this.\" \"And what about the rest of humanity's activities?\" \"I'm not interested in them.\" \"You've looked at them all, have you?\" \"No. Not exactly.\" Passion is your greatest love. Passion is the thing that will help you create the highest expression of your talent. Passion, interest — it's not the same thing. Are you really going to go to your sweetie and say, \"Marry me! You're interesting.\" (Laughter) Won't happen. Won't happen, and you will die alone. (Laughter) What you want, what you want, what you want, is passion. It is beyond interest. You need 20 interests, and then one of them, one of them might grab you, one of them might engage you more than anything else, and then you may have found your greatest love, in comparison to all the other things that interest you, and that's what passion is. I have a friend, proposed to his sweetie. He was an economically rational person. He said to his sweetie, \"Let us marry. Let us merge our interests.\" (Laughter) Yes, he did. \"I love you truly,\" he said. \"I love you deeply. I love you more than any other woman I've ever encountered. I love you more than Mary, Jane, Susie, Penelope, Ingrid, Gertrude, Gretel — I was on a German exchange program then. I love you more than —\" All right. She left the room halfway through his enumeration of his love for her. After he got over his surprise at being, you know, turned down, he concluded he'd had a narrow escape from marrying an irrational person. Although, he did make a note to himself that the next time he proposed, it was perhaps not necessary to enumerate all of the women he had auditioned for the part. (Laughter) But the point stands. You must look for alternatives so that you find your destiny, or are you afraid of the word \"destiny\"? Does the word \"destiny\" scare you? That's what we're talking about. And if you don't find the highest expression of your talent, if you settle for \"interesting,\" what the hell ever that means, do you know what will happen at the end of your long life? Your friends and family will be gathered in the cemetery, and there beside your gravesite will be a tombstone, and inscribed on that tombstone it will say, \"Here lies a distinguished engineer, who invented Velcro.\" But what that tombstone should have said, in an alternative lifetime, what it should have said if it was your highest expression of talent, was, \"Here lies the last Nobel Laureate in Physics, who formulated the Grand Unified Field Theory and demonstrated the practicality of warp drive.\" (Laughter) Velcro, indeed! (Laughter) One was a great career. One was a missed opportunity. But then, there are some of you who, in spite of all these excuses, you will find, you will find your passion. And you'll still fail. You're going to fail, because — because you're not going to do it, because you will have invented a new excuse, any excuse to fail to take action, and this excuse, I've heard so many times: \"Yes, I would pursue a great career, but, I value human relationships — (Laughter) more than accomplishment. I want to be a great friend. I want to be a great spouse. I want to be a great parent, and I will not sacrifice them on the altar of great accomplishment.\" (Laughter) What do you want me to say? Now, do you really want me to say now, tell you, \"Really, I swear I don't kick children.\" (Laughter) Look at the worldview you've given yourself. You're a hero no matter what. And I, by suggesting ever so delicately that you might want a great career, must hate children. I don't hate children. I don't kick them. Yes, there was a little kid wandering through this building when I came here, and no, I didn't kick him. (Laughter) Course, I had to tell him the building was for adults only, and to get out. He mumbled something about his mother, and I told him she'd probably find him outside anyway. Last time I saw him, he was on the stairs crying. (Laughter) What a wimp. (Laughter) But what do you mean? That's what you expect me to say. Do you really think it's appropriate that you should actually take children and use them as a shield? You know what will happen someday, you ideal parent, you? The kid will come to you someday and say, \"I know what I want to be. I know what I'm going to do with my life.\" You are so happy. It's the conversation a parent wants to hear, because your kid's good in math, and you know you're going to like what comes next. Says your kid, \"I have decided I want to be a magician. I want to perform magic tricks on the stage.\" (Laughter) And what do you say? You say, you say, \"That's risky, kid. Might fail, kid. Don't make a lot of money at that, kid. I don't know, kid, you should think about that again, kid. You're so good at math, why don't you —\" The kid interrupts you and says, \"But it is my dream. It is my dream to do this.\" And what are you going to say? You know what you're going to say? \"Look kid. I had a dream once, too, but — But —\" So how are you going to finish the sentence with your \"but\"? \"But. I had a dream too, once, kid, but I was afraid to pursue it.\" Or are you going to tell him this: \"I had a dream once, kid. But then, you were born.\" (Laughter) (Applause) Do you really want to use your family, do you really ever want to look at your spouse and your kid, and see your jailers? There was something you could have said to your kid, when he or she said, \"I have a dream.\" You could have said — looked the kid in the face and said, \"Go for it, kid! Just like I did.\" But you won't be able to say that, because you didn't. So you can't. (Laughter) And so the sins of the parents are visited on the poor children. Why will you seek refuge in human relationships as your excuse not to find and pursue your passion? You know why. In your heart of hearts, you know why, and I'm being deadly serious. You know why you would get all warm and fuzzy and wrap yourself up in human relationships. It is because you are — you know what you are. You're afraid to pursue your passion. You're afraid to look ridiculous. You're afraid to try. You're afraid you may fail. Great friend, great spouse, great parent, great career. Is that not a package? Is that not who you are? How can you be one without the other? But you're afraid. And that's why you're not going to have a great career. Unless — \"unless,\" that most evocative of all English words — \"unless.\" But the \"unless\" word is also attached to that other, most terrifying phrase, \"If only I had ...\" \"If only I had ...\" If you ever have that thought ricocheting in your brain, it will hurt a lot. So, those are the many reasons why you are going to fail to have a great career. Unless — Unless. Thank you. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
       "When you think about the brain, it's difficult to understand, because if I were to ask you right now, how does the heart work, you would instantly tell me it's a pump. It pumps blood. If I were to ask about your lungs, you would say it exchanges oxygen for carbon dioxide. That's easy. If I were to ask you how the brain works, it's hard to understand because you can't just look at a brain and understand what it is. It's not a mechanical object, not a pump, not an airbag. It's just like, if you held it in your hand when it was dead, it's just a piece of fat. To understand how the brain works, you have to go inside a living brain. Because the brain's not mechanical, the brain is electrical and it's chemical. Your brain is made out of 100 billion cells, called neurons. And these neurons communicate with each other with electricity. And we're going to eavesdrop in on a conversation between two cells, and we're going to listen to something called a spike. But we're not going to record my brain or your brain or your teachers' brains, we're going to use our good friend the cockroach. Not just because I think they're cool, but because they have brains very similar to ours. So if you learn a little bit about how their brains work, we're going to learn a lot about how our brains work. I'm going to put them in some ice water here And then — Audience: Ew! Greg Gabe: Yeah ... Right now they're becoming anesthetized. Because they're cold blooded, they become the temperature of the water and they can't control it so they just basically \"chillax,\" right? They're not going to feel anything, which may tell you a little about what we're going to do, a scientific experiment to understand the brain. So ... This is the leg of a cockroach. And a cockroach has all these beautiful hairs and pricklies all over it. Underneath each one of those is a cell, and this cell's a neuron that is going to send information about wind or vibration. If you ever try to catch a cockroach, it's hard because they can feel you coming before you're even there, they start running. These cells are zipping up this information up to the brain using those little axons with electronic messages in there. We're going to record by sticking a pin right in there. We need to take off the leg of a cockroach — don't worry, they'll grow back — then we're going to put two pins in there. These are metal pins. One will pick up this electronic message, this electric message is going by. So, we're now going to do the surgery, let's see if you guys can see this. Yeah, it's gross ... All right. So there we go. You guys can see his leg right there. Now I'm going to take this leg, I'm going to put it in this invention that we came up with called the Spikerbox — and this replaces lots of expensive equipment in a research lab, so you guys can do this in your own high schools, or in your own basements if it's me. (Audience: Laughter) So, there. Can you guys see that? Alright, so I'm going to go ahead and turn this on. I'm going to plug it in. (Tuning sound) To me, this is the most beautiful sound in the world. This is what your brain is doing right now. You have 100 billion cells making these raindrop-type noises. Let's take a look at what it looks like, let's pull it up on the iPad screen. I plugged my iPad into here as well. So remember we said the axon looks like a spike. So we're going to take a look at what one of them looks like in just a brief second. We're going to tap here, so we can sort of average this guy. So there we see it. That's an action potential. You've got 100 billion cells in your brain doing this right now, sending all this information back about what you're seeing, hearing. We also said this is a cell that's going to be taking up information about vibrations in the wind. So what if we do an experiment? We can actually blow on this and hear if we see a change. Are you guys going to be ready? If I blow on it you tell me if you hear anything. (Blowing) (Sound changes) Let me just touch this with a little pen here. (Noise) That was the neural firing rate. That actually took a while in neuroscience to understand this. This is called rate coding: the harder you press on something, the more spikes there are, and all that information is coming up to your brain. That's how you perceive things. So that's one way of doing an experiment with electricity. The other way is that your brain is not only taking in electrical impulses, you're also sending out. That's how you move your muscles around. Let's see what happens if I've plugged in something that's electric into the cockroach leg here. I'm going to take two pins, I'm going to plug them onto the cockroach. I'm going to take the other end, I'm going to plug in into my iPod. It's my iPhone actually. Do you guys know how your earbuds work in your ears? You have a battery in your phone, or iPod, right? It's sending electrical current into these magnets in your earbuds which shake back and forth and allow you to hear things. But that current's the same currency that our brain uses, so we can send that to our cockroach leg and hopefully if this works, we can actually see what happens when we play music into the cockroach. Let's take a look. (Music beat) Can we turn it up? There we go. (Audience reacts and gasps) GG: So what's happening? Audience: Wow! (Laughter) So you see what's moving. It's moving on the bass. All those audiophiles out there, if you have awesome, kicking car stereos, you know, the bass speakers are the biggest speakers. The biggest speakers have the longest waves, which have the most current, and the current is what's causing these things to move. So it's not just speakers that are causing electricity. Microphones also cause electricity. (Beat) So I'm going to go ahead and invite another person out on the stage here to help me out with this. So there we go. (Beatboxing) This is the first time this has ever happened in the history of mankind. Human beatbox to a cockroach leg. When you guys go back to your high school, think about neuroscience and how you guys can begin the neuro-revolution. Thank you very much. Bye bye. (Applause)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "Picture yourself driving down the road tomorrow, heading somewhere to buy an item you found on Craigslist, perhaps a nice mountain bike for 3,000 dollars. At that price, it's probably one of those bikes with a little electric motor on it — (Laughter) maybe some streamers from the handlebars. (Laughter) The seller has declared this a cash-only deal, so you have, in the console of your car, 3,000 dollars. Suddenly, you are pulled over. During the stop, the officer asks, \"Do you have any drugs, weapons or large amounts of cash in your car?\" You truthfully answer, \"Yes,\" not to the drugs or to the weapons, but to the cash. In the blink of an eye, you are ordered out of your car. The officer searches it and finds your cash. On the spot, he seizes it, and he says he suspects it's part of a drug crime. A few days later, the local district attorney files paperwork to keep your money — permanently. And all of this happens without you ever being charged or convicted of any crime. Now, you might be saying, \"Ah, this would never happen in the United States.\" (Laughter) Incidents like this occur every day in our country. It's one of the most significant threats to your property rights most people have never even heard of. It's called \"civil forfeiture.\" Most of you are generally aware of criminal forfeiture, although the term itself might be a little unfamiliar, so let's begin with forfeiture. When we forfeit something, we give up that thing, or we're forced to give it up. In criminal forfeiture, someone is charged and convicted of a crime, and therefore, they have to give up property related to that crime. For example, suppose you use your car to transport and deal drugs. You're caught and convicted; now you have to give up or forfeit your car as part of the sentencing. That's criminal forfeiture. But in civil forfeiture, no person is charged with a crime — the property is charged and convicted of a crime. (Laughter) You heard that correctly: the government actually convicts an inanimate object with a crime. It's as if that thing itself committed the crime. That's why civil forfeiture cases have these really peculiar names, like, \"The United States of America v. One 1990 Ford Thunderbird.\" (Laughter) Or \"The State of Oklahoma v. 53,234 Dollars in Cash.\" (Laughter) Or my personal favorite: \"The United States of America v. One Solid Gold Object in the Form of a Rooster.\" (Laughter) Now, you're thinking: How does something like this happen? That's exactly what I said when I first learned about civil forfeiture while on a road trip with my wife. No, we did not get pulled over. (Laughter) I was reading about the history of civil forfeiture as part of my work as a research director at the law firm, and I came across one of the cases I just mentioned, \"The United States of America v. One 1990 Ford Thunderbird.\" In that case, Carol Thomas loaned her car to her son. While in the car, her son committed a minor drug crime. Carol didn't commit any crime, so law enforcement couldn't convict her and take the car, but they could — and did — use civil forfeiture to \"convict the car\" and take it. Carol was completely innocent, but she lost her car nonetheless. In other words, she was punished for a crime she did not commit. When I read this, I was gobsmacked. How could this occur? How is this even legal? It turns out, it began in our country with maritime law. Early in our republic, the government sought to fight piracy — yes, actual pirates. The problem was the government often couldn't catch the pirates, so instead it used civil forfeiture to convict the pirates' property and take it, and therefore deny the pirates their illegal profits. Of course, the government could've simply taken and kept the booty without necessarily using civil forfeiture, but doing so would have violated our most basic due process and property rights. Now, the government rarely used civil forfeiture until the 1980s and the war on drugs. We expanded civil forfeiture law to cover drug crimes and then later, other types of crime. Canada and the European Union adopted similar provisions so that now all kinds of people are ensnared in the forfeiture web, people like Russ Caswell. Russ Caswell owned a small budget motel in Tewksbury, Massachusetts. His father built the motel in 1955, and Russ took it over in the 1980s. During the years that Russ owned the motel, from time to time, people would rent rooms, and they would commit drug crimes. Russ didn't condone the activities — in fact, whenever he found out about it, he would immediately call police. Russ was entirely innocent of any crime, but that did not stop the US Department of Justice from seizing his motel simply because other people committed crimes there. But Russ's case was not alone. Between 1997 and 2016, the US Department of Justice took more than 635,000 properties. This means each year, tens of thousands of people lose their properties in cases in which they're never charged or convicted of any crime. And we're not necessarily talking about major drug kingpins or headline-grabbing financial fraudsters whose cases involve hundreds of thousands if not millions of dollars. Many of these seizures and forfeitures involve just everyday people like Russ Caswell or you or me. But it gets worse. Are you wondering: Where does all this cash and property end up? In most places, law enforcement keeps it. And they use it to buy equipment or pay for building repairs or even pay salaries and overtime. This is a clear conflict of interest. It creates a perverse profit incentive that can distort law enforcement. And this is a problem that's not lost on those in law enforcement, either. Former chief of police in Rochester, Minnesota, Roger Peterson, described the choice that police officers often face. As he described it: suppose I'm a police officer, and I see a drug deal. Now I face a choice: Do I go after the buyer and remove from the street illegal drugs, or do I go after the seller and get cash for my agency to use? So it's easy to see why a police officer might go for the cash. It was just such a circumstance that compelled police officers in Philadelphia to seize an entire house. In 2014, Chris and Markela Sourovelis' son sold 40 dollars worth of drugs down the street from their house. Forty dollars. The police watched the deal go down. They could've arrested the buyer and confiscated the drugs, but they didn't. They could've arrested the Sourovelises' son right there on the street and grabbed 40 dollars. But they didn't. They waited to arrest him at home, because then they could seize their entire house. The house was worth 350,000 dollars. That is what I mean by a perverse profit incentive. But the Sourovelises' case was no outlier. Philadelphia, the \"City of Brotherly Love,\" the \"Athens of America,\" the \"Cradle of Liberty,\" birthplace to the Constitution, home to the Liberty Bell and Independence Hall, the \"City that Loves you Back\" — (Laughter) that Philadelphia was running a forfeiture machine. Between 2002 and 2016, Philadelphia took more than 77 million dollars through forfeiture, including 1,200 homes. Cars, jewelry, electronics — all of it they sold, the proceeds they kept. And they would have kept right on doing it, had it not been for a class-action lawsuit — our team's class-action lawsuit — (Applause and cheers) Thank you. We forced them to change their forfeiture practices and to compensate victims. (Applause and cheers) When our team first began researching forfeiture in 2007, we had no idea how much forfeiture revenue there was. In fact, no one knew. It wasn't until our groundbreaking study, \"Policing for Profit,\" that we found federal law enforcement agencies have taken in almost 40 billion dollars — billion with a B — since 2001, more than 80 percent of that through civil forfeiture. Unfortunately, we have no idea how much state and local agencies have taken in, because in many states, they don't have to report it. So until we reform forfeiture, we'll never know how much forfeiture activity actually occurs in the United States. And we desperately need reform. Legislatures should abolish civil forfeiture and replace it with criminal forfeiture. And all forfeiture proceeds should go to a neutral fund such as a general fund. When forfeiture proceeds stop hitting law enforcement budgets directly, that is when we will end policing for profit. (Applause) Now, as you can imagine, law enforcement officials don't love these recommendations. (Laughter) They stand to lose a lot of money, and they believe civil forfeiture is an effective crime-fighting tool. The trouble is, it's not. In June 2019, we released a study that found forfeiture does not improve crime-fighting. And the report also found that law enforcement agencies pursue more forfeiture money during economic downturns. So when city and county budgets are tight, law enforcement will use forfeiture to find the money. So it's no wonder, then, that law enforcement officials predict a criminal apocalypse — (Laughter) if these reforms are adopted. But some states have already implemented them, and we're pushing for reform all across the country, because until we reform forfeiture, this is something that could happen to any of us. It can happen in the United States, it can happen in the United Kingdom, it can happen in countries throughout the European Union and beyond. People like you and me and the Sourovelises and Russ Caswell, just doing the everyday stuff of life, can be caught in a scheme we never thought possible. It is time we end policing for profit once and for all. Thank you. (Applause and cheers)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "Name: count, Length: 3330, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"transcript\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159b9c8",
   "metadata": {},
   "source": [
    "This column is ready to be CountVectorized.  We will address CountVectorization in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e448efc",
   "metadata": {},
   "source": [
    "#### - title             3331 non-null   object (Possible Count Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30024612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Averting the climate crisis                             1\n",
       "We can hack our immune cells to fight cancer            1\n",
       "There's no such thing as not voting                     1\n",
       "Why you should know how much your coworkers get paid    1\n",
       "Why open a school? To close a prison                    1\n",
       "                                                       ..\n",
       "A TED speaker's worst nightmare                         1\n",
       "Design to challenge reality                             1\n",
       "Why you will fail to have a great career                1\n",
       "The cockroach beatbox                                   1\n",
       "How \"policing for profit\" undermines your rights        1\n",
       "Name: count, Length: 3330, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d337aaa",
   "metadata": {},
   "source": [
    "I am considering CountVectorizing this column.  For now we will leave as-is.  CountVectorizing MAY be done in the next section.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6b63e",
   "metadata": {},
   "source": [
    "#### - speaker           3331 non-null   object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58e1993a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker\n",
       "Greg Gage                  9\n",
       "Juan Enriquez              9\n",
       "Hans Rosling               9\n",
       "Marco Tempest              7\n",
       "Bill Gates                 6\n",
       "                          ..\n",
       "Sue Austin                 1\n",
       "Boghuma Kabisen Titanji    1\n",
       "Andy Puddicombe            1\n",
       "Angela Patton              1\n",
       "Dick M. Carpenter II       1\n",
       "Name: count, Length: 2843, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"speaker\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a3f5d",
   "metadata": {},
   "source": [
    "As this column has little to do with the speech itself, and because we are trying to limit the number of features to the number of rows, I will drop this column.  \n",
    "\n",
    "It is noteworthy that WHO a speaker is would likely impact their rating on the speech itself, as each person represents their own personal brand, and when someone \"likes\" a speech they are in part \"liking\" that person's personal brand.  But given that the number of features we have is limited to the number of rows that we have, dummying the speaker names would create too many features to justify it's influence on our question \"what makes a great speech\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "04665aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the speaker column\n",
    "merged_cleaved_df.drop([\"speaker\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e107e68",
   "metadata": {},
   "source": [
    "#### - recorded_date     3331 non-null   object \n",
    "#### - published_date    3331 non-null   object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9a954",
   "metadata": {},
   "source": [
    "I will change these dates into DateTime datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cc31f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df[\"published_date\"] = pd.to_datetime(merged_cleaved_df[\"published_date\"])\n",
    "merged_cleaved_df[\"recorded_date\"] = pd.to_datetime(merged_cleaved_df[\"recorded_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d8dc9",
   "metadata": {},
   "source": [
    "#### event             3331 non-null   object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c32aa477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "TED2017                    96\n",
       "TED2018                    95\n",
       "TED2019                    91\n",
       "TED2014                    83\n",
       "TED2009                    81\n",
       "                           ..\n",
       "TEDSalon NY2015             1\n",
       "TEDxIndianapolis            1\n",
       "TEDxChapmanU                1\n",
       "TEDxGoldenGatePark 2012     1\n",
       "TEDxCreativeCoast           1\n",
       "Name: count, Length: 428, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cleaved_df[\"event\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f765d49",
   "metadata": {},
   "source": [
    "I will create a binary \"ted_mainstage\" column in the next section, to differentiate between TED and TEDx (and other) events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f0327",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "#### We will create the following features:\n",
    "- percent_likes (likes / views)\n",
    "- ted_mainstage (mainstage ted events)\n",
    "- word_count (from the \"transcript\" column)\n",
    "- words_per_minute (total_words_count / duration)\n",
    "- total_question_count (summing the instances of \"?\" in the transcript)\n",
    "- questions_per_minute (total_question_count / duration)\n",
    "- total_laugh_count (\"Laughter\" is included in the transcripts, and we will sum these occurrences)\n",
    "- laugh_per_minute (total_laugh_count / duration)\n",
    "- multiple_speakers (dummy variable - wether there were multiple speakers or not - created in the previous section)\n",
    "- published month\n",
    "- published year\n",
    "- recorded month\n",
    "- recorded year\n",
    "\n",
    "\n",
    "#### We will Dummying (via MultiLabelBinarizing) the following columns:\n",
    "- Occupation\n",
    "- Topic\n",
    "\n",
    "#### We will CountVectorize the following columns:\n",
    "- Transcript\n",
    "- Title\n",
    "- Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aed8bb",
   "metadata": {},
   "source": [
    "#### Percent likes feature\n",
    "- Create a \"percent_likes\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0125b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we'll create a \"percent_likes\" column, which is the percentage of likes out of the total views\n",
    "merged_cleaved_df['percent_likes'] = merged_cleaved_df['likes'] / merged_cleaved_df['view']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f790b",
   "metadata": {},
   "source": [
    "#### Ted Mainstage Feature\n",
    "\n",
    "- Create a binanry \"main_stage\" feature (from \"event\", which ones are mainstage TED talks vs which ones are 'Tedx'-like talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "841d195b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ted_mainstage\n",
       "0    2154\n",
       "1    1176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we'll create a 'ted_mainstage' column, which is a boolean column that is True if the talk was performed at a mainstream \"TED\" event, and False if it was not.\n",
    "# This is a regex pattern that matches the TED events that are not TEDx or TED Global\n",
    "mainstage = '^\\s*TED\\d{4}\\s*$'\n",
    "\n",
    "# Create a binary column based on the condition\n",
    "merged_cleaved_df['ted_mainstage'] = merged_cleaved_df['event'].str.match(mainstage).astype(int)\n",
    "merged_cleaved_df['ted_mainstage'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5c6c8",
   "metadata": {},
   "source": [
    "#### Word count columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9dd357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create another column that counts the number of words in the transcript.\n",
    "# A function that counts words in a string\n",
    "def count_words(text):\n",
    "    # Splitting the text into words and count them\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply this function to each row in the 'transcript' column and create a new column\n",
    "merged_cleaved_df['word_count'] = merged_cleaved_df['transcript'].apply(count_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec465d",
   "metadata": {},
   "source": [
    "#### Words per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8302c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words count per minute\n",
    "merged_cleaved_df['words_per_minute'] = merged_cleaved_df['word_count'] / merged_cleaved_df['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31176637",
   "metadata": {},
   "source": [
    "#### Total Question Count and Questions per Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38f3bd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>occupations</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>transcript</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>multiple_speakers</th>\n",
       "      <th>transformed_occupations</th>\n",
       "      <th>percent_likes</th>\n",
       "      <th>ted_mainstage</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words_per_minute</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>questions_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>climate_advocate</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>1</td>\n",
       "      <td>2153</td>\n",
       "      <td>2.203685</td>\n",
       "      <td>8</td>\n",
       "      <td>0.008188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "      <td>15432904</td>\n",
       "      <td>462000</td>\n",
       "      <td>0</td>\n",
       "      <td>global_health_expert;_data...</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>1</td>\n",
       "      <td>3174</td>\n",
       "      <td>2.667227</td>\n",
       "      <td>22</td>\n",
       "      <td>0.018487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainme...</td>\n",
       "      <td>(Music: \"The Sound of Sile...</td>\n",
       "      <td>2012797</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>technology_columnist</td>\n",
       "      <td>0.029809</td>\n",
       "      <td>1</td>\n",
       "      <td>3371</td>\n",
       "      <td>2.621306</td>\n",
       "      <td>35</td>\n",
       "      <td>0.027216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                          title                    occupations  \\\n",
       "0        1    Averting the climate crisis      {0: ['climate advocate']}   \n",
       "1       92  The best stats you've ever...  {0: ['global health expert...   \n",
       "2        7               Simplicity sells  {0: ['technology columnist']}   \n",
       "\n",
       "  recorded_date published_date    event  comments  duration  \\\n",
       "0    2006-02-25     2006-06-27  TED2006     272.0       977   \n",
       "1    2006-02-22     2006-06-27  TED2006     628.0      1190   \n",
       "2    2006-02-24     2006-06-27  TED2006     124.0      1286   \n",
       "\n",
       "                          topics                     transcript      view  \\\n",
       "0  ['alternative energy', 'ca...  Thank you so much, Chris. ...   3681537   \n",
       "1  ['Africa', 'Asia', 'Google...  About 10 years ago, I took...  15432904   \n",
       "2  ['computers', 'entertainme...  (Music: \"The Sound of Sile...   2012797   \n",
       "\n",
       "    likes  multiple_speakers        transformed_occupations  percent_likes  \\\n",
       "0  110000                  0               climate_advocate       0.029879   \n",
       "1  462000                  0  global_health_expert;_data...       0.029936   \n",
       "2   60000                  0           technology_columnist       0.029809   \n",
       "\n",
       "   ted_mainstage  word_count  words_per_minute  num_question_marks  \\\n",
       "0              1        2153          2.203685                   8   \n",
       "1              1        3174          2.667227                  22   \n",
       "2              1        3371          2.621306                  35   \n",
       "\n",
       "   questions_per_minute  \n",
       "0              0.008188  \n",
       "1              0.018487  \n",
       "2              0.027216  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that counts question marks in a given string\n",
    "def count_question_marks(text):\n",
    "    return text.count('?')\n",
    "\n",
    "# Apply this function to each row of the 'transcript' column and store the result in a new column\n",
    "merged_cleaved_df['num_question_marks'] = merged_cleaved_df['transcript'].apply(count_question_marks)\n",
    "merged_cleaved_df['questions_per_minute'] = merged_cleaved_df['num_question_marks'] / merged_cleaved_df['duration']\n",
    "merged_cleaved_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47165f89",
   "metadata": {},
   "source": [
    "#### Total Laugh Count and Laughs per Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3a886d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>occupations</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>transcript</th>\n",
       "      <th>view</th>\n",
       "      <th>likes</th>\n",
       "      <th>multiple_speakers</th>\n",
       "      <th>transformed_occupations</th>\n",
       "      <th>percent_likes</th>\n",
       "      <th>ted_mainstage</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words_per_minute</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>questions_per_minute</th>\n",
       "      <th>num_laughs</th>\n",
       "      <th>laughs_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'ca...</td>\n",
       "      <td>Thank you so much, Chris. ...</td>\n",
       "      <td>3681537</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>climate_advocate</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>1</td>\n",
       "      <td>2153</td>\n",
       "      <td>2.203685</td>\n",
       "      <td>8</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>22</td>\n",
       "      <td>0.022518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever...</td>\n",
       "      <td>{0: ['global health expert...</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google...</td>\n",
       "      <td>About 10 years ago, I took...</td>\n",
       "      <td>15432904</td>\n",
       "      <td>462000</td>\n",
       "      <td>0</td>\n",
       "      <td>global_health_expert;_data...</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>1</td>\n",
       "      <td>3174</td>\n",
       "      <td>2.667227</td>\n",
       "      <td>22</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainme...</td>\n",
       "      <td>(Music: \"The Sound of Sile...</td>\n",
       "      <td>2012797</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>technology_columnist</td>\n",
       "      <td>0.029809</td>\n",
       "      <td>1</td>\n",
       "      <td>3371</td>\n",
       "      <td>2.621306</td>\n",
       "      <td>35</td>\n",
       "      <td>0.027216</td>\n",
       "      <td>38</td>\n",
       "      <td>0.029549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                          title                    occupations  \\\n",
       "0        1    Averting the climate crisis      {0: ['climate advocate']}   \n",
       "1       92  The best stats you've ever...  {0: ['global health expert...   \n",
       "2        7               Simplicity sells  {0: ['technology columnist']}   \n",
       "\n",
       "  recorded_date published_date    event  comments  duration  \\\n",
       "0    2006-02-25     2006-06-27  TED2006     272.0       977   \n",
       "1    2006-02-22     2006-06-27  TED2006     628.0      1190   \n",
       "2    2006-02-24     2006-06-27  TED2006     124.0      1286   \n",
       "\n",
       "                          topics                     transcript      view  \\\n",
       "0  ['alternative energy', 'ca...  Thank you so much, Chris. ...   3681537   \n",
       "1  ['Africa', 'Asia', 'Google...  About 10 years ago, I took...  15432904   \n",
       "2  ['computers', 'entertainme...  (Music: \"The Sound of Sile...   2012797   \n",
       "\n",
       "    likes  multiple_speakers        transformed_occupations  percent_likes  \\\n",
       "0  110000                  0               climate_advocate       0.029879   \n",
       "1  462000                  0  global_health_expert;_data...       0.029936   \n",
       "2   60000                  0           technology_columnist       0.029809   \n",
       "\n",
       "   ted_mainstage  word_count  words_per_minute  num_question_marks  \\\n",
       "0              1        2153          2.203685                   8   \n",
       "1              1        3174          2.667227                  22   \n",
       "2              1        3371          2.621306                  35   \n",
       "\n",
       "   questions_per_minute  num_laughs  laughs_per_minute  \n",
       "0              0.008188          22           0.022518  \n",
       "1              0.018487           9           0.007563  \n",
       "2              0.027216          38           0.029549  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function that counts the number of \"(Laughter)\" in a string.\n",
    "def count_laughter(text):\n",
    "    # Splitting the text into words and count them\n",
    "    return text.count(\"(Laughter)\")\n",
    "\n",
    "# Apply this function to each row of the 'transcript' column and store the result in a new column\n",
    "merged_cleaved_df['num_laughs'] = merged_cleaved_df['transcript'].apply(count_laughter)\n",
    "merged_cleaved_df['laughs_per_minute'] = merged_cleaved_df['num_laughs'] / merged_cleaved_df['duration']\n",
    "merged_cleaved_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17946195",
   "metadata": {},
   "source": [
    "#### Published and Recorded Month and Year columns:\n",
    "\n",
    "- published_year\n",
    "- published_month\n",
    "- recorded_year\n",
    "- recorded_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf5e6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am creating additional columns for the year and month of the published and recorded dates\n",
    "merged_cleaved_df[\"published_year\"] = merged_cleaved_df[\"published_date\"].dt.year\n",
    "merged_cleaved_df[\"published_month\"] = merged_cleaved_df[\"published_date\"].dt.month\n",
    "merged_cleaved_df[\"recorded_year\"] = merged_cleaved_df[\"recorded_date\"].dt.year\n",
    "merged_cleaved_df[\"recorded_month\"] = merged_cleaved_df[\"recorded_date\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d280e3",
   "metadata": {},
   "source": [
    "#### We will Dummying (via MultiLabelBinarizing) the following columns:\n",
    "- Occupation\n",
    "- Topic\n",
    "\n",
    "#### We will CountVectorize the following columns:\n",
    "- Transcript\n",
    "- Title\n",
    "- Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2cc2d021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3330, 449)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiLabelBinarizing the 'topics' column\n",
    "# Convert the string representation of lists in 'topics' column to actual lists\n",
    "merged_cleaved_df['topics_list'] = merged_cleaved_df['topics'].apply(ast.literal_eval)\n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform 'topics_list' column (now actual lists) into a binary matrix\n",
    "topics_encoded = mlb.fit_transform(merged_cleaved_df['topics_list'])\n",
    "\n",
    "# Creating a DataFrame from the transformed topics\n",
    "topics_df = pd.DataFrame(topics_encoded, columns=mlb.classes_)\n",
    "\n",
    "# topics_df now contains the binarized form of the 'topics' column, with each column representing a unique topic\n",
    "topics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a3825",
   "metadata": {},
   "source": [
    "Topics dummy variables account for 449 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "299b3570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3330, 1701)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiLabelBinarizing the 'transformed_occupation' column\n",
    "# Convert the string representation of lists in 'topics' column to actual lists\n",
    "merged_cleaved_df['transformed_occupations_list'] = merged_cleaved_df['transformed_occupations'].apply(lambda x: x.split(' '))\n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform 'transformed_occupations_list' column (now actual lists) into a binary matrix\n",
    "occupations_encoded = mlb.fit_transform(merged_cleaved_df['transformed_occupations_list'])\n",
    "\n",
    "# Creating a DataFrame from the transformed occupations\n",
    "occupations_df = pd.DataFrame(occupations_encoded, columns=mlb.classes_)\n",
    "\n",
    "# occupations_df now contains the binarized form of the 'transformed_occupations' column, with each column representing a unique topic\n",
    "occupations_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd798693",
   "metadata": {},
   "source": [
    "Occupation dummy variables account for 1701 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dbbe8",
   "metadata": {},
   "source": [
    "## Merging into a single dataframe\n",
    "\n",
    "We will merge the dataframes before our countvectorization process.\n",
    "\n",
    "Let's first drop all non-numerical columns (other than the columns we will be doing our CountVectorizing on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53bc6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2cc6722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3330 entries, 0 to 3993\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   comments              3330 non-null   float64\n",
      " 1   duration              3330 non-null   int64  \n",
      " 2   view                  3330 non-null   int64  \n",
      " 3   multiple_speakers     3330 non-null   int64  \n",
      " 4   percent_likes         3330 non-null   float64\n",
      " 5   ted_mainstage         3330 non-null   int64  \n",
      " 6   word_count            3330 non-null   int64  \n",
      " 7   words_per_minute      3330 non-null   float64\n",
      " 8   num_question_marks    3330 non-null   int64  \n",
      " 9   questions_per_minute  3330 non-null   float64\n",
      " 10  num_laughs            3330 non-null   int64  \n",
      " 11  laughs_per_minute     3330 non-null   float64\n",
      " 12  transcript            3330 non-null   object \n",
      "dtypes: float64(5), int64(7), object(1)\n",
      "memory usage: 364.2+ KB\n",
      "(3330, 13)\n"
     ]
    }
   ],
   "source": [
    "# Dropping the non numerical columns\n",
    "ready_to_merge_numerical_df = merged_cleaved_df.select_dtypes(include=['int64', 'float64'])\n",
    "ready_to_merge_numerical_df.drop([\"talk_id\"], axis=1, inplace=True) # Dropping the talk_id column\n",
    "ready_to_merge_numerical_df.drop([\"likes\"], axis=1, inplace=True) # Dropping the likes column\n",
    "ready_to_merge_numerical_df['transcript'] = merged_cleaved_df['transcript'] # Adding the transcript column back in\n",
    "ready_to_merge_numerical_df.info()\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a26ca",
   "metadata": {},
   "source": [
    "We now have a dataframe to which we can merge the topics and occupations dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a5d0d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330, 449)\n",
      "(3330, 1701)\n",
      "(3330, 13)\n"
     ]
    }
   ],
   "source": [
    "# Lets check the shape of the topics_df and occupations_df and ready_to_merge_numerical_df\n",
    "print(topics_df.shape)\n",
    "print(occupations_df.shape)\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ea26a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As all three dataframes have the same shape, we'll reset their indexes and merge them together\n",
    "# Reset the index of each DataFrame to ensure alignment\n",
    "occupations_df_reset = occupations_df.reset_index(drop=True)\n",
    "topics_df_reset = topics_df.reset_index(drop=True)\n",
    "ready_to_merge_numerical_df_reset = ready_to_merge_numerical_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c8700525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3330, 2163)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_merged_df = pd.concat([occupations_df_reset, topics_df_reset, ready_to_merge_numerical_df_reset], axis=1)\n",
    "dummy_merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97877b01",
   "metadata": {},
   "source": [
    "For countvectorizing, we have space for (3330 - 2162 = 1168) 1168 columns.  We will set the MaxFeatures at 1100. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3ea6b",
   "metadata": {},
   "source": [
    "## Defining what a \"good\" speach is - creating a binary dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91b43f",
   "metadata": {},
   "source": [
    "Let's first look at the \"percent_likes\" column to decide where to draw the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9450b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/d5ln4l29453322fq40g1dz2h0000gn/T/ipykernel_47092/1665270562.py:3: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.histplot(dummy_merged_df['percent_likes'], kde=False, palette='coolwarm', bins=30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the distribution\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size for better readability\n",
    "sns.histplot(dummy_merged_df['percent_likes'], kde=False, palette='coolwarm', bins=30)\n",
    "# 'kde=False' turns off the Kernel Density Estimate plot overlay\n",
    "# 'bins=30' specifies how many bins you want to divide your data into\n",
    "# 'color' specifies the color of the histogram\n",
    "\n",
    "# Calculating and plotting the mean\n",
    "mean_value = dummy_merged_df['percent_likes'].mean()\n",
    "plt.axvline(mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.4f}')\n",
    "# This draws a vertical line at the mean value, '--' makes the line dashed, and ':.2f' formats the mean to 2 decimal places\n",
    "\n",
    "plt.xlabel('Percent Likes')  # Label for the x-axis\n",
    "plt.ylabel('Number of Talks')  # Label for the y-axis\n",
    "plt.title('Distribution of Percent Likes')  # Title of the plot\n",
    "plt.legend()  # Show the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b624b9",
   "metadata": {},
   "source": [
    "We're first going to create a binary \"good_speech\" column.  We are indicating that speeches that recieved an above the mean \"percent_likes\" are counted as \"good_speech\", and those that were below the \"percent_likes\" mean are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f798c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = dummy_merged_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "dummy_merged_df['good_speech'] = (dummy_merged_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45691a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['comments', 'duration', 'view', 'multiple_speakers',\n",
    "       'percent_likes', 'num_question_marks',\n",
    "       'questions_per_minute', 'num_laughs', 'laughs_per_minute']\n",
    "\n",
    "# Scale the selected columns and replace in the dataframe\n",
    "dummy_merged_df[columns_to_scale] = scaler.fit_transform(dummy_merged_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d34319",
   "metadata": {},
   "source": [
    "## Baseline Model:\n",
    "\n",
    "Result:\n",
    "\n",
    "Logistic Regression:\n",
    "| Metric      | Score           |\n",
    "|-------------|-----------------|\n",
    "| Train score | 0.6415165165165165 |\n",
    "| Test score  | 0.6036036036036037 |\n",
    "\n",
    "Random Forest:\n",
    "| Metric      | Score           |\n",
    "|-------------|-----------------|\n",
    "| Train score | 0.9966216216216216 |\n",
    "| Test score  | 0.6066066066066066 |\n",
    "\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| want know        | 0.039544    |\n",
    "| people say       | 0.029546    |\n",
    "| people think     | 0.026989    |\n",
    "| feels like       | 0.025923    |\n",
    "| dont think       | 0.025119    |\n",
    "| black hole       | 0.024329    |\n",
    "| know people      | 0.022076    |\n",
    "| years later      | 0.021207    |\n",
    "| high school      | 0.020977    |\n",
    "| answer question  | 0.020397    |\n",
    "\n",
    "Logistic Regression (bottom 10 positive coefficients):\n",
    "| Feature           | Coefficient |\n",
    "|-------------------|-------------|\n",
    "| 20 years          | -0.016250   |\n",
    "| 90 percent        | -0.017265   |\n",
    "| 30 years          | -0.017755   |\n",
    "| middle east       | -0.018234   |\n",
    "| im going          | -0.022491   |\n",
    "| just want         | -0.023509   |\n",
    "| looks like        | -0.025027   |\n",
    "| ladies gentlemen  | -0.026333   |\n",
    "| people living     | -0.029691   |\n",
    "| weve got          | -0.031859   |\n",
    "\n",
    "\n",
    "Random Forest:\n",
    "| Feature        | Importance |\n",
    "|----------------|------------|\n",
    "| years ago      | 0.012877   |\n",
    "| im going       | 0.010958   |\n",
    "| united states  | 0.010084   |\n",
    "| dont know      | 0.009862   |\n",
    "| little bit     | 0.009772   |\n",
    "| looks like     | 0.009366   |\n",
    "| new york       | 0.008108   |\n",
    "| just like      | 0.007697   |\n",
    "| years old      | 0.007577   |\n",
    "| id like        | 0.007223   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99518516",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dummy_merged_df.drop(\"good_speech\", axis=1)\n",
    "y=dummy_merged_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\", \"♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(2, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=300) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9a4ed",
   "metadata": {},
   "source": [
    "## Logistic Regression on CountVectorized Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9f607",
   "metadata": {},
   "source": [
    "We will use this as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d17c5",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b32759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(10))\n",
    "print(coefficients_df.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d93a4",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb27579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69840214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e1975",
   "metadata": {},
   "source": [
    "## Model Iteration\n",
    "\n",
    "We now have solid baseline models in both a Random Forest Model, and a Logistic Regression Model\n",
    "\n",
    "We will iterate over our selected features to see:\n",
    "1. which coefficients/feature_importances we can see as having the most influence, and\n",
    "2. if we can produce a better performing model\n",
    "\n",
    "Model Iterations:\n",
    "\n",
    "1. limit our features to only the numeric columns of the original dataset (no countvectorizing and no dummying)\n",
    "2. only include countvectorization of the \"transcript\" column.  Adjust n_grams and Max Features and see what insights we can glean.\n",
    "3. include countvectorization and topics dummies (do not include occupation dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b01661",
   "metadata": {},
   "source": [
    "### Model Iteration: 1. limit our features to only the numeric columns of the original dataset (no countvectorizing and no dummying)\n",
    "\n",
    "Result:\n",
    "\n",
    "Logistic Regression:\n",
    "| Metric      | Score        |\n",
    "|-------------|--------------|\n",
    "| Train score | 0.6415165165 |\n",
    "| Test score  | 0.6036036036 |\n",
    "\n",
    "Random Forest:\n",
    "| Metric      | Score        |\n",
    "|-------------|--------------|\n",
    "| Train score | 1.0          |\n",
    "| Test score  | 0.5750750751 |\n",
    "\n",
    "\n",
    "\n",
    "Logistic Regression:\n",
    "| Feature               | Coefficient |\n",
    "|-----------------------|-------------|\n",
    "| ted_mainstage         | 0.035492    |\n",
    "| num_question_marks    | 0.009934    |\n",
    "| laughs_per_minute     | 0.008348    |\n",
    "| comments              | 0.007841    |\n",
    "| questions_per_minute  | 0.007794    |\n",
    "| num_laughs            | 0.007096    |\n",
    "| duration              | 0.003855    |\n",
    "| multiple_speakers     | -0.005425   |\n",
    "\n",
    "\n",
    "Random Forest:\n",
    "| Feature               | Importance |\n",
    "|-----------------------|------------|\n",
    "| comments              | 0.238122   |\n",
    "| duration              | 0.208304   |\n",
    "| questions_per_minute  | 0.190413   |\n",
    "| laughs_per_minute     | 0.148356   |\n",
    "| num_question_marks    | 0.114803   |\n",
    "| num_laughs            | 0.069227   |\n",
    "| ted_mainstage         | 0.020783   |\n",
    "| multiple_speakers     | 0.009992   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non numerical columns\n",
    "ready_to_merge_numerical_df = merged_cleaved_df.select_dtypes(include=['int64', 'float64'])\n",
    "ready_to_merge_numerical_df.drop([\"talk_id\"], axis=1, inplace=True) # Dropping the talk_id column\n",
    "ready_to_merge_numerical_df.drop([\"likes\"], axis=1, inplace=True) # Dropping the likes column\n",
    "ready_to_merge_numerical_df.drop([\"view\"], axis=1, inplace=True) # Dropping the view column\n",
    "ready_to_merge_numerical_df.info()\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = dummy_merged_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "dummy_merged_df['good_speech'] = (dummy_merged_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition\n",
    "\n",
    "# since this data is already represented in the \"good_speech\" column, we'll drop the \"percent_likes\" column\n",
    "ready_to_merge_numerical_df.drop([\"percent_likes\"], axis=1, inplace=True) # Dropping the percent_likes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['comments', 'duration',\n",
    "       'num_question_marks', 'questions_per_minute', 'num_laughs', 'laughs_per_minute']\n",
    "\n",
    "# Scale the selected columns and replace in the dataframe\n",
    "ready_to_merge_numerical_df[columns_to_scale] = scaler.fit_transform(ready_to_merge_numerical_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=ready_to_merge_numerical_df.drop(\"good_speech\", axis=1)\n",
    "y=ready_to_merge_numerical_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc0c02",
   "metadata": {},
   "source": [
    "## Logistic Regression on Original Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793319a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea43ebd",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50925143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train is a pandas DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Extracting the coefficients\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Creating a DataFrame for better readability\n",
    "coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Sorting the DataFrame by the absolute values of the coefficients in descending order\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Printing the DataFrame\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14ee47",
   "metadata": {},
   "source": [
    "## Random Forest Classifier on Original Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e011d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(X_train, y_train)\n",
    "test_score_rf = random_forest.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70c49f",
   "metadata": {},
   "source": [
    "### Model Iteration: 2. only include countvectorization of the \"transcript\" column.  Adjust n_grams and Max Features and see what insights we can glean.\n",
    "\n",
    "Result:\n",
    "\n",
    "Max Features 500, n_gram 2,6:\n",
    "\n",
    "    Logistic Regression:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6437687688 |\n",
    "| Test score   | 0.6096096096 |\n",
    "\n",
    "    Random Forest:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6512762763 |\n",
    "| Test score   | 0.5990990991 |\n",
    "\n",
    "        \n",
    "\n",
    "Max Features 200, n_gram 2,6:\n",
    "\n",
    "    Logistic Regression:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6441441441 |\n",
    "| Test score   | 0.6096096096 |\n",
    "    \n",
    "    Random Forest:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.9962462462 |\n",
    "| Test score   | 0.5855855856 |\n",
    "        \n",
    "\n",
    "Max Features 200, n_gram 3,6:\n",
    "\n",
    "    Logistic Regression:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6415165165 |\n",
    "| Test score   | 0.6036036036 |\n",
    "\n",
    "    Random Forest:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.8599849850 |\n",
    "| Test score   | 0.5690690691 |\n",
    "\n",
    "\n",
    "Max Features 200, n_gram 4,6:\n",
    "\n",
    "    Logistic Regression:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6415165165 |\n",
    "| Test score   | 0.6036036036 |\n",
    "\n",
    "    Random Forest:\n",
    "| Metric       | Score        |\n",
    "|--------------|--------------|\n",
    "| Train score  | 0.6512762763 |\n",
    "| Test score   | 0.5990990991 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-- Coefficients and Important_Features:\n",
    "\n",
    "Max Features 500, n_gram 2,6:\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| want know        | 0.038674    |\n",
    "| people say       | 0.028643    |\n",
    "| people think     | 0.026238    |\n",
    "| feels like       | 0.025608    |\n",
    "| dont think       | 0.024323    |\n",
    "| black hole       | 0.022536    |\n",
    "| know people      | 0.022126    |\n",
    "| years later      | 0.020346    |\n",
    "| answer question  | 0.019935    |\n",
    "| high school      | 0.019769    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients):\n",
    "| Feature        | Coefficient |\n",
    "|----------------|-------------|\n",
    "| — theyre       | -0.013201   |\n",
    "| looked like    | -0.013604   |\n",
    "| going make     | -0.014004   |\n",
    "| dont want      | -0.014266   |\n",
    "| years ago      | -0.014587   |\n",
    "| youre seeing   | -0.014933   |\n",
    "| thats going    | -0.015702   |\n",
    "| stem cells     | -0.016102   |\n",
    "| 20 years       | -0.016648   |\n",
    "| 90 percent     | -0.017463   |\n",
    "\n",
    "\n",
    "Random Forest (top 10 feature importance):\n",
    "| Feature       | Importance |\n",
    "|---------------|------------|\n",
    "| years ago     | 0.008267   |\n",
    "| little bit    | 0.007942   |\n",
    "| im going      | 0.007934   |\n",
    "| united states | 0.007818   |\n",
    "| looks like    | 0.007428   |\n",
    "| dont know     | 0.007099   |\n",
    "| new york      | 0.006233   |\n",
    "| people living | 0.005921   |\n",
    "| dont want     | 0.005228   |\n",
    "| id like       | 0.00519    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Max Features 200, n_gram 2,6:\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| want know        | 0.039334    |\n",
    "| people say       | 0.029366    |\n",
    "| people think     | 0.026868    |\n",
    "| feels like       | 0.026130    |\n",
    "| dont think       | 0.025444    |\n",
    "| black hole       | 0.023943    |\n",
    "| know people      | 0.022474    |\n",
    "| years later      | 0.020595    |\n",
    "| high school      | 0.020350    |\n",
    "| answer question  | 0.020276    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients):\n",
    "| Feature         | Coefficient |\n",
    "|-----------------|-------------|\n",
    "| want talk       | -0.012010   |\n",
    "| public health   | -0.012439   |\n",
    "| billion people  | -0.012615   |\n",
    "| whats going     | -0.012632   |\n",
    "| million people  | -0.013118   |\n",
    "| — theyre        | -0.013279   |\n",
    "| looked like     | -0.013664   |\n",
    "| dont want       | -0.013932   |\n",
    "| going make      | -0.013938   |\n",
    "| years ago       | -0.014915   |\n",
    "\n",
    "\n",
    "Random Forest (top 10 feature importance):\n",
    "| Feature        | Importance |\n",
    "|----------------|------------|\n",
    "| years ago      | 0.017003   |\n",
    "| im going       | 0.015808   |\n",
    "| united states  | 0.013924   |\n",
    "| dont know      | 0.012760   |\n",
    "| looks like     | 0.012600   |\n",
    "| little bit     | 0.012325   |\n",
    "| id like        | 0.010884   |\n",
    "| new york       | 0.010279   |\n",
    "| 10 years       | 0.009843   |\n",
    "| just like      | 0.009789   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Max Features 200, n_gram 3,6:\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature               | Coefficient |\n",
    "|-----------------------|-------------|\n",
    "| just little bit       | 0.012587    |\n",
    "| say things like       | 0.009311    |\n",
    "| martin luther king    | 0.008210    |\n",
    "| blah blah blah        | 0.008072    |\n",
    "| don ’ t               | 0.005960    |\n",
    "| thats good thing      | 0.005930    |\n",
    "| hubble space telescope| 0.005765    |\n",
    "| dont know people      | 0.005476    |\n",
    "| know dont know        | 0.005271    |\n",
    "| music music ends      | 0.005257    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients):\n",
    "| Feature                     | Coefficient |\n",
    "|-----------------------------|-------------|\n",
    "| 40 years ago                | -0.003641   |\n",
    "| international space station | -0.003710   |\n",
    "| doesnt look like            | -0.003868   |\n",
    "| little bit different        | -0.004017   |\n",
    "| 20 years ago                | -0.004078   |\n",
    "| know im going               | -0.004224   |\n",
    "| world trade center          | -0.004249   |\n",
    "| today im going              | -0.004470   |\n",
    "| world wide web              | -0.004638   |\n",
    "| im going make               | -0.004904   |\n",
    "\n",
    "\n",
    "Random Forest (top 10 feature importance):\n",
    "| Feature             | Importance |\n",
    "|---------------------|------------|\n",
    "| new york city       | 0.020171   |\n",
    "| new york times      | 0.014279   |\n",
    "| im going tell       | 0.013936   |\n",
    "| im going talk       | 0.013907   |\n",
    "| 10 years ago        | 0.011581   |\n",
    "| 20 years ago        | 0.010626   |\n",
    "| little bit like     | 0.010120   |\n",
    "| 15 years ago        | 0.009633   |\n",
    "| world war ii        | 0.009455   |\n",
    "| million years ago   | 0.008828   |\n",
    "\n",
    "\n",
    "Max Features 200, n_gram 4,6:\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature                    | Coefficient |\n",
    "|----------------------------|-------------|\n",
    "| let tell little bit        | 0.003087    |\n",
    "| martin luther king jr      | 0.002650    |\n",
    "| im going im going          | 0.001601    |\n",
    "| make world better place    | 0.001591    |\n",
    "| — dont know —              | 0.001372    |\n",
    "| im going tell story        | 0.001089    |\n",
    "| cut long story short       | 0.000941    |\n",
    "| going talk little bit      | 0.000657    |\n",
    "| im going talk little       | 0.000299    |\n",
    "| dont know dont know        | 0.000094    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients) :\n",
    "| Feature                      | Coefficient |\n",
    "|------------------------------|-------------|\n",
    "| dont know dont know          | 0.000094    |\n",
    "| know whats going happen      | -0.000414   |\n",
    "| want talk little bit         | -0.001542   |\n",
    "| today im going talk          | -0.002334   |\n",
    "| id like talk today           | -0.003330   |\n",
    "| thank chris anderson thank   | -0.003408   |\n",
    "| im going talk today          | -0.003448   |\n",
    "| weve come long way           | -0.004327   |\n",
    "| small thing big idea         | -0.004327   |\n",
    "| thank thank thank thank      | -0.006758   |\n",
    "\n",
    "\n",
    "Random Forest (top 10 feature importance):\n",
    "| Feature                    | Importance |\n",
    "|----------------------------|------------|\n",
    "| weve come long way         | 0.108924   |\n",
    "| thank thank thank thank    | 0.105864   |\n",
    "| small thing big idea       | 0.092390   |\n",
    "| thank chris anderson thank | 0.084021   |\n",
    "| im going talk today        | 0.076134   |\n",
    "| id like talk today         | 0.063073   |\n",
    "| let tell little bit        | 0.056309   |\n",
    "| make world better place    | 0.049534   |\n",
    "| dont know dont know        | 0.047605   |\n",
    "| today im going talk        | 0.046653   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d792a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Transcript Only Dataframe\n",
    "only_transcript_df = merged_cleaved_df[['percent_likes', 'transcript']]\n",
    "only_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57be4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = only_transcript_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "only_transcript_df['good_speech'] = (only_transcript_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition\n",
    "\n",
    "only_transcript_df.drop([\"percent_likes\"], axis=1, inplace=True) # Dropping the percent_likes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_transcript_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5395d",
   "metadata": {},
   "source": [
    "### Max Features 500, n_gram 2,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f51094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=only_transcript_df.drop(\"good_speech\", axis=1)\n",
    "y=only_transcript_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(2, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=500) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ec51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc79097",
   "metadata": {},
   "source": [
    "## Logistic Regression Max Features 500, n_gram 2,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a225cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7e046",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(20))\n",
    "print(coefficients_df.tail(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a843a92",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model on Max Features 500, n_gram 2,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc17979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00118020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cf132",
   "metadata": {},
   "source": [
    "## Max Features = 200, n_gram = 2,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd790c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=only_transcript_df.drop(\"good_speech\", axis=1)\n",
    "y=only_transcript_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(2, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=200) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866eef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5ad6d",
   "metadata": {},
   "source": [
    "## Logistic Regression on Max Features 200, n_gram 2,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdda1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81492f3",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(20))\n",
    "print(coefficients_df.tail(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0109e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model on Max Features 200, n_gram 2,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1052e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10e478",
   "metadata": {},
   "source": [
    "## Max Features = 200, n_gram = 3,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f41dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=only_transcript_df.drop(\"good_speech\", axis=1)\n",
    "y=only_transcript_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\", \"♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(3, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=200) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2f21e",
   "metadata": {},
   "source": [
    "## Logistic Regression on Max Features 200, n_gram 3,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055e40a",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(20))\n",
    "print(coefficients_df.tail(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a913c",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model on Max Features 200, n_gram 3,6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4254c",
   "metadata": {},
   "source": [
    "## Max Features = 200, n_gram = 4,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=only_transcript_df.drop(\"good_speech\", axis=1)\n",
    "y=only_transcript_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58181841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\", \"♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(4, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=200) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af667232",
   "metadata": {},
   "source": [
    "## Logistic Regression on Max Features = 200, n_gram = 4,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaecca5",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51314c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(20))\n",
    "print(coefficients_df.tail(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb3d5e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model on Max Features = 200, n_gram = 4,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02abc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110249bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533e912",
   "metadata": {},
   "source": [
    "### Model Iteration: 3. include countvectorization and topics dummies (do not include occupation dummies)\n",
    "\n",
    "Result:\n",
    "Logistic Regression:\n",
    "- Train score: 0.6437687687687688\n",
    "- Test score: 0.6096096096096096\n",
    "\n",
    "Random Forest:\n",
    "- Train score: 0.996996996996997    \n",
    "- Test score: 0.5900900900900901\n",
    "    \n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature       | Coefficient |\n",
    "|---------------|-------------|\n",
    "| want know     | 0.039126    |\n",
    "| people say    | 0.029091    |\n",
    "| people think  | 0.026444    |\n",
    "| feels like    | 0.026033    |\n",
    "| dont think    | 0.025069    |\n",
    "| black hole    | 0.024175    |\n",
    "| know people   | 0.022336    |\n",
    "| years later   | 0.020470    |\n",
    "| high school   | 0.020177    |\n",
    "| answer question| 0.020100    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients):\n",
    "\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| 90 percent       | -0.017563   |\n",
    "| 30 years         | -0.018234   |\n",
    "| middle east      | -0.018441   |\n",
    "| ♫ ♫              | -0.019905   |\n",
    "| im going         | -0.023090   |\n",
    "| just want        | -0.023170   |\n",
    "| ladies gentlemen | -0.025534   |\n",
    "| looks like       | -0.025968   |\n",
    "| people living    | -0.029898   |\n",
    "| weve got         | -0.031898   |\n",
    "\n",
    "\n",
    "Random Forest:\n",
    "| Feature       | Importance |\n",
    "|---------------|------------|\n",
    "| years ago     | 0.012858   |\n",
    "| united states | 0.010669   |\n",
    "| im going      | 0.010316   |\n",
    "| little bit    | 0.010272   |\n",
    "| dont know     | 0.010134   |\n",
    "| looks like    | 0.009707   |\n",
    "| id like       | 0.008441   |\n",
    "| years old     | 0.007860   |\n",
    "| things like   | 0.007416   |\n",
    "| new york      | 0.007234   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a0041",
   "metadata": {},
   "source": [
    "## Merging into a single dataframe\n",
    "\n",
    "We will merge the dataframes before our countvectorization process.\n",
    "\n",
    "Let's first drop all non-numerical columns (other than the columns we will be doing our CountVectorizing on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c570e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d40067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non numerical columns\n",
    "ready_to_merge_numerical_df = merged_cleaved_df.select_dtypes(include=['int64', 'float64'])\n",
    "ready_to_merge_numerical_df.drop([\"talk_id\"], axis=1, inplace=True) # Dropping the talk_id column\n",
    "ready_to_merge_numerical_df.drop([\"likes\"], axis=1, inplace=True) # Dropping the likes column\n",
    "ready_to_merge_numerical_df.drop([\"view\"], axis=1, inplace=True) # Dropping the view column\n",
    "ready_to_merge_numerical_df[\"transcript\"] = merged_cleaved_df[\"transcript\"] # Adding the transcript column back in\n",
    "ready_to_merge_numerical_df.info()\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef51c41",
   "metadata": {},
   "source": [
    "We now have a dataframe to which we can merge the topics and occupations dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the shape of the topics_df and ready_to_merge_numerical_df\n",
    "print(topics_df.shape)\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As all three dataframes have the same shape, we'll reset their indexes and merge them together\n",
    "# Reset the index of each DataFrame to ensure alignment\n",
    "topics_df_reset = topics_df.reset_index(drop=True)\n",
    "ready_to_merge_numerical_df_reset = ready_to_merge_numerical_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9cb515",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_merged_df = pd.concat([topics_df_reset, ready_to_merge_numerical_df_reset], axis=1)\n",
    "dummy_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = dummy_merged_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "dummy_merged_df['good_speech'] = (dummy_merged_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition\n",
    "\n",
    "dummy_merged_df.drop([\"percent_likes\"], axis=1, inplace=True) # Dropping the percent_likes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['comments', 'duration', 'num_question_marks',\n",
    "       'questions_per_minute', 'num_laughs', 'laughs_per_minute']\n",
    "\n",
    "# Scale the selected columns and replace in the dataframe\n",
    "dummy_merged_df[columns_to_scale] = scaler.fit_transform(dummy_merged_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dummy_merged_df.drop(\"good_speech\", axis=1)\n",
    "y=dummy_merged_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CountVectorizing the 'transcript' column\n",
    "# Custom stop words\n",
    "custom_stop_words = [\"laughter\", \"applause\", \"laughter applause\", \"--\", \"-\", \"♫ ♫\"]\n",
    "\n",
    "# Combine custom stop words with default English stop words\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# As tokenizers must be functions, we will define a function for the tokenizer we will use\n",
    "def nltk_tokenizer(text):\n",
    "    # Remove punctuation using a list comprehension\n",
    "    text_no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text without punctuation\n",
    "    return word_tokenize(text_no_punctuation)\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "bagofwords_transcript = CountVectorizer(stop_words=stop_words, # remove stop words\n",
    "                                        tokenizer=nltk_tokenizer, # use the NLTK tokenizer\n",
    "                                        min_df=10, # minimum document frequency of 10\n",
    "                                        max_df=0.8, # maximum document frequency of 75% (i.e., ignore words that appear in more than 75% of the documents)\n",
    "                                        ngram_range=(2, 6), # allowing for bigrams, and trigrams\n",
    "                                        max_features=300) # maximum number of features to keep\n",
    "\n",
    "# Fit the CountVectorizer object on the positive (and, separately, negative) reviews\n",
    "bagofwords_transcript.fit(X_train[\"transcript\"])\n",
    "print(bagofwords_transcript.fit(X_train[\"transcript\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43824f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train = bagofwords_transcript.transform(X_train[\"transcript\"])\n",
    "sparse_matrix_test = bagofwords_transcript.transform(X_test[\"transcript\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29da4d",
   "metadata": {},
   "source": [
    "## Logistic Regression on Transcripts, Numerical Columns, and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf558e3",
   "metadata": {},
   "source": [
    "We will use this as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(sparse_matrix_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(sparse_matrix_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84bd895",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]  # For logistic regression, `coef_` returns an array in shape (n_classes, n_features)\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show features with the highest absolute coefficient values at the top\n",
    "coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display the top N most impactful features\n",
    "print(coefficients_df.head(10))\n",
    "print(coefficients_df.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6ad51",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98291bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(sparse_matrix_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(sparse_matrix_train, y_train)\n",
    "test_score_rf = random_forest.score(sparse_matrix_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Create a pandas DataFrame for easier manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "print(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac866008",
   "metadata": {},
   "source": [
    "### Model Iteration: 4. only analyzing original numerical features and topics dummies (do not include occupation dummies, and do not countvectorize)\n",
    "\n",
    "Result:\n",
    "Logistic Regression:\n",
    "- Train score: 0.6415165165165165\n",
    "- Test score: 0.6036036036036037\n",
    "\n",
    "Random Forest:\n",
    "- Train score: 0.996996996996997\n",
    "- Test score: 0.5900900900900901\n",
    "\n",
    "\n",
    "Logistic Regression (top 10 positive coefficients):\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| society          | 0.036462    |\n",
    "| ted_mainstage    | 0.036185    |\n",
    "| personal growth  | 0.024413    |\n",
    "| social change    | 0.021618    |\n",
    "| work             | 0.021587    |\n",
    "| business         | 0.018524    |\n",
    "| leadership       | 0.017687    |\n",
    "| psychology       | 0.017051    |\n",
    "| humanity         | 0.016938    |\n",
    "| education        | 0.016009    |\n",
    "\n",
    "Logistic Regression (top 10 negative coefficients):\n",
    "| Feature        | Coefficient |\n",
    "|----------------|-------------|\n",
    "| india          | -0.011716   |\n",
    "| entertainment  | -0.011894   |\n",
    "| live music     | -0.012179   |\n",
    "| war            | -0.014048   |\n",
    "| TEDx           | -0.015971   |\n",
    "| technology     | -0.016110   |\n",
    "| art            | -0.018632   |\n",
    "| science        | -0.019537   |\n",
    "| design         | -0.027669   |\n",
    "| global issues  | -0.045344   |\n",
    "\n",
    "\n",
    "\n",
    "Random Forest (top 10 feature importance):\n",
    "| Feature       | Importance |\n",
    "|---------------|------------|\n",
    "| years ago     | 0.012858   |\n",
    "| united states | 0.010669   |\n",
    "| im going      | 0.010316   |\n",
    "| little bit    | 0.010272   |\n",
    "| dont know     | 0.010134   |\n",
    "| looks like    | 0.009707   |\n",
    "| id like       | 0.008441   |\n",
    "| years old     | 0.007860   |\n",
    "| things like   | 0.007416   |\n",
    "| new york      | 0.007234   |\n",
    "\n",
    "Random Forest (bottom 10 feature importance):\n",
    "| Feature      | Importance |\n",
    "|--------------|------------|\n",
    "| ill just     | 0.001656   |\n",
    "| didnt really | 0.001655   |\n",
    "| going work   | 0.001508   |\n",
    "| ’ t          | 0.001504   |\n",
    "| lot things   | 0.001476   |\n",
    "| think youre  | 0.001470   |\n",
    "| know theyre  | 0.001445   |\n",
    "| think going  | 0.001405   |\n",
    "| people make  | 0.001290   |\n",
    "| black hole   | 0.000873   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c35086",
   "metadata": {},
   "source": [
    "## Merging into a single dataframe\n",
    "\n",
    "We will merge the dataframes before our countvectorization process.\n",
    "\n",
    "Let's first drop all non-numerical columns (other than the columns we will be doing our CountVectorizing on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40793695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non numerical columns\n",
    "ready_to_merge_numerical_df = merged_cleaved_df.select_dtypes(include=['int64', 'float64'])\n",
    "ready_to_merge_numerical_df.drop([\"talk_id\"], axis=1, inplace=True) # Dropping the talk_id column\n",
    "ready_to_merge_numerical_df.drop([\"likes\"], axis=1, inplace=True) # Dropping the likes column\n",
    "ready_to_merge_numerical_df.drop([\"view\"], axis=1, inplace=True) # Dropping the view column\n",
    "ready_to_merge_numerical_df.info()\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0a686",
   "metadata": {},
   "source": [
    "We now have a dataframe to which we can merge the topics and occupations dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e46679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the shape of the topics_df and ready_to_merge_numerical_df\n",
    "print(topics_df.shape)\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf86a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As all three dataframes have the same shape, we'll reset their indexes and merge them together\n",
    "# Reset the index of each DataFrame to ensure alignment\n",
    "topics_df_reset = topics_df.reset_index(drop=True)\n",
    "ready_to_merge_numerical_df_reset = ready_to_merge_numerical_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_merged_df = pd.concat([topics_df_reset, ready_to_merge_numerical_df_reset], axis=1)\n",
    "dummy_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3791fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = dummy_merged_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "dummy_merged_df['good_speech'] = (dummy_merged_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition\n",
    "\n",
    "dummy_merged_df.drop([\"percent_likes\"], axis=1, inplace=True) # Dropping the percent_likes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['comments', 'duration', 'num_question_marks',\n",
    "       'questions_per_minute', 'num_laughs', 'laughs_per_minute']\n",
    "\n",
    "# Scale the selected columns and replace in the dataframe\n",
    "dummy_merged_df[columns_to_scale] = scaler.fit_transform(dummy_merged_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dummy_merged_df.drop(\"good_speech\", axis=1)\n",
    "y=dummy_merged_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a031dd4",
   "metadata": {},
   "source": [
    "## Logistic Regression on Numerical Columns, and Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef011e37",
   "metadata": {},
   "source": [
    "We will use this as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5367b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f49c3",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Check if the length of feature names matches the length of coefficients\n",
    "if len(feature_names) == len(coefficients):\n",
    "    # Create a pandas DataFrame for easier manipulation\n",
    "    coefficients_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame to show features with the highest coefficient values at the top\n",
    "    coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "    # Display the top N most impactful features\n",
    "    print(coefficients_df.head(10))  # Adjust the number of features you want to display\n",
    "    print(coefficients_df.tail(10))\n",
    "else:\n",
    "    print(\"Mismatch in the length of feature names and coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4a39b",
   "metadata": {},
   "source": [
    "## Random Forest Classifier on Numerical Columns, and Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(X_train, y_train)\n",
    "test_score_rf = random_forest.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "# This assumes that 'bagofwords_transcript' was used to transform the data fed into the Random Forest\n",
    "feature_names = bagofwords_transcript.get_feature_names_out()\n",
    "\n",
    "# Check if the length of feature names matches the length of feature importances\n",
    "if len(feature_names) == len(feature_importances):\n",
    "    # Create a pandas DataFrame for easier manipulation and visualization\n",
    "    features_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame to show the most important features at the top\n",
    "    features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display the top N most important features\n",
    "    print(features_df.head(10))\n",
    "    print(features_df.tail(10))  \n",
    "else:\n",
    "    print(\"Mismatch in the length of feature names and importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7418a",
   "metadata": {},
   "source": [
    "## Only Topics\n",
    "\n",
    "Results:\n",
    "\n",
    "Logistic Regression:\n",
    "| Metric      | Score           |\n",
    "|-------------|-----------------|\n",
    "| Train score | 0.6415165165165165 |\n",
    "| Test score  | 0.6036036036036037 |\n",
    "\n",
    "\n",
    "Random Forest:\n",
    "| Metric      | Score           |\n",
    "|-------------|-----------------|\n",
    "| Train score | 0.9973723723723724 |\n",
    "| Test score  | 0.6171171171171171 |\n",
    "\n",
    "\n",
    "\n",
    "Logistic Regression (Top 10 Coefficients)\n",
    "| Feature          | Coefficient |\n",
    "|------------------|-------------|\n",
    "| society          | 0.036170    |\n",
    "| personal growth  | 0.024280    |\n",
    "| work             | 0.021501    |\n",
    "| social change    | 0.021344    |\n",
    "| business         | 0.018442    |\n",
    "| leadership       | 0.017648    |\n",
    "| psychology       | 0.017092    |\n",
    "| humanity         | 0.016840    |\n",
    "| education        | 0.015957    |\n",
    "| communication    | 0.015277    |\n",
    "\n",
    "Logistic Regression (Bottom 10 Coefficients)\n",
    "| Feature       | Coefficient |\n",
    "|---------------|-------------|\n",
    "| Africa        | -0.011622   |\n",
    "| india         | -0.011786   |\n",
    "| live music    | -0.012104   |\n",
    "| war           | -0.014104   |\n",
    "| technology    | -0.015705   |\n",
    "| TEDx          | -0.017136   |\n",
    "| art           | -0.018498   |\n",
    "| science       | -0.019425   |\n",
    "| design        | -0.027372   |\n",
    "| global issues | -0.045442   |\n",
    "\n",
    "\n",
    "Random Forest (Top 10 Features):\n",
    "| Feature       | Importance |\n",
    "|---------------|------------|\n",
    "| technology    | 0.015786   |\n",
    "| TEDx          | 0.015405   |\n",
    "| culture       | 0.015356   |\n",
    "| global issues | 0.012585   |\n",
    "| science       | 0.011720   |\n",
    "| design        | 0.011125   |\n",
    "| business      | 0.010850   |\n",
    "| entertainment | 0.009887   |\n",
    "| society       | 0.009571   |\n",
    "| art           | 0.009509   |\n",
    "\n",
    "\n",
    "\n",
    "Random Forest (Bottom 10 Features):\n",
    "| Feature         | Importance |\n",
    "|-----------------|------------|\n",
    "| skateboarding   | 0.000060   |\n",
    "| cooperation     | 0.000047   |\n",
    "| autism          | 0.000026   |\n",
    "| cloud           | 0.000018   |\n",
    "| start-up        | 0.000016   |\n",
    "| evil            | 0.000006   |\n",
    "| Social Science  | 0.000005   |\n",
    "| rap             | 0.000002   |\n",
    "| exoskeleton     | 0.000000   |\n",
    "| neurology       | 0.000000   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea8eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c23d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dropping the non numerical columns\n",
    "only_topics_df = ready_to_merge_numerical_df[[\"percent_likes\"]]\n",
    "print(only_topics_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119d896",
   "metadata": {},
   "source": [
    "We now have a dataframe to which we can merge the topics and occupations dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "40403f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330, 449)\n",
      "(3330, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets check the shape of the topics_df and ready_to_merge_numerical_df\n",
    "print(topics_df.shape)\n",
    "print(only_topics_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6e257cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As all three dataframes have the same shape, we'll reset their indexes and merge them together\n",
    "# Reset the index of each DataFrame to ensure alignment\n",
    "topics_df_reset = topics_df.reset_index(drop=True)\n",
    "only_topics_df_reset = only_topics_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c08c9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3330, 450)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_merged_df = pd.concat([topics_df_reset, only_topics_df_reset], axis=1)\n",
    "dummy_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9d0394cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column called 'good_speech' that is 1 if the speech is in the top 50% of percent_likes, and 0 if it is in the bottom 50% of percent_likes\n",
    "\n",
    "# Calculate the 50th percentile (median) of the 'percent_likes' column\n",
    "median_percent_likes = dummy_merged_df['percent_likes'].mean()\n",
    "\n",
    "# Create the 'good_speech' column based on the condition\n",
    "dummy_merged_df['good_speech'] = (dummy_merged_df['percent_likes'] >= median_percent_likes).astype(int)\n",
    "\n",
    "# Now, merged_cleaved_df has a new column 'good_speech' with 1s and 0s based on the condition\n",
    "\n",
    "dummy_merged_df.drop([\"percent_likes\"], axis=1, inplace=True) # Dropping the percent_likes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scaling the data\n",
    "\n",
    "# # Initialize the Min-Max Scaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # List of columns to scale\n",
    "# columns_to_scale = ['comments', 'duration', 'num_question_marks',\n",
    "#        'questions_per_minute', 'num_laughs', 'laughs_per_minute']\n",
    "\n",
    "# # Scale the selected columns and replace in the dataframe\n",
    "# dummy_merged_df[columns_to_scale] = scaler.fit_transform(dummy_merged_df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "071f9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dummy_merged_df.drop(\"good_speech\", axis=1)\n",
    "y=dummy_merged_df[\"good_speech\"]\n",
    "\n",
    "# train/test split should be conducted before Vectorization\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75adea6",
   "metadata": {},
   "source": [
    "## Logistic Regression on Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835ea27",
   "metadata": {},
   "source": [
    "We will use this as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3acd89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.6415165165165165\n",
      "Test score: 0.6036036036036037\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "logreg = LogisticRegression(C = 0.001, max_iter=1000, n_jobs=-1) \n",
    "\n",
    "#Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "print(f\"Train score: {logreg.score(X_train, y_train)}\")\n",
    "print(f\"Test score: {logreg.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07910d68",
   "metadata": {},
   "source": [
    "What are the features with the highest coefficients (which features were most impactful in the model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "01ae24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "388          society     0.036170\n",
      "328  personal growth     0.024280\n",
      "443             work     0.021501\n",
      "386    social change     0.021344\n",
      "108         business     0.018442\n",
      "259       leadership     0.017648\n",
      "358       psychology     0.017092\n",
      "233         humanity     0.016840\n",
      "169        education     0.015957\n",
      "125    communication     0.015277\n",
      "           Feature  Coefficient\n",
      "3           Africa    -0.011622\n",
      "240          india    -0.011786\n",
      "263     live music    -0.012104\n",
      "435            war    -0.014104\n",
      "411     technology    -0.015705\n",
      "57            TEDx    -0.017136\n",
      "78             art    -0.018498\n",
      "372        science    -0.019425\n",
      "156         design    -0.027372\n",
      "214  global issues    -0.045442\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "# Extracting coefficients\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Check if the length of feature names matches the length of coefficients\n",
    "if len(feature_names) == len(coefficients):\n",
    "    # Create a pandas DataFrame for easier manipulation\n",
    "    coefficients_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame to show features with the highest coefficient values at the top\n",
    "    coefficients_df = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "    # Display the top N most impactful features\n",
    "    print(coefficients_df.head(10))  # Adjust the number of features you want to display\n",
    "    print(coefficients_df.tail(10))\n",
    "else:\n",
    "    print(\"Mismatch in the length of feature names and coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4dcf6915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_mapping = {\n",
    "    'society': 'Society',\n",
    "    'personal growth': 'Personal Growth',\n",
    "    'work': 'Work',\n",
    "    'social change': 'Social Change',\n",
    "    'business': 'Business',\n",
    "    'TEDx': 'Tedx',\n",
    "    'art': 'Art',\n",
    "    'science': 'Science',\n",
    "    'design': 'Design',\n",
    "    'global issues': 'Global Issues'\n",
    "}\n",
    "\n",
    "# Apply the name mapping to the 'Feature' column\n",
    "coefficients_df['Feature'] = coefficients_df['Feature'].map(name_mapping).fillna(coefficients_df['Feature'])\n",
    "\n",
    "# Extracting top 5 and bottom 5 coefficients\n",
    "top_5 = coefficients_df.head(5)\n",
    "bottom_5 = coefficients_df.tail(5)\n",
    "\n",
    "# Combining top 5 and bottom 5 for plotting\n",
    "combined_df = pd.concat([top_5, bottom_5])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=combined_df, palette=\"coolwarm\")\n",
    "plt.title('TED Talk Topics and Their Impact on Speech Rating')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('TED Talk Topics')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731ee13",
   "metadata": {},
   "source": [
    "## Random Forest Classifier on Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aebcd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9973723723723724\n",
      "Test score: 0.6171171171171171\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Random Forest model\n",
    "# n_estimators is the number of trees in the forest, max_depth is the maximum depth of the trees\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "# Note: Random Forest handles the feature importance internally, so scaling is not as critical as in logistic regression\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Training and test score\n",
    "train_score_rf = random_forest.score(X_train, y_train)\n",
    "test_score_rf = random_forest.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score_rf}\")\n",
    "print(f\"Test score: {test_score_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bd09ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Importance\n",
      "411     technology    0.015786\n",
      "57            TEDx    0.015405\n",
      "145        culture    0.015356\n",
      "214  global issues    0.012585\n",
      "372        science    0.011720\n",
      "156         design    0.011125\n",
      "108       business    0.010850\n",
      "176  entertainment    0.009887\n",
      "388        society    0.009571\n",
      "78             art    0.009509\n",
      "            Feature  Importance\n",
      "383   skateboarding    0.000060\n",
      "135     cooperation    0.000047\n",
      "85           autism    0.000026\n",
      "120           cloud    0.000018\n",
      "398        start-up    0.000016\n",
      "180            evil    0.000006\n",
      "41   Social Science    0.000005\n",
      "363             rap    0.000002\n",
      "184     exoskeleton    0.000000\n",
      "306       neurology    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Extracting feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Getting feature names from the CountVectorizer\n",
    "# This assumes that 'bagofwords_transcript' was used to transform the data fed into the Random Forest\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Check if the length of feature names matches the length of feature importances\n",
    "if len(feature_names) == len(feature_importances):\n",
    "    # Create a pandas DataFrame for easier manipulation and visualization\n",
    "    features_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "\n",
    "    # Sort the DataFrame to show the most important features at the top\n",
    "    features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display the top N most important features\n",
    "    print(features_df.head(10))\n",
    "    print(features_df.tail(10))  \n",
    "else:\n",
    "    print(\"Mismatch in the length of feature names and importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c453a",
   "metadata": {},
   "source": [
    "### Various Visualizations\n",
    "\n",
    "#### Questions/Laughs/Words per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of seaborn for better visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a scatter plot for 'questions_per_minute'\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['questions_per_minute'], color='blue', alpha=0.5, label='Questions per Minute')\n",
    "\n",
    "# Create a scatter plot for 'laughs_per_minute' on the same axes\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['laughs_per_minute'], color='red', alpha=0.5, label='Laughs per Minute')\n",
    "\n",
    "# Create a scatter plot for 'words_per_minute' on the same axes\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['words_per_minute'], color='green', alpha=0.5, label='Words per Minute')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Questions, Laughs, and Words per Minute vs Percent Likes')\n",
    "plt.xlabel('Percent Likes')\n",
    "plt.ylabel('Frequency per Minute')\n",
    "\n",
    "# Adding legend to distinguish the groups\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734239f",
   "metadata": {},
   "source": [
    "We will have to scale this data to get a better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['questions_per_minute', 'laughs_per_minute', 'words_per_minute', 'percent_likes']\n",
    "\n",
    "# Scale the selected columns and replace in the dataframe\n",
    "merged_cleaved_df[columns_to_scale] = scaler.fit_transform(merged_cleaved_df[columns_to_scale])\n",
    "\n",
    "# Set the style of seaborn for better visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create scatter plots for the scaled variables\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['words_per_minute'], color='green', alpha=0.3, label='Words per Minute')\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['questions_per_minute'], color='blue', alpha=0.3, label='Questions per Minute')\n",
    "plt.scatter(merged_cleaved_df['percent_likes'], merged_cleaved_df['laughs_per_minute'], color='red', alpha=0.3, label='Laughs per Minute')\n",
    "\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Questions, Laughs, and Words per Minute vs Percent Likes (Scaled)')\n",
    "plt.xlabel('Percent Likes (Scaled)')\n",
    "plt.ylabel('Frequency per Minute (Scaled)')\n",
    "\n",
    "# Adding legend to distinguish the groups\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bdf9d",
   "metadata": {},
   "source": [
    "## Percent_Likes Correlation: Correlating with Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'percent_likes' to the topics DataFrame for correlation analysis\n",
    "topics_with_likes = pd.concat([topics_df, merged_cleaved_df['percent_likes'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Calculating the correlation\n",
    "correlation = topics_with_likes.corr()['percent_likes']\n",
    "\n",
    "# Dropping 'percent_likes' correlation with itself\n",
    "correlation = correlation.drop(labels=['percent_likes'])\n",
    "\n",
    "# Sorting the correlations to find the top 100 topics\n",
    "top_20_topics = correlation.sort_values(ascending=False).head(20)\n",
    "bottom_20_topics = correlation.sort_values(ascending=True).head(20)\n",
    "\n",
    "# Displaying the top 100 topics\n",
    "print(top_20_topics)\n",
    "print(bottom_20_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba3de2",
   "metadata": {},
   "source": [
    "## Percent_Likes Correlation: Correlating with Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c37719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'percent_likes' to the occupations DataFrame for correlation analysis\n",
    "occupations_with_likes = pd.concat([occupations_df, merged_cleaved_df['percent_likes'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Calculating the correlation\n",
    "correlation = occupations_with_likes.corr()['percent_likes']\n",
    "\n",
    "# Dropping 'percent_likes' correlation with itself\n",
    "correlation = correlation.drop(labels=['percent_likes'])\n",
    "\n",
    "# Sorting the correlations to find the top 100 topics\n",
    "top_20_topics = correlation.sort_values(ascending=False).head(20)\n",
    "bottom_20_topics = correlation.sort_values(ascending=True).head(20)\n",
    "\n",
    "# Displaying the top 100 topics\n",
    "print(top_20_topics)\n",
    "print(bottom_20_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd8643",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19538a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 topics with highest positive correlation\n",
    "top_10_positive_topics = top_20_topics.head(10)\n",
    "\n",
    "# Top 10 topics with highest negative correlation\n",
    "# Remember, in bottom_100_topics, the most negative correlations are at the end, so we use tail()\n",
    "top_10_negative_topics = bottom_20_topics.tail(10)\n",
    "\n",
    "# Plotting the top 10 topics with highest positive correlation\n",
    "plt.figure(figsize=(10, 3))\n",
    "top_10_positive_topics.plot(kind='bar')\n",
    "plt.title('Top 10 Topics with Highest Positive Correlation with Percent Likes')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the top 10 topics with highest negative correlation\n",
    "plt.figure(figsize=(10, 3))\n",
    "top_10_negative_topics.plot(kind='bar')\n",
    "plt.title('Top 10 Topics with Highest Negative Correlation with Percent Like NOTE I DID THIS WRONG!!!')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f22975",
   "metadata": {},
   "source": [
    "## Percent_Likes Correlation: Correlating with Various Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged_cleaved_df[['questions_per_minute', 'laughs_per_minute', 'words_per_minute', 'percent_likes', 'ted_mainstage', 'published_year', 'published_month', 'recorded_year', 'recorded_month']].corr()\n",
    "print(correlation['percent_likes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea08437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your actual DataFrame here\n",
    "# merged_cleaved_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation = merged_cleaved_df[['published_year', 'published_month', 'recorded_year', 'recorded_month', 'percent_likes']].corr()\n",
    "\n",
    "# Extracting the correlation of specified columns with 'percent_likes'\n",
    "correlation_with_percent_likes = correlation['percent_likes'].drop('percent_likes', errors='ignore')\n",
    "\n",
    "# Plotting a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_with_percent_likes.plot(kind='bar')\n",
    "plt.title('Correlation with Percent Likes')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xlabel('Dates')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d903f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for 'published_year' and 'recorded_year'\n",
    "published_year_dummies = pd.get_dummies(merged_cleaved_df['published_year'], prefix='pub_year')\n",
    "recorded_year_dummies = pd.get_dummies(merged_cleaved_df['recorded_year'], prefix='rec_year')\n",
    "\n",
    "# Combining the dummy variables with 'percent_likes'\n",
    "combined_df = pd.concat([merged_cleaved_df['percent_likes'], published_year_dummies, recorded_year_dummies], axis=1)\n",
    "\n",
    "# Calculating the correlation\n",
    "correlation = combined_df.corr()\n",
    "\n",
    "# Extracting correlation with 'percent_likes' and removing the self-correlation\n",
    "correlation_with_percent_likes = correlation['percent_likes'].drop('percent_likes', errors='ignore')\n",
    "\n",
    "# Sorting the correlations to find the top ones\n",
    "sorted_correlation = correlation_with_percent_likes.sort_values(ascending=False)\n",
    "\n",
    "# Plotting the top correlations for 'published_year' and 'recorded_year'\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 12))\n",
    "\n",
    "# Top correlations for 'published_year'\n",
    "top_published_year = sorted_correlation.filter(like='pub_year').head(10)\n",
    "top_published_year.plot(kind='bar', ax=axes[0], color='blue')\n",
    "axes[0].set_title('Top 10 Correlations with Percent Likes - Published Year')\n",
    "axes[0].set_ylabel('Correlation Coefficient')\n",
    "\n",
    "# Top correlations for 'recorded_year'\n",
    "top_recorded_year = sorted_correlation.filter(like='rec_year').head(10)\n",
    "top_recorded_year.plot(kind='bar', ax=axes[1], color='green')\n",
    "axes[1].set_title('Top 10 Correlations with Percent Likes - Recorded Year')\n",
    "axes[1].set_ylabel('Correlation Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14180795",
   "metadata": {},
   "source": [
    "# Linear Regression on Various Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3fc8f822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3330 entries, 0 to 3993\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   comments              3330 non-null   float64\n",
      " 1   duration              3330 non-null   int64  \n",
      " 2   multiple_speakers     3330 non-null   int64  \n",
      " 3   percent_likes         3330 non-null   float64\n",
      " 4   ted_mainstage         3330 non-null   int64  \n",
      " 5   word_count            3330 non-null   int64  \n",
      " 6   words_per_minute      3330 non-null   float64\n",
      " 7   num_question_marks    3330 non-null   int64  \n",
      " 8   questions_per_minute  3330 non-null   float64\n",
      " 9   num_laughs            3330 non-null   int64  \n",
      " 10  laughs_per_minute     3330 non-null   float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 312.2 KB\n",
      "(3330, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dropping the non numerical columns\n",
    "ready_to_merge_numerical_df = merged_cleaved_df.select_dtypes(include=['int64', 'float64'])\n",
    "ready_to_merge_numerical_df.drop([\"talk_id\"], axis=1, inplace=True) # Dropping the talk_id column\n",
    "ready_to_merge_numerical_df.drop([\"likes\"], axis=1, inplace=True) # Dropping the likes column\n",
    "#ready_to_merge_numerical_df.drop([\"good_speech\"], axis=1, inplace=True) # Dropping the good_speech column\n",
    "ready_to_merge_numerical_df.drop([\"view\"], axis=1, inplace=True) # Dropping the view column\n",
    "ready_to_merge_numerical_df.info()\n",
    "print(ready_to_merge_numerical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0af8476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comments', 'duration', 'multiple_speakers', 'percent_likes',\n",
       "       'ted_mainstage', 'word_count', 'words_per_minute', 'num_question_marks',\n",
       "       'questions_per_minute', 'num_laughs', 'laughs_per_minute'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_to_merge_numerical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a0c6514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.010225277514163689\n",
      "                       Coefficient\n",
      "laughs_per_minute     6.814619e-03\n",
      "ted_mainstage         1.581614e-05\n",
      "num_question_marks    3.066136e-06\n",
      "comments              1.793214e-07\n",
      "word_count            1.076774e-08\n",
      "duration             -3.118684e-08\n",
      "num_laughs           -5.117746e-06\n",
      "words_per_minute     -2.340765e-05\n",
      "multiple_speakers    -1.061302e-04\n",
      "questions_per_minute -9.702146e-04\n"
     ]
    }
   ],
   "source": [
    "# Dropping the 'transcript' column\n",
    "\n",
    "# Selecting the independent and dependent variables\n",
    "X = ready_to_merge_numerical_df.drop('percent_likes', axis=1)\n",
    "y = ready_to_merge_numerical_df['percent_likes']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Displaying the coefficients\n",
    "coefficients = pd.DataFrame(model.coef_, X_train.columns, columns=['Coefficient']).sort_values(by='Coefficient', ascending=False)\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "afeca642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+IAAAK7CAYAAAB27DXAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACaWklEQVR4nOzdd3xO9///8ecViexhR6wgYobYs7YPTe3aM+VDUVTN0tYIrVGbUt/6SGjVKKrVKopEzZpRatYeUWoktSU5vz/cXD+XDEmkJ60+7rfbdbvlvK/3eZ/XOUn+eF7v9zmXxTAMQwAAAAAAwBR2GV0AAAAAAAD/JgRxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAANJRWFiYLBaL9u7dm2Sfs2fPymKxKCwszLzC0lFERIQsFov1lSlTJuXIkUNNmjRJ9rxfNk9+12fPns2Q48fHx+vzzz9X/fr1lT17djk4OChnzpxq3Lix1qxZo/j4+L/s2A8fPlSvXr2UO3duZcqUSYGBgZKkGzduqF27dsqZM6csFouaN28uSbJYLBo9enSqjmHW/8mXX36p6dOn/6XHAIBn2Wd0AQAA/Nvkzp1bO3fuVOHChTO6lBfy0UcfqU6dOnr06JEOHDigMWPGqFatWoqMjFSRIkUyury/3GuvvaadO3cqd+7cph/7/v37at68uTZs2KB27dpp7ty58vb21rVr17Ru3Tq1bt1ay5YtU7Nmzf6S48+dO1fz5s3TrFmzVL58ebm5uUmSxo4dq6+//loLFixQ4cKFlTVrVknSzp07lTdv3lQdw6z/ky+//FKHDx/WgAED/tLjAMDTCOIAAJjM0dFRVapUyegyknX37l25uLgk26dIkSLW83jllVfk5eWlrl276osvvtCYMWPMKNMqJfWmtxw5cihHjhymHvOJgQMHav369Vq4cKG6dOli817Lli01ZMgQ3bt37y87/uHDh+Xs7Ky+ffsmaC9cuLA6duxo056Wv/d/wv8JAKQVS9MBADBZYktuR48eLYvFol9//VXt27eXp6encuXKpW7duik6Otpmf8MwNGfOHAUGBsrZ2VlZsmRRq1atdPr0aZt+P/74o5o1a6a8efPKyclJfn5+evPNN/XHH3/Y9Hty7P3796tVq1bKkiVLmmYhK1SoIEn6/fffbdpPnjypDh06KGfOnHJ0dFTx4sX1ySefJNj/119/1X/+8x+5uLgoR44ceuutt/T999/LYrEoIiLC2q927doqVaqUfvrpJ1WrVk0uLi7q1q2bJCkmJkaDBw9WwYIFlTlzZuXJk0cDBgzQnTt3bI711VdfqXLlyvL09JSLi4sKFSpkHUN6vOx73LhxKlq0qJydneXl5aXSpUtrxowZ1j5JLU1fsGCBypQpIycnJ2XNmlUtWrTQ0aNHbfoEBwfLzc1Nv/32m4KCguTm5qZ8+fJp0KBBevDgQbLX+cqVK5o/f74aNmyYIIQ/UaRIEZUuXdq6ff78eXXq1MnmdzBlypQEy9cfPnyocePGqVixYnJ0dFSOHDn0xhtv6Nq1a9Y+FotF8+fP171796y3Jzy5Fhs3btTRo0et7U9+b4ktTb906ZJ69uypfPnyKXPmzPLx8VGrVq2sfz9JLU1Pyd/Tk9snlixZovfee08+Pj7y8PBQ/fr1dfz4cWu/2rVr6/vvv9e5c+dsbrd4Yu7cuSpTpozc3Nzk7u6uYsWKacSIEcn+fgAgJZgRBwDgb+T1119X27Zt1b17dx06dEjDhw+X9DjcPfHmm28qLCxM/fv318SJE3Xjxg2FhISoWrVqOnjwoHLlyiVJOnXqlKpWrar//ve/8vT01NmzZzV16lTVqFFDhw4dkoODg82xW7ZsqXbt2qlXr14JgmtKnDlzRpLk7+9vbTty5IiqVaum/Pnza8qUKfL29tb69evVv39//fHHHxo1apQkKSoqSrVq1ZKrq6vmzp2rnDlzasmSJQlmXJ+IiopSp06dNHToUH300Ueys7PT3bt3VatWLV28eFEjRoxQ6dKl9euvv2rkyJE6dOiQNm7cKIvFop07d6pt27Zq27atRo8eLScnJ507d06bN2+2jj9p0iSNHj1a77//vmrWrKlHjx7p2LFjunXrVrLXYPz48RoxYoTat2+v8ePH6/r16xo9erSqVq2qPXv22CzZf/TokZo2baru3btr0KBB+umnnzR27Fh5enpq5MiRSR4jPDxcjx49st5//TzXrl1TtWrV9PDhQ40dO1a+vr767rvvNHjwYJ06dUpz5syR9PjDh2bNmmnr1q0aOnSoqlWrpnPnzmnUqFGqXbu29u7dK2dnZ+3cuVNjx45VeHi49ZoVLFhQO3fuVJ8+fRQdHa3FixdLkkqUKJFoTZcuXVLFihX16NEj6+/q+vXrWr9+vW7evGn9G35WSv+enhgxYoSqV6+u+fPnKyYmRsOGDVOTJk109OhRZcqUSXPmzFHPnj116tQpff311zb7Ll26VH369FG/fv00efJk2dnZ6bffftORI0dSdN0BIFkGAABIN6GhoYYkY8+ePUn2OXPmjCHJCA0NtbaNGjXKkGRMmjTJpm+fPn0MJycnIz4+3jAMw9i5c6chyZgyZYpNvwsXLhjOzs7G0KFDEz1mfHy88ejRI+PcuXOGJOObb75JcOyRI0em6BzDw8MNScayZcuMR48eGXfv3jW2b99uFC1a1ChRooRx8+ZNa9+GDRsaefPmNaKjo23G6Nu3r+Hk5GTcuHHDMAzDGDJkiGGxWIxff/3Vpl/Dhg0NSUZ4eLi1rVatWoYkY9OmTTZ9x48fb9jZ2SW49itWrDAkGWvXrjUMwzAmT55sSDJu3bqV5Dk2btzYCAwMTPY6PPldnzlzxjAMw7h586bh7OxsBAUF2fQ7f/684ejoaHTo0MHa1rVrV0OSsXz5cpu+QUFBRtGiRZM97oQJEwxJxrp165Lt98S7775rSDJ+/vlnm/bevXsbFovFOH78uGEYhrFkyRJDkrFy5Uqbfnv27DEkGXPmzLGp39XVNcGxatWqZZQsWTJBuyRj1KhR1u1u3boZDg4OxpEjR5KsO7H/k5T+PT35G332d7F8+XJDkrFz505r22uvvWYUKFAgwfH79u1reHl5JVkfALwIlqYDAPA30rRpU5vt0qVL6/79+7p69aok6bvvvpPFYlGnTp0UGxtrfXl7e6tMmTI2S7ivXr2qXr16KV++fLK3t5eDg4MKFCggSQmWSkuPZ+NTo23btnJwcJCLi4uqV6+umJgYff/99/Ly8pL0+IFimzZtUosWLeTi4mJTb1BQkO7fv69du3ZJkrZs2aJSpUolmEFt3759osfOkiWL6tata9P23XffqVSpUgoMDLQ5VsOGDW2WSVesWFGS1KZNGy1fvlyXLl1KMH6lSpV08OBB9enTR+vXr1dMTMxzr8fOnTt17949BQcH27Tny5dPdevW1aZNm2zaLRaLmjRpYtNWunRpnTt37rnHSo3NmzerRIkSqlSpkk17cHCwDMOwzmp/99138vLyUpMmTWyuX2BgoLy9vW3+tl7UDz/8oDp16qh48eIp3ic1f09PJPb/JClF17hSpUq6deuW2rdvr2+++SbBLR0A8CII4gAA/I1ky5bNZtvR0VGSrA/e+v3332UYhnLlyiUHBweb165du6xhIT4+Xv/5z3+0atUqDR06VJs2bdLu3butQSWxB3ml9unfEydO1J49e7Rlyxa99957+v3339W8eXPrPc7Xr19XbGysZs2alaDWoKAgSbLWe/369USXIye1RDmxWn///Xf98ssvCY7l7u4uwzCsx6pZs6ZWr16t2NhYdenSRXnz5lWpUqW0ZMkS61jDhw/X5MmTtWvXLr366qvKli2b6tWrl+zXs12/fj3J2nx8fKzvP+Hi4iInJyebNkdHR92/fz/JY0hS/vz5Jf3/WwGe5/r160nW9HTdv//+u27duqXMmTMnuIZXrlxJ1yB67dq1VD9FPTV/T0887/8pOZ07d9aCBQt07tw5vf7668qZM6cqV66sH3/8MVV1A0BiuEccAIB/kOzZs8tisWjr1q3WUPG0J22HDx/WwYMHFRYWpq5du1rf/+2335Ic++mHVKVEoUKFrA9oq1mzppydnfX+++9r1qxZGjx4sLJkyaJMmTKpc+fOeuuttxIdo2DBgpIeB6ZnH/ImPX4wWUprzZ49u5ydnW3up3/2/SeaNWumZs2a6cGDB9q1a5fGjx+vDh06yNfXV1WrVpW9vb0GDhyogQMH6tatW9q4caNGjBihhg0b6sKFC4k+of1J6IuKikrw3uXLl22O/yLq1KkjBwcHrV69Wr169Xpu/2zZsiVZk/T/r0v27NmVLVs2rVu3LtFx3N3dX6BqWzly5NDFixdTtU9q/p7SyxtvvKE33nhDd+7c0U8//aRRo0apcePGOnHihHV1CQCkBUEcAIB/kMaNG2vChAm6dOmS2rRpk2S/J0H12bA+b968v6y2oUOHKiwsTBMmTNCbb74pd3d31alTRwcOHFDp0qWVOXPmJPetVauWJk+erCNHjtgsT1+6dGmKj9+4cWN99NFHypYtW4oDmaOjo2rVqiUvLy+tX79eBw4cUNWqVW36eHl5qVWrVrp06ZIGDBigs2fPJvoQsqpVq8rZ2VlffPGFWrdubW2/ePGiNm/erFatWqX4XJLj7e2t//73v5o7d64WLVqU6JPTT506pTt37qh06dKqV6+exo8fr/3796tcuXLWPosWLZLFYlGdOnUkPb5+S5cuVVxcnCpXrpwutSbl1Vdf1eeff67jx4+raNGiKdrHxcUlxX9PqeHo6PjcGXJXV1e9+uqrevjwoZo3b65ff/2VIA7ghRDEAQD4C2zevDnB11pJsi6hTavq1aurZ8+eeuONN7R3717VrFlTrq6uioqK0rZt2xQQEKDevXurWLFiKly4sN59910ZhqGsWbNqzZo1f+myWgcHB3300Udq06aNZsyYoffff18zZsxQjRo19Morr6h3797y9fXVn3/+qd9++01r1qyx3p88YMAALViwQK+++qpCQkKUK1cuffnllzp27Jgkyc7u+XfTDRgwQCtXrlTNmjX1zjvvqHTp0oqPj9f58+e1YcMGDRo0SJUrV9bIkSN18eJF1atXT3nz5tWtW7c0Y8YMOTg4qFatWpKkJk2aqFSpUqpQoYJy5Mihc+fOafr06SpQoIDNk8+f5uXlpQ8++EAjRoxQly5d1L59e12/fl1jxoyRk5NTgid6v4ipU6fq9OnTCg4O1vr169WiRQvlypVLf/zxh3788UeFhoZq6dKlKl26tN555x0tWrRIr732mkJCQlSgQAF9//33mjNnjnr37m19yn27du20ePFiBQUF6e2331alSpXk4OCgixcvKjw8XM2aNVOLFi3Spf6QkBD98MMPqlmzpkaMGKGAgADdunVL69at08CBA1WsWLFE90vp31NqBAQEaNWqVZo7d67Kly8vOzs7VahQQT169JCzs7OqV6+u3Llz68qVKxo/frw8PT2tzxkAgLQiiAMA8BcYNmxYou0pva83OfPmzVOVKlU0b948zZkzR/Hx8fLx8VH16tWtD+RycHDQmjVr9Pbbb+vNN9+Uvb296tevr40bN1rvMf4rtG7dWpUrV9bUqVPVr18/lShRQvv379fYsWP1/vvv6+rVq/Ly8lKRIkVsPpTw8fHRli1bNGDAAPXq1UsuLi5q0aKFQkJC1LVrV+sD4JLj6uqqrVu3asKECfq///s/nTlzRs7OzsqfP7/q168vX19fSVLlypW1d+9eDRs2TNeuXZOXl5cqVKigzZs3q2TJkpIeL/9euXKl9WuvvL291aBBA33wwQcJvvbtacOHD1fOnDk1c+ZMLVu2TM7Ozqpdu7Y++uijJAN8Wjg5Oen777/X4sWLtXDhQr355puKiYlRlixZVKFCBS1YsMD6ILgcOXJox44dGj58uIYPH66YmBgVKlRIkyZN0sCBA61jZsqUSd9++61mzJihzz//XOPHj5e9vb3y5s2rWrVqKSAgIN3qz5Mnj3bv3q1Ro0ZpwoQJun79unLkyKEaNWooa9asSe6X0r+n1Hj77bf166+/asSIEYqOjpZhGDIMQ6+88orCwsK0fPly3bx5U9mzZ1eNGjW0aNEi5ciRI62nDgCSJIthGEZGFwEAAJCYnj17asmSJbp+/Xq6LUUGACCjMSMOAAD+FkJCQuTj46NChQrp9u3b+u677zR//ny9//77hHAAwEuFIA4AAP4WHBwc9PHHH+vixYuKjY1VkSJFNHXqVL399tsZXRoAAOmKpekAAAAAAJjo+Y8gBQAAAAAA6YYgDgAAAACAiQjiAAAAAACYiIe1AWkUHx+vy5cvy93dXRaLJaPLAQAAAJBBDMPQn3/+KR8fH9nZPX++myAOpNHly5eVL1++jC4DAAAAwN/EhQsXlDdv3uf2I4gDaeTu7i7p8T+bh4dHBlcDAAAAIKPExMQoX7581ozwPARxII2eLEf38PAgiAMAAABI8S2rPKwNAAAAAAATEcQBAAAAADARQRwAAAAAABNxjzgApEDvkZEZXQIAAACeMTckMKNLSBNmxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFB/B+gdu3aGjBgQEaXYQpfX19Nnz49o8sAAAAAgL8MQTwZwcHBat68eUaXke7CwsJksVisr9y5c6tNmzY6c+ZMuh+rdu3aslgsmjBhQoL3goKCZLFYNHr0aGvbnj171LNnz3StYfTo0QoMDEzXMQEAAAAgrQji/1IeHh6KiorS5cuX9eWXXyoyMlJNmzZVXFxcmsZ79OhRku/ly5dPoaGhNm2XL1/W5s2blTt3bpv2HDlyyMXFJU01AAAAAMA/AUH8BUydOlUBAQFydXVVvnz51KdPH92+fdv6fmIzsdOnT5evr691OzY2Vv3795eXl5eyZcumYcOGqWvXrglm4uPj4zV06FBlzZpV3t7eNrPIT46VP39+OTo6ysfHR/3790+2dovFIm9vb+XOnVt16tTRqFGjdPjwYf3222+SpDVr1qh8+fJycnJSoUKFNGbMGMXGxtrs/+mnn6pZs2ZydXXVuHHjkjxW48aNdf36dW3fvt3aFhYWpv/85z/KmTOnTd9nl6ZbLBbNnz9fLVq0kIuLi4oUKaJvv/3WZhwvLy+bMVavXi2LxWJ9f8yYMTp48KB1BUBYWJgkKTo6Wj179lTOnDnl4eGhunXr6uDBg8leNwAAAAB4UQTxF2BnZ6eZM2fq8OHDWrhwoTZv3qyhQ4emaoyJEydq8eLFCg0N1fbt2xUTE6PVq1cn6Ldw4UK5urrq559/1qRJkxQSEqIff/xRkrRixQpNmzZN8+bN08mTJ7V69WoFBASkqg5nZ2dJj2e2169fr06dOql///46cuSI5s2bp7CwMH344Yc2+4waNUrNmjXToUOH1K1btyTHzpw5szp27GgzKx4WFpbsPk8bM2aM2rRpo19++UVBQUHq2LGjbty4kaJ927Ztq0GDBqlkyZKKiopSVFSU2rZtK8Mw9Nprr+nKlStau3at9u3bp3LlyqlevXpJjv3gwQPFxMTYvAAAAAAgtQjiL2DAgAGqU6eOChYsqLp162rs2LFavnx5qsaYNWuWhg8frhYtWqhYsWKaPXt2ghleSSpdurRGjRqlIkWKqEuXLqpQoYI2bdokSTp//ry8vb1Vv3595c+fX5UqVVKPHj1SXMPFixf18ccfK2/evPL399eHH36od999V127dlWhQoXUoEEDjR07VvPmzbPZr0OHDurWrZsKFSqkAgUKJHuM7t27a/ny5bpz545++uknRUdH67XXXktRfcHBwWrfvr38/Pz00Ucf6c6dO9q9e3eK9nV2dpabm5vs7e3l7e0tb29vOTs7Kzw8XIcOHdJXX32lChUqqEiRIpo8ebK8vLy0YsWKRMcaP368PD09ra98+fKlqAYAAAAAeBpB/AWEh4erQYMGypMnj9zd3dWlSxddv35dd+7cSdH+0dHR+v3331WpUiVrW6ZMmVS+fPkEfUuXLm2znTt3bl29elWS1Lp1a927d0+FChVSjx499PXXX9ssI0/q2G5ubtZl9Q8fPtSqVauUOXNm7du3TyEhIXJzc7O+evTooaioKN29e9c6RoUKFVJ0nk/qL1KkiFasWKEFCxaoc+fOcnBwSPG+T7i6usrd3d167mm1b98+3b59W9myZbM5zzNnzujUqVOJ7jN8+HBFR0dbXxcuXHihGgAAAAD8O9lndAH/VOfOnVNQUJB69eqlsWPHKmvWrNq2bZu6d+9ufXCZnZ2dDMOw2S+xh5o9uZ/5iWf3kZQgtFosFsXHx0t6/DC048eP68cff9TGjRvVp08fffzxx9qyZUuSYdfd3V379++XnZ2dcuXKJVdXV+t78fHxGjNmjFq2bJlgPycnJ+vPT++TEt26ddMnn3yiI0eOpHhGW0r+3FN6jZ8VHx+v3LlzKyIiIsF7ia1IkCRHR0c5OjqmrGgAAAAASAJBPI327t2r2NhYTZkyRXZ2jxcWPLssPUeOHLpy5YoMw7CG7cjISOv7np6eypUrl3bv3q1XXnlFkhQXF6cDBw6k+uu2nJ2d1bRpUzVt2lRvvfWWihUrpkOHDqlcuXKJ9rezs5Ofn1+i75UrV07Hjx9P8v206tChgwYPHqwyZcqoRIkS6TJmjhw59Oeff+rOnTvWDwaevsbS43vUn30afLly5XTlyhXZ29vbPDwPAAAAAP5qBPHniI6OThDssmbNqsKFCys2NlazZs1SkyZNtH37dn366ac2/WrXrq1r165p0qRJatWqldatW6cffvhBHh4e1j79+vXT+PHj5efnp2LFimnWrFm6efNmglny5ISFhSkuLk6VK1eWi4uLPv/8czk7Oz/3vu2kjBw5Uo0bN1a+fPnUunVr2dnZ6ZdfftGhQ4eSfTr682TJkkVRUVEpXpKeEk/OecSIEerXr592795tfSr6E76+vjpz5owiIyOVN29eubu7q379+qpataqaN2+uiRMnqmjRorp8+bLWrl2r5s2bp2rZPQAAAACkBveIP0dERITKli1r8xo5cqQCAwM1depUTZw4UaVKldLixYs1fvx4m32LFy+uOXPm6JNPPlGZMmW0e/duDR482KbPsGHD1L59e3Xp0kVVq1aVm5ubGjZsaLME/Hm8vLz02WefqXr16ipdurQ2bdqkNWvWKFu2bGk654YNG+q7777Tjz/+qIoVK6pKlSqaOnVqmoP9s7Wmdkl7crJmzaovvvhCa9euVUBAgJYsWZLgq91ef/11NWrUSHXq1FGOHDm0ZMkSWSwWrV27VjVr1lS3bt3k7++vdu3a6ezZs8qVK1e61QcAAAAAz7IYid2QjAwTHx+v4sWLq02bNho7dmxGl4NkxMTEyNPTU9HR0TarHPBy6j0yMqNLAAAAwDPmhgRmdAmSUp8NWJqewc6dO6cNGzaoVq1aevDggWbPnq0zZ86oQ4cOGV0aAAAAAOAvwNL0DGZnZ6ewsDBVrFhR1atX16FDh7Rx40YVL148o0sDAAAAAPwFmBHPYPny5dP27dszugwAAAAAgEmYEQcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATGSf0QUAwD/B3JDAjC4BAAAALwlmxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAUuCjsMsZXQIAAABeEgRxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBBHugoODlbz5s0zugwAAAAA+NsiiGcQi8WS7Cs4ODjZfkuXLpUkRUREWNvs7Ozk6empsmXLaujQoYqKikq2hrNnz8piscje3l6XLl2yeS8qKkr29vayWCw6e/Zsis9rxowZCgsLS82lSJavr6+mT5+ebuMBAAAAQEazz+gC/q2eDsnLli3TyJEjdfz4cWubs7Oz9efQ0FA1atTIZn8vLy+b7ePHj8vDw0MxMTHav3+/Jk2apP/973+KiIhQQEBAsrX4+Pho0aJFGj58uLVt4cKFypMnj86fP5+q8/L09ExVfwAAAAD4t2FGPIN4e3tbX56enrJYLAnanvDy8rJ5z9vbW05OTjbj5cyZU97e3vL391e7du20fft25ciRQ717935uLV27dlVoaKhNW1hYmLp27WrTFhcXp+7du6tgwYJydnZW0aJFNWPGDJs+zy5Nr127tvr376+hQ4cqa9as8vb21ujRo232GT16tPLnzy9HR0f5+Piof//+1n3PnTund955xzrrL0nXr19X+/btlTdvXrm4uCggIEBLliyxGfPPP/9Ux44d5erqqty5c2vatGmqXbu2BgwYYO3z8OFDDR06VHny5JGrq6sqV66siIiI514vAAAAAHgRBPGXlLOzs3r16qXt27fr6tWryfZt2rSpbt68qW3btkmStm3bphs3bqhJkyY2/eLj45U3b14tX75cR44c0ciRIzVixAgtX7482fEXLlwoV1dX/fzzz5o0aZJCQkL0448/SpJWrFihadOmad68eTp58qRWr15tncFftWqV8ubNq5CQEEVFRVlXEdy/f1/ly5fXd999p8OHD6tnz57q3Lmzfv75Z+sxBw4cqO3bt+vbb7/Vjz/+qK1bt2r//v02db3xxhvavn27li5dql9++UWtW7dWo0aNdPLkyUTP48GDB4qJibF5AQAAAEBqsTT9H6B9+/bKlCmTTdsvv/yiQoUKJbtfsWLFJD2+FzxnzpxJ9nNwcFCnTp20YMEC1ahRQwsWLFCnTp3k4OCQoN+YMWOs2wULFtSOHTu0fPlytWnTJsnxS5curVGjRkmSihQpotmzZ2vTpk1q0KCBzp8/L29vb9WvX18ODg7Knz+/KlWqJEnKmjWrMmXKJHd3d3l7e1vHy5MnjwYPHmzd7tevn9atW6evvvpKlStX1p9//qmFCxfqyy+/VL169SQ9Xt7v4+Nj3efUqVNasmSJLl68aG0fPHiw1q1bp9DQUH300UcJzmP8+PE25w8AAAAAaUEQ/weYNm2a6tevb9OWL1++5+5nGIYkWZd0J6d79+6qWrWqPvroI3311VfauXOnYmNjE/T79NNPNX/+fJ07d0737t3Tw4cPFRgYmOzYpUuXttnOnTu3dZa+devWmj59ugoVKqRGjRopKChITZo0kb190n+acXFxmjBhgpYtW6ZLly7pwYMHevDggVxdXSVJp0+f1qNHj6yBXnp873rRokWt2/v375dhGPL397cZ+8GDB8qWLVuixx0+fLgGDhxo3Y6JiUnR7wEAAAAAnkYQ/wfw9vaWn59fqvc7evSopMdPHn+eUqVKqVixYmrfvr2KFy+uUqVKKTIy0qbP8uXL9c4772jKlCmqWrWq3N3d9fHHH9ssCU/MszPrFotF8fHxkh5/oHD8+HH9+OOP2rhxo/r06aOPP/5YW7ZsSbDfE1OmTNG0adM0ffp0BQQEyNXVVQMGDNDDhw8lJf0BxJN26fEy+0yZMmnfvn0JVhu4ubklelxHR0c5Ojome64AAAAA8DwE8ZfUvXv39H//93+qWbOmcuTIkaJ9unXrpj59+mju3LmJvr9161ZVq1ZNffr0sbadOnXqhWt1dnZW06ZN1bRpU7311lsqVqyYDh06pHLlyilz5syKi4tLUEezZs3UqVMnSY9D9cmTJ1W8eHFJUuHCheXg4KDdu3dbZ6xjYmJ08uRJ1apVS5JUtmxZxcXF6erVq3rllVde+BwAAAAAIKUI4v8At27d0pUrV2za3N3drUuxJenq1au6f/++/vzzT+3bt0+TJk3SH3/8oVWrVqX4OD169FDr1q0TfDXaE35+flq0aJHWr1+vggUL6vPPP9eePXtUsGDBNJ2X9Pjp7HFxcapcubJcXFz0+eefy9nZWQUKFJD0eDb/p59+Urt27eTo6Kjs2bPLz89PK1eu1I4dO5QlSxZNnTpVV65csQZxd3d3de3aVUOGDFHWrFmVM2dOjRo1SnZ2dtZZcn9/f3Xs2FFdunTRlClTVLZsWf3xxx/avHmzAgICFBQUlOZzAgAAAIDk8NT0f4A33nhDuXPntnnNmjXLpk/RokXl4+Oj8uXLa8KECapfv74OHz6sEiVKpPg49vb2yp49e5L3Z/fq1UstW7ZU27ZtVblyZV2/ft1mdjwtvLy89Nlnn6l69eoqXbq0Nm3apDVr1ljv0w4JCdHZs2dVuHBh68z+Bx98oHLlyqlhw4aqXbu2vL29bb4yTZKmTp2qqlWrqnHjxqpfv76qV6+u4sWL23ztW2hoqLp06aJBgwapaNGiatq0qX7++Wfu+wYAAADwl7IYT984C7yk7ty5ozx58mjKlCnq3r17uowZExMjT09PRUdHy8PDI13GxN/XR2GXNSLY5/kdAQAA8K+T2mzA0nS8lA4cOKBjx46pUqVKio6OVkhIiCSpWbNmGVwZAAAAgH87gjheWpMnT9bx48eVOXNmlS9fXlu3blX27NkzuiwAAAAA/3IEcbyUypYtq3379mV0GQAAAACQAA9rAwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEASIERwT4ZXQIAAABeEgRxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBBPJ8eOHVOVKlXk5OSkwMDAjC4nzSwWi1avXp3RZaSLs2fPymKxKDIyMqNLAQAAAACrf10Qv3btmhwcHHT37l3FxsbK1dVV58+ff+FxR40aJVdXVx0/flybNm1Kst+FCxfUvXt3+fj4KHPmzCpQoIDefvttXb9+/YVrSI3Ro0cn+oFBVFSUXn311b/02GFhYbJYLCpevHiC95YvXy6LxSJfX9+/tAYAAAAAyCj/uiC+c+dOBQYGysXFRfv27VPWrFmVP3/+Fx731KlTqlGjhgoUKKBs2bIl2uf06dOqUKGCTpw4oSVLlui3337Tp59+qk2bNqlq1aq6cePGC9fxory9veXo6PiXH8fV1VVXr17Vzp07bdoXLFiQLr+Phw8fvvAYAAAAAPBX+NcF8R07dqh69eqSpG3btll/Tk58fLxCQkKUN29eOTo6KjAwUOvWrbO+b7FYtG/fPoWEhMhisWj06NGJjvPWW28pc+bM2rBhg2rVqqX8+fPr1Vdf1caNG3Xp0iW99957NmM+u0Tcy8tLYWFh1u1Lly6pbdu2ypIli7Jly6ZmzZrp7Nmz1vcjIiJUqVIlubq6ysvLS9WrV9e5c+cUFhamMWPG6ODBg7JYLLJYLNZxnz3uoUOHVLduXTk7Oytbtmzq2bOnbt++bX0/ODhYzZs31+TJk5U7d25ly5ZNb731lh49epTsNbW3t1eHDh20YMECa9vFixcVERGhDh062PQ9deqUmjVrply5csnNzU0VK1bUxo0bbfr4+vpq3LhxCg4Olqenp3r06JHgmPHx8erRo4f8/f117tw5SY9XBuTPn1+Ojo7y8fFR//79k60bAAAAAF7UvyKInz9/Xl5eXvLy8tLUqVM1b948eXl5acSIEVq9erW8vLzUp0+fJPefMWOGpkyZosmTJ+uXX35Rw4YN1bRpU508eVLS4+XcJUuW1KBBgxQVFaXBgwcnGOPGjRtav369+vTpI2dnZ5v3vL291bFjRy1btkyGYaTonO7evas6derIzc1NP/30k7Zt2yY3Nzc1atRIDx8+VGxsrJo3b65atWrpl19+0c6dO9WzZ09ZLBa1bdtWgwYNUsmSJRUVFaWoqCi1bds20WM0atRIWbJk0Z49e/TVV19p48aN6tu3r02/8PBwnTp1SuHh4Vq4cKHCwsJsPjBISvfu3bVs2TLdvXtX0uMl640aNVKuXLls+t2+fVtBQUHauHGjDhw4oIYNG6pJkyYJbin4+OOPVapUKe3bt08ffPCBzXsPHz5UmzZttHfvXm3btk0FChTQihUrNG3aNM2bN08nT57U6tWrFRAQkGS9Dx48UExMjM0LAAAAAFLLPqMLMIOPj48iIyMVExOjChUqaNeuXXJzc1NgYKC+//575c+fX25ubknuP3nyZA0bNkzt2rWTJE2cOFHh4eGaPn26PvnkE3l7e8ve3l5ubm7y9vZOdIyTJ0/KMIxE74uWpOLFi+vmzZu6du2acubM+dxzWrp0qezs7DR//nxZLBZJUmhoqLy8vBQREaEKFSooOjpajRs3VuHCha3HeMLNzU329vZJ1itJixcv1r1797Ro0SK5urpKkmbPnq0mTZpo4sSJ1sCcJUsWzZ49W5kyZVKxYsX02muvadOmTYnOSj8tMDBQhQsX1ooVK9S5c2eFhYVp6tSpOn36tE2/MmXKqEyZMtbtcePG6euvv9a3335r86FA3bp1bT4EebI64Pbt23rttdd07949RUREyNPTU9LjD2i8vb1Vv359OTg4KH/+/KpUqVKS9Y4fP15jxoxJ9pwAAAAA4Hn+FTPi9vb28vX11bFjx1SxYkWVKVNGV65cUa5cuVSzZk35+voqe/bsie4bExOjy5cvJ1jCXr16dR09ejTdanwyE545c+YU9d+3b59+++03ubu7y83NTW5ubsqaNavu37+vU6dOKWvWrAoODrbOHs+YMUNRUVGpquno0aMqU6aMNYRLj887Pj5ex48ft7aVLFlSmTJlsm7nzp1bV69eTdExunXrptDQUG3ZssU68/2sO3fuaOjQoSpRooS8vLzk5uamY8eOJZgRr1ChQqLHaN++vW7fvq0NGzZYQ7gktW7dWvfu3VOhQoXUo0cPff3114qNjU2y1uHDhys6Otr6unDhQorOEQAAAACe9q8I4iVLlpSbm5s6d+6s3bt3y83NTfXq1dPZs2fl5uamkiVLPneMJ7POTxiGkaAtOX5+frJYLDpy5Eii7x87dkw5cuSQl5eX9XjPLlN/+r7r+Ph4lS9fXpGRkTavEydOWO+xDg0N1c6dO1WtWjUtW7ZM/v7+2rVrV4prTu4cn253cHBI8F58fHyKjtGxY0ft2rVLo0ePVpcuXWRvn3CRxpAhQ7Ry5Up9+OGH2rp1qyIjIxUQEJDggWxPf2DwtKCgIP3yyy8Jzj1fvnw6fvy4PvnkEzk7O6tPnz6qWbNmkve3Ozo6ysPDw+YFAAAAAKn1rwjia9euVWRkpLy9vfXFF18oMjJSpUqV0vTp0xUZGam1a9cmua+Hh4d8fHy0bds2m/YdO3Ykucw8MdmyZVODBg00Z84c3bt3z+a9K1euaPHixQoODra25ciRw2YG++TJk9Z7qSWpXLlyOnnypHLmzCk/Pz+b19OzvmXLltXw4cO1Y8cOlSpVSl9++aWkxzPvcXFxydZcokQJRUZG6s6dO9a27du3y87OTv7+/ik+9+RkzZpVTZs21ZYtW9StW7dE+2zdulXBwcFq0aKFAgIC5O3tbfNQuufp3bu3JkyYYD3O05ydndW0aVPNnDlTERER2rlzpw4dOvQipwQAAAAAyfpXBPECBQrIzc1Nv//+u5o1a6b8+fPryJEjatmypfz8/FSgQIFk9x8yZIgmTpyoZcuW6fjx43r33XcVGRmpt99+O1V1zJ49Ww8ePFDDhg31008/6cKFC1q3bp0aNGggf39/jRw50tq3bt26mj17tvbv36+9e/eqV69eNjPPHTt2VPbs2dWsWTNt3bpVZ86c0ZYtW/T222/r4sWLOnPmjIYPH66dO3fq3Llz2rBhg06cOGH98MDX11dnzpxRZGSk/vjjDz148CBBvR07dpSTk5O6du2qw4cPKzw8XP369VPnzp0TPFDtRYSFhemPP/5QsWLFEn3fz89Pq1atUmRkpA4ePKgOHTqkeMb9iX79+mncuHFq3Lix9UOVsLAw/e9//9Phw4d1+vRpff7553J2dn7u3wMAAAAAvIh/RRCXHn+VV8WKFeXk5KSff/5ZefLkkY+PT4r27d+/vwYNGqRBgwYpICBA69at07fffqsiRYqkqoYiRYpoz549KlSokNq0aaMCBQro1Vdflb+/v7Zv327zwLgpU6YoX758qlmzpjp06KDBgwfLxcXF+r6Li4t++ukn5c+fXy1btlTx4sXVrVs33bt3Tx4eHnJxcdGxY8f0+uuvy9/fXz179lTfvn315ptvSpJef/11NWrUSHXq1FGOHDm0ZMmSBPW6uLho/fr1unHjhipWrKhWrVqpXr16mj17dqrO+3mefDVaUqZNm6YsWbKoWrVqatKkiRo2bKhy5cql+jgDBgzQmDFjFBQUpB07dsjLy0ufffaZqlevrtKlS2vTpk1as2ZNsrUAAAAAwIuyGCn9viz8JUaNGqWpU6dqw4YNqlq1akaXg1SIiYmRp6enoqOjuV8cAAAA+BdLbTb4V3x92d/ZmDFj5Ovrq59//lmVK1eWnd2/ZpECAAAAAPwrEcT/Bt54442MLgEAAAAAYBKmXwEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADDRSx/Ejx07pipVqsjJyUmBgYGmHTcsLExeXl4Ztj8AAAAA4O/pbxPEr127JgcHB929e1exsbFydXXV+fPnX3jcUaNGydXVVcePH9emTZsSvP/pp5/K3d1dsbGx1rbbt2/LwcFBr7zyik3frVu3ymKx6MSJEy9c1/O0bdvW5jijR49O1w8SwsPDFRQUpGzZssnFxUUlSpTQoEGDdOnSpXQ7xt9NcHCwmjdvntFlAAAAAPiX+9sE8Z07dyowMFAuLi7at2+fsmbNqvz587/wuKdOnVKNGjVUoEABZcuWLcH7derU0e3bt7V3715r29atW+Xt7a09e/bo7t271vaIiAj5+PjI39//het6HmdnZ+XMmfMvGXvevHmqX7++vL29tXLlSh05ckSffvqpoqOjNWXKlL/kmAAAAACAx/42QXzHjh2qXr26JGnbtm3Wn5MTHx+vkJAQ5c2bV46OjgoMDNS6deus71ssFu3bt08hISGyWCwaPXp0gjGKFi0qHx8fRUREWNsiIiLUrFkzFS5cWDt27LBpr1OnjiTp4cOHGjp0qPLkySNXV1dVrlzZZownVq9eLX9/fzk5OalBgwa6cOGC9b2DBw+qTp06cnd3l4eHh8qXL2/9QODppelhYWEaM2aMDh48KIvFIovForCwMElSdHS0evbsqZw5c8rDw0N169bVwYMHk7xmFy9eVP/+/dW/f38tWLBAtWvXlq+vr2rWrKn58+dr5MiR1r4rV65UyZIl5ejoKF9f3wQh3dfXV+PGjVOXLl3k5uamAgUK6JtvvtG1a9fUrFkzubm5KSAgwOZDjifn9d1336lo0aJycXFRq1atdOfOHS1cuFC+vr7KkiWL+vXrp7i4OOt+z7veT8Zdv369ihcvLjc3NzVq1EhRUVGSHq8oWLhwob755hvrNYyIiNDDhw/Vt29f5c6dW05OTvL19dX48eOTvH4AAAAA8MKMDHTu3DnD09PT8PT0NBwcHAwnJyfD09PTyJw5s+Ho6Gh4enoavXv3TnL/qVOnGh4eHsaSJUuMY8eOGUOHDjUcHByMEydOGIZhGFFRUUbJkiWNQYMGGVFRUcaff/6Z6DgdOnQw/vOf/1i3K1asaHz11VdG7969jREjRhiGYRgPHjwwnJ2djfnz51v3qVatmvHTTz8Zv/32m/Hxxx8bjo6O1mOHhoYaDg4ORoUKFYwdO3YYe/fuNSpVqmRUq1bNepySJUsanTp1Mo4ePWqcOHHCWL58uREZGWnd39PT0zAMw7h7964xaNAgo2TJkkZUVJQRFRVl3L1714iPjzeqV69uNGnSxNizZ49x4sQJY9CgQUa2bNmM69evJ3nNJBmXL19O9nezd+9ew87OzggJCTGOHz9uhIaGGs7OzkZoaKi1T4ECBYysWbMan376qXHixAmjd+/ehru7u9GoUSNj+fLlxvHjx43mzZsbxYsXN+Lj422uS4MGDYz9+/cbW7ZsMbJly2b85z//Mdq0aWP8+uuvxpo1a4zMmTMbS5cutfkdpeR6169f39izZ4+xb98+o3jx4kaHDh0MwzCMP//802jTpo3RqFEj6zV88OCB8fHHHxv58uUzfvrpJ+Ps2bPG1q1bjS+//DLRa3L//n0jOjra+rpw4YIhyYiOjk72WgIAAAB4uUVHR6cqG2RoEH/06JFx5swZ4+DBg4aDg4MRGRlp/Pbbb4abm5uxZcsW48yZM8a1a9eS3N/Hx8f48MMPbdoqVqxo9OnTx7pdpkwZY9SoUcnW8X//93+Gq6ur8ejRIyMmJsawt7c3fv/9d2Pp0qXW4LxlyxZDknHq1Cnjt99+MywWi3Hp0iWbcerVq2cMHz7cMIzHwVCSsWvXLuv7R48eNSQZP//8s2EYhuHu7m6EhYUlWtPTQdwwDGPUqFFGmTJlbPps2rTJ8PDwMO7fv2/TXrhwYWPevHmJjtu7d2/Dw8Mj2ethGI+Db4MGDWzahgwZYpQoUcK6XaBAAaNTp07W7aioKEOS8cEHH1jbdu7caUgyoqKirOclyfjtt9+sfd58803DxcXF5oOShg0bGm+++aZhGEaqrvfT437yySdGrly5rNtdu3Y1mjVrZjNGv379jLp161o/KEjOqFGjDEkJXgRxAAAA4N8ttUE8Q5em29vby9fXV8eOHVPFihVVpkwZXblyRbly5VLNmjXl6+ur7NmzJ7pvTEyMLl++nGAJe/Xq1XX06NFU1VGnTh3duXNHe/bs0datW+Xv76+cOXOqVq1a2rNnj+7cuaOIiAjlz59fhQoV0v79+2UYhvz9/eXm5mZ9bdmyRadOnbI5vwoVKli3ixUrJi8vL2t9AwcO1H//+1/Vr19fEyZMsNk3Jfbt26fbt28rW7ZsNnWcOXMmybEMw5DFYnnu2EePHk302p48edJmyXjp0qWtP+fKlUuSFBAQkKDt6tWr1jYXFxcVLlzYpo+vr6/c3Nxs2p7sk9Lr/ey4uXPntjluYoKDgxUZGamiRYuqf//+2rBhQ5J9hw8frujoaOvr6dsMAAAAACCl7DPy4CVLltS5c+f06NEjxcfHy83NTbGxsYqNjbXec/zrr78mO8azoTKlQfNpfn5+yps3r8LDw3Xz5k3VqlVLkuTt7a2CBQtq+/btCg8PV926dSU9vjc9U6ZM2rdvnzJlymQz1tNhMrH6nm4bPXq0OnTooO+//14//PCDRo0apaVLl6pFixYpqjs+Pl65c+dO9N70pL76zN/fX9HR0YqKilLu3LmTHDux62gYRoJ+Dg4O1p+f9E+sLT4+PtF9nvRJrO3JPim93omNkVjNTytXrpzOnDmjH374QRs3blSbNm1Uv359rVixIkFfR0dHOTo6JjseAAAAADxPhs6Ir127VpGRkfL29tYXX3yhyMhIlSpVStOnT1dkZKTWrl2b5L4eHh7y8fHRtm3bbNp37Nih4sWLp7qWOnXqKCIiQhEREapdu7a1vVatWlq/fr127dplfVBb2bJlFRcXp6tXr8rPz8/m5e3tbd03NjbW5kFlx48f161bt1SsWDFrm7+/v9555x1t2LBBLVu2VGhoaKL1Zc6c2WYmWnocIq9cuSJ7e/sEdSS1kqBVq1bKnDmzJk2alOj7t27dkiSVKFEi0Wvr7++fIAz/1VJ6vZ8nsWsoPf5batu2rT777DMtW7ZMK1eu1I0bN9LzFAAAAADAKkNnxAsUKKArV67o999/V7NmzWRnZ6cjR46oZcuW8vHxee7+Q4YM0ahRo1S4cGEFBgYqNDRUkZGRWrx4caprqVOnjt566y09evTIOiMuPQ7ivXv31v37961B3N/fXx07dlSXLl00ZcoUlS1bVn/88Yc2b96sgIAABQUFSXo8Q9uvXz/NnDlTDg4O6tu3r6pUqaJKlSrp3r17GjJkiFq1aqWCBQvq4sWL2rNnj15//fVE6/P19dWZM2cUGRmpvHnzyt3dXfXr11fVqlXVvHlzTZw4UUWLFtXly5e1du1aNW/e3GZZ/BP58uXTtGnT1LdvX8XExKhLly7y9fXVxYsXtWjRIrm5uWnKlCkaNGiQKlasqLFjx6pt27bauXOnZs+erTlz5qT62r6olF7v5/H19dX69et1/PhxZcuWTZ6enpo9e7Zy586twMBA2dnZ6auvvpK3t3eSKwoAAAAA4EVlaBCXHn8lWMWKFeXk5KStW7cqT548KQrhktS/f3/FxMRo0KBBunr1qkqUKKFvv/1WRYoUSXUdderU0b1791SsWDHrfc3S4yD+559/qnDhwsqXL5+1PTQ0VOPGjdOgQYN06dIlZcuWTVWrVrUJhS4uLho2bJg6dOigixcvqkaNGlqwYIEkKVOmTLp+/bq6dOmi33//XdmzZ1fLli01ZsyYROt7/fXXtWrVKtWpU0e3bt1SaGiogoODtXbtWr333nvq1q2brl27Jm9vb9WsWdPmHJ7Vp08f+fv7a/LkyWrRooXu3bsnX19fNW7cWAMHDpT0eLZ9+fLlGjlypMaOHavcuXMrJCREwcHBqb626SEl1/t5evTooYiICFWoUEG3b99WeHi43NzcNHHiRJ08eVKZMmVSxYoVtXbtWtnZ/W2+2Q8AAADAS8ZiPO8mWgCJiomJkaenp6Kjo+Xh4ZHR5QAAAADIIKnNBkz7AQAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIohnAF9fX02fPj2jy0hS7dq1NWDAgIwuI1kRERGyWCy6detWRpcCAAAAAKnyrw7iFosl2VdwcPBz91+9enW61rRu3TpZLBZduXLFpt3b21v58uWzabt48aIsFos2bNiQrjW8qHnz5qlMmTJydXWVl5eXypYtq4kTJ2Z0WQAAAADwt2Cf0QVkpKioKOvPy5Yt08iRI3X8+HFrm7Ozs+k11ahRQ/b29oqIiFC7du0kSUePHtX9+/d17949/fbbb/Lz85MkhYeHy8HBQdWrV0/1cQzDUFxcnOzt0/dP4H//+58GDhyomTNnqlatWnrw4IF++eUXHTlyJF2PAwAAAAD/VP/qGXFvb2/ry9PTUxaLxabtyy+/VOHChZU5c2YVLVpUn3/+uXVfX19fSVKLFi1ksVis26dOnVKzZs2UK1cuubm5qWLFitq4cWOKa3qyT0REhLUtIiJCNWrUUI0aNRK0V6pUSa6urnrw4IH69++vnDlzysnJSTVq1NCePXts+losFq1fv14VKlSQo6Ojtm7dqjt37qhLly5yc3NT7ty5NWXKlAQ1zZkzR0WKFJGTk5Ny5cqlVq1aJVn/mjVr1KZNG3Xv3l1+fn4qWbKk2rdvr7Fjx1r7BAcHq3nz5hozZoxy5swpDw8Pvfnmm3r48KG1z/PO51n37t3Ta6+9pipVqujGjRuSpNDQUBUvXlxOTk4qVqyY5syZY+1/9uxZWSwWrVq1SnXq1JGLi4vKlCmjnTt3JnkMAAAAAEgP/+ognpyvv/5ab7/9tgYNGqTDhw/rzTff1BtvvKHw8HBJsobC0NBQRUVFWbdv376toKAgbdy4UQcOHFDDhg3VpEkTnT9/PsXHrlOnjvU40uOZ79q1a6tWrVoJ2uvUqSNJGjp0qFauXKmFCxdq//798vPzU8OGDa2h9ImhQ4dq/PjxOnr0qEqXLq0hQ4YoPDxcX3/9tTZs2KCIiAjt27fP2n/v3r3q37+/QkJCdPz4ca1bt041a9ZMsnZvb2/t2rVL586dS/YcN23apKNHjyo8PFxLlizR119/rTFjxtjUmZLzkaTo6Gj95z//0cOHD7Vp0yZlzZpVn332md577z19+OGHOnr0qD766CN98MEHWrhwoc2+7733ngYPHqzIyEj5+/urffv2io2NTbTmBw8eKCYmxuYFAAAAAKlmwDAMwwgNDTU8PT2t29WqVTN69Ohh06d169ZGUFCQdVuS8fXXXz937BIlShizZs2ybhcoUMCYNm1akv03bNhgSDIuX75sGIZh5MyZ09i9e7exa9cuw8fHxzAMwzh//rwhydi0aZNx+/Ztw8HBwVi8eLF1jIcPHxo+Pj7GpEmTDMMwjPDwcEOSsXr1amufP//808icObOxdOlSa9v169cNZ2dn4+233zYMwzBWrlxpeHh4GDExMc89T8MwjMuXLxtVqlQxJBn+/v5G165djWXLlhlxcXHWPl27djWyZs1q3Llzx9o2d+5cw83NzYiLi0vV+Rw7dswoU6aM0bJlS+PBgwfW/vny5TO+/PJLm9rGjh1rVK1a1TAMwzhz5owhyZg/f771/V9//dWQZBw9ejTRcxs1apQhKcErOjo6RdcGAAAAwMspOjo6VdmAGfEkHD16NMG919WrV9fRo0eT3e/OnTsaOnSoSpQoIS8vL7m5uenYsWOpmhGvXr26MmfOrIiICB05ckT37t1TuXLlVL58ecXExOjkyZMKDw+Xo6OjqlWrplOnTunRo0c29To4OKhSpUoJ6q1QoYL151OnTunhw4eqWrWqtS1r1qwqWrSodbtBgwYqUKCAChUqpM6dO2vx4sW6e/dukrXnzp1bO3fu1KFDh9S/f389evRIXbt2VaNGjRQfH2/tV6ZMGbm4uFi3q1atqtu3b+vChQupOp/69eurUKFCWr58uTJnzixJunbtmi5cuKDu3bvLzc3N+ho3bpxOnTpls3/p0qVtapekq1evJnpuw4cPV3R0tPV14cKFJK8DAAAAACTlX/2wtuexWCw224ZhJGh71pAhQ7R+/XpNnjxZfn5+cnZ2VqtWrWzuf34eFxcXVapUSeHh4bpx44Zq1KihTJkySZKqVaum8PBw7dy5U1WrVpWTk5MMw0hxva6urjbvP4+7u7v279+viIgIbdiwQSNHjtTo0aO1Z88eeXl5JblfqVKlVKpUKb311lvatm2bXnnlFW3ZssW6lD4pFoslVefz2muvaeXKlTpy5IgCAgIkyRr4P/vsM1WuXNmm/5Pr+ISDg4PNsZ/e/1mOjo5ydHRMtn4AAAAAeB5mxJNQvHhxbdu2zaZtx44dKl68uHXbwcFBcXFxNn22bt2q4OBgtWjRQgEBAfL29tbZs2dTffw6deooIiJCERERql27trW9Vq1a1vYnodbPz0+ZM2e2qffRo0fau3evTb3P8vPzk4ODg3bt2mVtu3nzpk6cOGHTz97eXvXr19ekSZP0yy+/6OzZs9q8eXOKz6VEiRKSHq8WeOLgwYO6d++edXvXrl1yc3NT3rx5U3U+EyZMUNeuXVWvXj3rk9lz5cqlPHny6PTp0/Lz87N5FSxYMMV1AwAAAMBfId1mxG/dupXsDOk/zZAhQ9SmTRuVK1dO9erV05o1a7Rq1SqbJ6D7+vpq06ZNql69uhwdHZUlSxb5+flp1apVatKkiSwWiz744IMkZ1iTU6dOHY0dO1ZRUVEaPHiwtb1WrVqaMGGC/vzzT2sQd3V1Ve/evTVkyBBlzZpV+fPn16RJk3T37l117949yWO4ubmpe/fuGjJkiLJly6ZcuXLpvffek53d//985rvvvtPp06dVs2ZNZcmSRWvXrlV8fLzN8vWn9e7dWz4+Pqpbt67y5s2rqKgojRs3Tjly5LBZAv/w4UN1795d77//vs6dO6dRo0apb9++srOzS/X5TJ48WXFxcapbt64iIiJUrFgxjR49Wv3795eHh4deffVVPXjwQHv37tXNmzc1cODAVP8+AAAAACC9pCmIT5w4Ub6+vmrbtq0kqU2bNlq5cqW8vb21du1alSlTJl2LzAjNmzfXjBkz9PHHH6t///4qWLCgQkNDbWanp0yZooEDB+qzzz5Tnjx5dPbsWU2bNk3dunVTtWrVlD17dg0bNixNT9euWrWqdRl0+fLlre0VK1ZUXFycnJ2dbZZdT5gwQfHx8ercubP+/PNPVahQQevXr1eWLFmSPc7HH3+s27dvq2nTpnJ3d9egQYMUHR1tfd/Ly0urVq3S6NGjdf/+fRUpUkRLlixRyZIlEx2vfv36WrBggebOnavr168re/bsqlq1qjZt2qRs2bJZ+9WrV09FihRRzZo19eDBA7Vr106jR49O8/lMmzbNJoz/97//lYuLiz7++GMNHTpUrq6uCggI0IABA5K9HgAAAADwV7MYKblR+BmFChXSF198oWrVqunHH39UmzZttGzZMi1fvlznz5/Xhg0b/opa8ZIIDg7WrVu3tHr16owu5YXExMTI09NT0dHR8vDwyOhyAAAAAGSQ1GaDNM2IR0VFKV++fJIeL11u06aN/vOf/8jX1zfBw7EAAAAAAMD/l6aHtWXJksX61U3r1q1T/fr1JT1+qvWzDy8DAAAAAAD/X5pmxFu2bKkOHTqoSJEiun79ul599VVJUmRkpPz8/NK1QLx8wsLCMroEAAAAAMgwaQri06ZNk6+vry5cuKBJkybJzc1N0uMl63369EnXAgEAAAAAeJmk6WFtAHhYGwAAAIDHUpsN0nSPuCR9/vnnqlGjhnx8fHTu3DlJ0vTp0/XNN9+kdUgAAAAAAF56aQric+fO1cCBA/Xqq6/q1q1b1ge0eXl5afr06elZHwAAAAAAL5U0BfFZs2bps88+03vvvadMmTJZ2ytUqKBDhw6lW3EAAAAAALxs0hTEz5w5o7JlyyZod3R01J07d164KAAAAAAAXlZpCuIFCxZUZGRkgvYffvhBJUqUeNGaAAAAAAB4aaXp68uGDBmit956S/fv35dhGNq9e7eWLFmi8ePHa/78+eldIwAAAAAAL400BfE33nhDsbGxGjp0qO7evasOHTooT548mjFjhtq1a5feNQIAAAAA8NJIdRCPjY3V4sWL1aRJE/Xo0UN//PGH4uPjlTNnzr+iPgAAAAAAXiqpvkfc3t5evXv31oMHDyRJ2bNnJ4QDAAAAAJBCaXpYW+XKlXXgwIH0rgUAAAAAgJdemu4R79OnjwYNGqSLFy+qfPnycnV1tXm/dOnS6VIcAAAAAAAvG4thGEZqd7KzSziRbrFYZBiGLBaL4uLi0qU44O8sJiZGnp6eio6OloeHR0aXAwAAACCDpDYbpGlG/MyZM2nZDQAAAACAf700BfECBQqkdx0AAAAAAPwrpCmIL1q0KNn3u3TpkqZiAAAAAAB42aXpHvEsWbLYbD969Eh3795V5syZ5eLiohs3bqRbgcDfFfeIAwAAAJBSnw3S9PVlN2/etHndvn1bx48fV40aNbRkyZK0DAkAAAAAwL9CmoJ4YooUKaIJEybo7bffTq8hAQAAAAB46aRbEJekTJky6fLly+k5JAAAAAAAL5U0Pazt22+/tdk2DENRUVGaPXu2qlevni6FAQAAAADwMkpTEG/evLnNtsViUY4cOVS3bl1NmTIlPeoCAAAAAOCllKYgHh8fn951AAAAAADwr5Cme8RDQkJ09+7dBO337t1TSEjICxcFAAAAAMDLKk3fI54pUyZFRUUpZ86cNu3Xr19Xzpw5FRcXl24FAn9XfI84AAAAAMmk7xE3DEMWiyVB+8GDB5U1a9a0DAkAAAAAwL9Cqu4Rz5IliywWiywWi/z9/W3CeFxcnG7fvq1evXqle5EAAAAAALwsUhXEp0+fLsMw1K1bN40ZM0aenp7W9zJnzixfX19VrVo13YsEAAAAAOBlkaog3rVrV0lSwYIFVa1aNTk4OPwlRQEAAAAA8LJK09eX1apVy/rzvXv39OjRI5v3eXAVAAAAAACJS9PD2u7evau+ffsqZ86ccnNzU5YsWWxeAAAAAAAgcWkK4kOGDNHmzZs1Z84cOTo6av78+RozZox8fHy0aNGi9K4RAAAAAICXRpqWpq9Zs0aLFi1S7dq11a1bN73yyivy8/NTgQIFtHjxYnXs2DG96wQAAAAA4KWQphnxGzduqGDBgpIe3w9+48YNSVKNGjX0008/pV91AAAAAAC8ZNIUxAsVKqSzZ89KkkqUKKHly5dLejxT7uXllV61AQAAAADw0klTEH/jjTd08OBBSdLw4cOt94q/8847GjJkSLoWCAAAAADAy8RiGIbxooOcP39ee/fuVeHChVWmTJn0qAv424uJiZGnp6eio6P5yj4AAADgXyy12SBND2t72v3795U/f37lz5//RYcCAAAAAOCll6al6XFxcRo7dqzy5MkjNzc3nT59WpL0wQcf6H//+1+6FggAAAAAwMskTUH8ww8/VFhYmCZNmqTMmTNb2wMCAjR//vx0Kw4AAAAAgJdNmoL4okWL9H//93/q2LGjMmXKZG0vXbq0jh07lm7FAQAAAADwsklTEL906ZL8/PwStMfHx+vRo0cvXBQAAAAAAC+rNAXxkiVLauvWrQnav/rqK5UtW/aFiwIAAAAA4GWVpqemjxo1Sp07d9alS5cUHx+vVatW6fjx41q0aJG+++679K4RAAAAAICXRqpmxE+fPi3DMNSkSRMtW7ZMa9eulcVi0ciRI3X06FGtWbNGDRo0+KtqBQAAAADgHy9VM+JFihRRVFSUcubMqYYNG2rBggX67bff5O3t/VfVBwAAAADASyVVM+KGYdhs//DDD7p79266FgTzhYWFycvLK6PLkCStXr1afn5+ypQpkwYMGJDu41ssFq1evVqSdPbsWVksFkVGRqb7cQAAAAAgKWl6WNsTzwZzJC04OFgWi0UWi0UODg7KlSuXGjRooAULFig+Pt60Onx9fTV9+nSbtrZt2+rEiROm1ZCcN998U61atdKFCxc0duxYm/ciIiKs1zCpV1hYWMYUDgAAAAAplKql6U/CzrNtSJlGjRopNDRUcXFx+v3337Vu3Tq9/fbbWrFihb799lvZ26fp2XkyDENxcXFp3t/Z2VnOzs5p2jc93b59W1evXlXDhg3l4+OT4P1q1aopKirKuv32228rJiZGoaGh1jZPT09TagUAAACAtEr10vTg4GC1bNlSLVu21P3799WrVy/r9pMXEufo6Chvb2/lyZNH5cqV04gRI/TNN9/ohx9+sM7kJrZc+tatW7JYLIqIiJD0/2eG169frwoVKsjR0VFbt27VqVOn1KxZM+XKlUtubm6qWLGiNm7caB2ndu3aOnfunN555x2bD1USW5o+d+5cFS5cWJkzZ1bRokX1+eef27xvsVg0f/58tWjRQi4uLipSpIi+/fbbZM//5s2b6tKli7JkySIXFxe9+uqrOnnypPWc3N3dJUl169a1Od8nMmfOLG9vb+vL2dnZek29vb114cIFNW3aVNmzZ5enp6dq1aql/fv3p+RXI0mKj49Xjx495O/vr3PnzqV4PwAAAABIjVQF8a5duypnzpzy9PSUp6enOnXqJB8fH+v2kxdSrm7duipTpoxWrVqV6n2HDh2q8ePH6+jRoypdurRu376toKAgbdy4UQcOHFDDhg3VpEkTnT9/XpK0atUq5c2bVyEhIYqKirKZXX7a119/rbfffluDBg3S4cOH9eabb+qNN95QeHi4Tb8xY8aoTZs2+uWXXxQUFKSOHTvqxo0bSdYbHBysvXv36ttvv9XOnTtlGIaCgoL06NEjVatWTcePH5ckrVy5UlFRUapWrVqqrseff/6prl27auvWrdq1a5eKFCmioKAg/fnnn8/d9+HDh2rTpo327t2rbdu2qUCBAgn6PHjwQDExMTYvAAAAAEitVK1lfnoJMNJPsWLF9Msvv6R6v5CQEJuvi8uWLZvKlClj3R43bpy+/vprffvtt+rbt6+yZs2qTJkyyd3dPdkn3U+ePFnBwcHq06ePJGngwIHatWuXJk+erDp16lj7BQcHq3379pKkjz76SLNmzdLu3bvVqFGjBGOePHlS3377rbZv324N2IsXL1a+fPm0evVqtW7dWjlz5pQkZc2aNU1P4q9bt67N9rx585QlSxZt2bJFjRs3TnK/27dv67XXXtO9e/cUERGR5IdJ48eP15gxY1JdFwAAAAA87YUe1ob0YRhGmu61r1Chgs32nTt3NHToUJUoUUJeXl5yc3PTsWPHrDPiKXX06FFVr17dpq169eo6evSoTVvp0qWtP7u6usrd3V1Xr15Nckx7e3tVrlzZ2pYtWzYVLVo0wbhpdfXqVfXq1Uv+/v7W1Rm3b99+7vm3b99et2/f1oYNG5Jd0TF8+HBFR0dbXxcuXEiXugEAAAD8u6Tt6V5IV0ePHlXBggUlSXZ2jz8befqJ9I8ePUp0P1dXV5vtIUOGaP369Zo8ebL8/Pzk7OysVq1a6eHDh6mu6dkPBhL7sMDBwSHBPkk9AT6pJ+yn9UOIxAQHB+vatWuaPn26ChQoIEdHR1WtWvW55x8UFKQvvvhCu3btSjCr/jRHR0c5OjqmS60AAAAA/r2YEc9gmzdv1qFDh/T6669LknLkyCFJNvdvp/R7rrdu3arg4GC1aNFCAQEB8vb21tmzZ236ZM6cWXFxccmOU7x4cW3bts2mbceOHSpevHiK6khMiRIlFBsbq59//tnadv36dZ04ceKFxn3a1q1b1b9/fwUFBalkyZJydHTUH3/88dz9evfurQkTJqhp06basmVLutQCAAAAAElhRtxEDx480JUrV2y+vmz8+PFq3LixunTpIunxV4lVqVJFEyZMkK+vr/744w+9//77KRrfz89Pq1atUpMmTWSxWPTBBx8kmKH29fXVTz/9pHbt2snR0VHZs2dPMM6QIUPUpk0blStXTvXq1dOaNWu0atUqmyewp1aRIkXUrFkz9ejRQ/PmzZO7u7veffdd5cmTR82aNUvzuE/z8/PT559/rgoVKigmJkZDhgxJ8dey9evXT3FxcWrcuLF++OEH1ahRI11qAgAAAIBnMSNuonXr1il37tzy9fVVo0aNFB4erpkzZ+qbb75RpkyZrP0WLFigR48eqUKFCnr77bc1bty4FI0/bdo0ZcmSRdWqVVOTJk3UsGFDlStXzqZPSEiIzp49q8KFC1tn35/VvHlzzZgxQx9//LFKliypefPmKTQ0VLVr107zuUuPH/ZXvnx5NW7cWFWrVpVhGFq7dm2CJe5ptWDBAt28eVNly5ZV586d1b9/f+sD4FJiwIABGjNmjIKCgrRjx450qQkAAAAAnmUxkrp5F0CyYmJi5OnpqejoaHl4eGR0OQAAAAAySGqzATPiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCCOVDl27JiqVKkiJycnBQYGZnQ5yapdu7YGDBiQ0WUAAAAAgA2C+Evq2rVrcnBw0N27dxUbGytXV1edP3/+hccdNWqUXF1ddfz4cW3atCnRPsHBwWrevPkLHwsAAAAAXkYE8ZfUzp07FRgYKBcXF+3bt09Zs2ZV/vz5X3jcU6dOqUaNGipQoICyZcuWDpUCAAAAwL8LQfwltWPHDlWvXl2StG3bNuvPyYmPj1dISIjy5s0rR0dHBQYGat26ddb3LRaL9u3bp5CQEFksFo0ePTpNtU2dOlUBAQFydXVVvnz51KdPH92+fdv6/ujRoxMse58+fbp8fX2t27Gxserfv7+8vLyULVs2DRs2TF27dk0wEx8fH6+hQ4cqa9as8vb2TlDz6NGjlT9/fjk6OsrHx0f9+/dP0zkBAAAAQEoRxF8i58+fl5eXl7y8vDR16lTNmzdPXl5eGjFihFavXi0vLy/16dMnyf1nzJihKVOmaPLkyfrll1/UsGFDNW3aVCdPnpQkRUVFqWTJkho0aJCioqI0ePDgNNVpZ2enmTNn6vDhw1q4cKE2b96soUOHpmqMiRMnavHixQoNDdX27dsVExOj1atXJ+i3cOFCubq66ueff9akSZMUEhKiH3/8UZK0YsUKTZs2TfPmzdPJkye1evVqBQQEJHnMBw8eKCYmxuYFAAAAAKlln9EFIP34+PgoMjJSMTExqlChgnbt2iU3NzcFBgbq+++/V/78+eXm5pbk/pMnT9awYcPUrl07SY/Dbnh4uKZPn65PPvlE3t7esre3l5ubm7y9vdNc59MPUCtYsKDGjh2r3r17a86cOSkeY9asWRo+fLhatGghSZo9e7bWrl2boF/p0qU1atQoSVKRIkU0e/Zsbdq0SQ0aNND58+fl7e2t+vXry8HBQfnz51elSpWSPOb48eM1ZsyYFNcIAAAAAIlhRvwlYm9vL19fXx07dkwVK1ZUmTJldOXKFeXKlUs1a9aUr6+vsmfPnui+MTExunz5coIl7NWrV9fRo0fTtc7w8HA1aNBAefLkkbu7u7p06aLr16/rzp07Kdo/Ojpav//+u01ozpQpk8qXL5+gb+nSpW22c+fOratXr0qSWrdurXv37qlQoULq0aOHvv76a8XGxiZ53OHDhys6Otr6unDhQorqBQAAAICnEcRfIiVLlpSbm5s6d+6s3bt3y83NTfXq1dPZs2fl5uamkiVLPncMi8Vis20YRoK2F3Hu3DkFBQWpVKlSWrlypfbt26dPPvlEkvTo0SNJj5euG4Zhs9+T955X67McHBwS7BMfHy9Jypcvn44fP65PPvlEzs7O6tOnj2rWrJnosSTJ0dFRHh4eNi8AAAAASC2C+Etk7dq1ioyMlLe3t7744gtFRkaqVKlSmj59uiIjIxNduv2Eh4eHfHx8tG3bNpv2HTt2qHjx4ulW4969exUbG6spU6aoSpUq8vf31+XLl2365MiRQ1euXLEJ1pGRkdafPT09lStXLu3evdvaFhcXpwMHDqS6HmdnZzVt2lQzZ85URESEdu7cqUOHDqX+xAAAAAAghbhH/CVSoEABXblyRb///ruaNWsmOzs7HTlyRC1btpSPj89z9x8yZIhGjRqlwoULKzAwUKGhoYqMjNTixYtTXUt0dLRNeJakrFmzqnDhwoqNjdWsWbPUpEkTbd++XZ9++qlNv9q1a+vatWuaNGmSWrVqpXXr1umHH36wmYHu16+fxo8fLz8/PxUrVkyzZs3SzZs3UzV7HxYWpri4OFWuXFkuLi76/PPP5ezsrAIFCqT6fAEAAAAgpZgRf8lERESoYsWKcnJy0s8//6w8efKkKIRLUv/+/TVo0CANGjRIAQEBWrdunb799lsVKVIkTXWULVvW5jVy5EgFBgZq6tSpmjhxokqVKqXFixdr/PjxNvsWL15cc+bM0SeffKIyZcpo9+7dCZ7QPmzYMLVv315dunRR1apV5ebmpoYNG8rJySnFNXp5eemzzz5T9erVVbp0aW3atElr1qzh+9EBAAAA/KUsRmI31gL/MPHx8SpevLjatGmjsWPHmnLMmJgYeXp6Kjo6mvvFAQAAgH+x1GYDlqbjH+ncuXPasGGDatWqpQcPHmj27Nk6c+aMOnTokNGlAQAAAECyWJqOfyQ7OzuFhYWpYsWKql69ug4dOqSNGzem64PlAAAAAOCvwIw4/pHy5cun7du3Z3QZAAAAAJBqzIgDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAAAAAAJiKIAwAAAABgIoI4AAAAAAAmIogDAAAAAGAigjgAAAAAACYiiAMAAAAAYCKCOAAk48qymbqybGZGlwEAAICXCEEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcRfUrVr19aAAQOs276+vpo+fXqK+/8bRUREyGKx6NatWxldCgAAAICXGEH8b8pisST7Cg4OTtfjrVq1SmPHjk3XMRNz+vRptW/fXj4+PnJyclLevHnVrFkznThx4i8/NgAAAAD8HdhndAFIXFRUlPXnZcuWaeTIkTp+/Li1zdnZOV2PlzVr1nQdLzEPHz5UgwYNVKxYMa1atUq5c+fWxYsXtXbtWkVHR//lxwcAAACAvwNmxP+mvL29rS9PT09ZLBbrtoODg3r16qW8efPKxcVFAQEBWrJkSarGDw0Nlaenp3788UdJiS9l/+ijj9StWze5u7srf/78+r//+z+bMXbs2KHAwEA5OTmpQoUKWr16tSwWiyIjIxM95pEjR3T69GnNmTNHVapUUYECBVS9enV9+OGHqlixoiTp7NmzslgsWrp0qapVqyYnJyeVLFlSERERCcYKCgqSm5ubcuXKpc6dO+uPP/6wvm8YhiZNmqRChQrJ2dlZZcqU0YoVK2zGWLt2rfz9/eXs7Kw6dero7NmzqbqGAAAAAJAWBPF/oPv376t8+fL67rvvdPjwYfXs2VOdO3fWzz//nKL9J0+erMGDB2v9+vVq0KBBkv2mTJmiChUq6MCBA+rTp4969+6tY8eOSZL+/PNPNWnSRAEBAdq/f7/Gjh2rYcOGJXvcHDlyyM7OTitWrFBcXFyyfYcMGaJBgwbpwIEDqlatmpo2barr169LerxaoFatWgoMDNTevXu1bt06/f7772rTpo11//fff1+hoaGaO3eufv31V73zzjvq1KmTtmzZIkm6cOGCWrZsqaCgIEVGRuq///2v3n333WRrevDggWJiYmxeAAAAAJBaBPF/oDx58mjw4MEKDAxUoUKF1K9fPzVs2FBfffXVc/cdPny4pk6dqoiICFWpUiXZvkFBQerTp4/8/Pw0bNgwZc+e3TozvXjxYlksFn322WcqUaKEXn31VQ0ZMuS5dc+cOVMjR45UlixZVLduXY0dO1anT59O0Ldv3756/fXXVbx4cc2dO1eenp763//+J0maO3euypUrp48++kjFihVT2bJltWDBAoWHh+vEiRO6c+eOpk6dqgULFqhhw4YqVKiQgoOD1alTJ82bN886RqFChTRt2jQVLVpUHTt2fO599+PHj5enp6f1lS9fvmT7AwAAAEBiuEf8HyguLk4TJkzQsmXLdOnSJT148EAPHjyQq6trsvtNmTJFd+7c0d69e1WoUKHnHqd06dLWn58sjb969aok6fjx4ypdurScnJysfSpVqvTcMd966y116dJF4eHh+vnnn/XVV1/po48+0rfffmszO1+1alXrz/b29qpQoYKOHj0qSdq3b5/Cw8Pl5uaWYPxTp04pOjpa9+/fTzDb//DhQ5UtW1aSdPToUVWpUkUWiyXRYyZm+PDhGjhwoHU7JiaGMA4AAAAg1Qji/0BTpkzRtGnTNH36dAUEBMjV1VUDBgzQw4cPk93vlVde0ffff6/ly5c/dxm2JDk4ONhsWywWxcfHS3p8D/bTIfZJW0q4u7uradOmatq0qcaNG6eGDRtq3LhxyS6Tf3J8SYqPj1eTJk00ceLEBH1y586tw4cPS5K+//575cmTx+Z9R0fHVNX67L5P9gcAAACAtCKI/wNt3bpVzZo1U6dOnSQ9DqYnT55U8eLFk92vUqVK1mXsmTJleu5S8uQUK1ZMixcv1oMHD6zhdO/evakex2KxqFixYtqxY4dN+65du1SzZk1JUmxsrPbt26e+fftKksqVK6eVK1fK19dX9vYJ/4RLlCghR0dHnT9/XrVq1Ur0uCVKlNDq1asTHBMAAAAA/mrcI/4P5Ofnpx9//FE7duzQ0aNH9eabb+rKlSsp2rdq1ar64YcfFBISomnTpqW5hg4dOig+Pl49e/bU0aNHtX79ek2ePFmSEsyUPxEZGalmzZppxYoVOnLkiH777Tf973//04IFC9SsWTObvp988om+/vprHTt2TG+99ZZu3rypbt26SXq8vP3GjRtq3769du/erdOnT2vDhg3q1q2b4uLi5O7ursGDB+udd97RwoULderUKR04cECffPKJFi5cKEnq1auXTp06pYEDB+r48eP68ssvFRYWlubrAQAAAAApxYz4P9AHH3ygM2fOqGHDhnJxcVHPnj3VvHnzFH8Xd/Xq1fX9998rKChImTJlUv/+/VNdg4eHh9asWaPevXsrMDBQAQEBGjlypDp06GBz3/jT8ubNK19fX40ZM8b6NWVPtt955x2bvhMmTNDEiRN14MABFS5cWN98842yZ88uSfLx8dH27ds1bNgwNWzYUA8ePFCBAgXUqFEj2dk9/mxp7Nixypkzp8aPH6/Tp0/Ly8tL5cqV04gRIyRJ+fPn18qVK/XOO+9ozpw5qlSpkvXr2gAAAADgr2Qx0nKzLJCIxYsX64033lB0dLScnZ3TNMbZs2dVsGBBHThwQIGBgelbYDqLiYmRp6enoqOj5eHhkdHl4C9yZdlMSZJ329R/YAUAAIB/h9RmA2bEkWaLFi1SoUKFlCdPHh08eFDDhg1TmzZt0hzCAQAAAODfgCCONLty5YpGjhypK1euKHfu3GrdurU+/PDDjC4LAAAAAP7WWJoOpBFL0/8dWJoOAACA50ltNuCp6QAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiQjiAAAAAACYiCAOAAAAAICJCOIAAAAAAJiIIA4AAAAAgIkI4gAAAAAAmIggDgAAAACAiewzugAA+Dvzbts/o0sAAADAS4YZcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwEQEcQAAAAAATEQQBwAAAADARARxAAAAAABMRBAHAAAAAMBEBHEAAAAAAExEEAcAAAAAwET2GV0AAGSkE+MHpaif//Apf3ElAAAA+LdgRhwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQRwAAAAAABMRxAEAAAAAMBFBHAAAAAAAExHEAQAAAAAwEUEcAAAAAAATEcQBAAAAADARQfxvwGKxaPXq1cn2CQ4OVvPmzVM1rq+vr6ZPn57muv5OwsLC5OXlldFlAAAAAMALI4inUnBwsCwWi3r16pXgvT59+shisSg4ODjN4589e1YWi0WRkZE27TNmzFBYWFiax02r8PBw1alTR1mzZpWLi4uKFCmirl27KjY21vRaAAAAAOBlQBBPg3z58mnp0qW6d++ete3+/ftasmSJ8ufP/5cc09PT0/QZ4V9//VWvvvqqKlasqJ9++kmHDh3SrFmz5ODgoPj4eFNrSW+GYfBhAgAAAIAMQRBPg3Llyil//vxatWqVtW3VqlXKly+fypYta9M3seXhgYGBGj16dKJjFyxYUJJUtmxZWSwW1a5dW1LCpem1a9dW37591bdvX3l5eSlbtmx6//33ZRhGknVHR0erZ8+eypkzpzw8PFS3bl0dPHgwyf4//vijcufOrUmTJqlUqVIqXLiwGjVqpPnz5ytz5syS/v+S8dWrV8vf319OTk5q0KCBLly4YDPWmjVrVL58eTk5OalQoUIaM2aMTRCeOnWqAgIC5Orqqnz58qlPnz66fft2krVdv35dlSpVUtOmTXX//n0ZhqFJkyapUKFCcnZ2VpkyZbRixQpr/4iICFksFq1fv14VKlSQo6Ojtm7dqoMHD6pOnTpyd3eXh4eHypcvr7179yZ5XAAAAAB4UQTxNHrjjTcUGhpq3V6wYIG6dev2wuPu3r1bkrRx40ZFRUXZhP1nLVy4UPb29vr55581c+ZMTZs2TfPnz0+0r2EYeu2113TlyhWtXbtW+/btU7ly5VSvXj3duHEj0X28vb0VFRWln376Kdma7969qw8//FALFy7U9u3bFRMTo3bt2lnfX79+vTp16qT+/fvryJEjmjdvnsLCwvThhx9a+9jZ2WnmzJk6fPiwFi5cqM2bN2vo0KGJHu/ixYt65ZVXVKxYMa1atUpOTk56//33FRoaqrlz5+rXX3/VO++8o06dOmnLli02+w4dOlTjx4/X0aNHVbp0aXXs2FF58+bVnj17tG/fPr377rtycHBI9LgPHjxQTEyMzQsAAAAAUss+owv4p+rcubOGDx9uvad7+/btWrp0qSIiIl5o3Bw5ckiSsmXLJm9v72T75suXT9OmTZPFYlHRokV16NAhTZs2TT169EjQNzw8XIcOHdLVq1fl6OgoSZo8ebJWr16tFStWqGfPngn2ad26tdavX69atWrJ29tbVapUUb169dSlSxd5eHhY+z169EizZ89W5cqVJT3+gKB48eLavXu3KlWqpA8//FDvvvuuunbtKkkqVKiQxo4dq6FDh2rUqFGSpAEDBljHK1iwoMaOHavevXtrzpw5NjWdOHFCDRo0ULNmzTRjxgxZLBbduXNHU6dO1ebNm1W1alXrMbZt26Z58+apVq1a1v1DQkLUoEED6/b58+c1ZMgQFStWTJJUpEiRJK/3+PHjNWbMmCTfBwAAAICUYEY8jbJnz67XXntNCxcuVGhoqF577TVlz57d1BqqVKkii8Vi3a5atapOnjypuLi4BH337dun27dvK1u2bHJzc7O+zpw5o1OnTiU6fqZMmRQaGqqLFy9q0qRJ8vHx0YcffqiSJUsqKirK2s/e3l4VKlSwbhcrVkxeXl46evSo9dghISE2x+3Ro4eioqJ09+5dSY8/KGjQoIHy5Mkjd3d3denSRdevX9edO3es4967d081atRQ8+bNNXPmTOu5HzlyRPfv31eDBg1sjrFo0aIE5/Z0nZI0cOBA/fe//1X9+vU1YcKEJK+FJA0fPlzR0dHW17PL7wEAAAAgJZgRfwHdunVT3759JUmffPJJon3s7OwS3Lf96NGjv7y2Z8XHxyt37tyJztg/7yFwefLkUefOndW5c2eNGzdO/v7++vTTT21mh5/+QODZtvj4eI0ZM0YtW7ZM0MfJyUnnzp1TUFCQevXqpbFjxypr1qzatm2bunfvbnOtHB0dVb9+fX3//fcaMmSI8ubNax1fkr7//nvlyZPHZvwns/9PuLq62myPHj1aHTp00Pfff68ffvhBo0aN0tKlS9WiRYsEtTo6OiYYDwAAAABSiyD+Aho1aqSHDx9Kkho2bJhonxw5ctjMHsfExOjMmTNJjvnkIWiJzWo/a9euXQm2ixQpokyZMiXoW65cOV25ckX29vby9fV97thJyZIli3Lnzm0zUx0bG6u9e/eqUqVKkqTjx4/r1q1b1uXe5cqV0/Hjx+Xn55fomHv37lVsbKymTJkiO7vHizSWL1+eoJ+dnZ0+//xzdejQQXXr1lVERIR8fHxUokQJOTo66vz58zbL0FPK399f/v7+euedd9S+fXuFhoYmGsQBAAAAID0QxF9ApkyZrMuvEwu/klS3bl2FhYWpSZMmypIliz744IMk+0pSzpw55ezsrHXr1ilv3rxycnKSp6dnon0vXLiggQMH6s0339T+/fs1a9YsTZkyJdG+9evXV9WqVdW8eXNNnDhRRYsW1eXLl7V27Vo1b948wZJtSZo3b54iIyPVokULFS5cWPfv39eiRYv066+/atasWdZ+Dg4O6tevn2bOnCkHBwf17dtXVapUsQbzkSNHqnHjxsqXL59at24tOzs7/fLLLzp06JDGjRunwoULKzY2VrNmzVKTJk20fft2ffrpp0le88WLF6t9+/bWMO7t7a3BgwfrnXfeUXx8vGrUqKGYmBjt2LFDbm5u1nvTn3Xv3j0NGTJErVq1UsGCBXXx4kXt2bNHr7/+epK/HwAAAAB4Udwj/oI8PDxsHlz2rOHDh6tmzZpq3LixgoKC1Lx5cxUuXDjJ/vb29po5c6bmzZsnHx8fNWvWLMm+Xbp00b1791SpUiW99dZb6tevX6IPXZMeLxNfu3atatasqW7dusnf31/t2rXT2bNn9f/au/Owquv8//+PI7IIsriAiKG4gPuC4oJNoqaBo5Ufa9RiVNSP5binXprjpPhp3PqMTnmZNmMF+hlHvAr0suzjmmi5ksiIijtufWDIXXNLeP3+6Mf5SiAhyfsg3W/Xda6L836/3u/36/U8p2OP91qrVq0il+nQoYNu3rypkSNHqnnz5oqIiNCePXu0du3aAkee3d3dNXXqVL366qsKDw9XlSpVlJCQYJ8fGRmpzz//XJs3b1b79u3VqVMnLVy4UPXq1ZP04+PcFi5cqPnz56tFixZauXKl5s6dW2yNVq1apebNm6t79+7KycnR22+/rRkzZmju3Llq2rSpIiMj9dlnn9kfB1cUJycnXbp0SYMHD1ZISIj69++vXr16cUM2AAAAAGXKZop78DTKra5du6pNmzaFnlFutfj4eE2YMEFXr151aD8c4fr16/L29ta1a9eK3RmD8u343EklahcyreizTQAAAIBHzQYcEQcAAAAAwEIEcQAAAAAALMTN2p5QRT2GzBFiYmIUExPj6G4AAAAAwBODI+IAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWIggDgAAAACAhQjiAAAAAABYiCAOAAAAAICFCOIAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWIggDgAAAACAhQjiAAAAAABYiCAOAAAAAICFCOIAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWKiyozsAAI4UMm2Bo7sAAACAXxmOiAMAAAAAYCGCOAAAAAAAFiKIAwAAAABgIYI4AAAAAAAWIogDAAAAAGAhgjgAAAAAABYiiAMAAAAAYCGCOAAAAAAAFiKIAwAAAABgIYI4AAAAAAAWIogDAAAAAGChyo7uAIDHY8fglx3dhQqty4pPHd0FAAAAVBAcEQcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHAAAAAMBCBHEAAAAAACxEEAcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHAAAAAMBCBHEAAAAAACxEEAcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHAAAAAMBCBHEAAAAAACxEEAcAAAAAwEIEcQAAAAAALEQQdwCbzaa1a9c6uhvlUteuXTVhwgRHdwMAAAAAykyFDOLnz5/X8OHDFRAQIBcXF9WrV0/jx4/XpUuXLO1HbGys2rRpU2h6VlaWevXqZWlfHpScnCybzWZ/+fr6qlevXvrXv/712LcVExMjm82mkSNHFpo3atQo2Ww2xcTE2KclJSXp7bfffqx9iI+Pl4+Pz2NdJwAAAACUVoUL4qdPn1ZYWJiOHz+uVatW6eTJk/rggw+0detWhYeH6/Lly47uovz9/eXq6urobujYsWPKysrS+vXrdeXKFUVFRenatWulWte9e/ceOi8wMFAJCQm6ffu2fdqdO3e0atUq1a1bt0Db6tWry9PTs1R9AAAAAIAnQYUL4qNHj5aLi4s2bdqkiIgI1a1bV7169dKWLVv07bffavr06fa2RZ0i7uPjo/j4ePv7b7/9VgMGDFC1atVUo0YNvfjiizpz5ox9fnJysjp06CAPDw/5+Pjo6aef1tmzZxUfH69Zs2bpX//6l/3Ic/56f7rd9PR0de/eXVWqVFGNGjX02muv6ebNm/b5MTEx6tu3r/7yl7+odu3aqlGjhkaPHq0ffvjB3mbJkiUKDg6Wm5ubatWqpZdffvlna+Xn5yd/f3916NBBCxYsUHZ2tvbs2SNJ2rVrl7p06aIqVaooMDBQ48aN0/fff29fNigoSH/+858VExMjb29vjRgx4qHbadu2rerWraukpCT7tKSkJAUGBio0NLRA25+emh4UFKQ5c+Zo2LBh8vT0VN26dfX3v/+9QP1tNpuuXr1qn5aWliabzaYzZ84oOTlZQ4cO1bVr1+yfQ2xsrKQfdx5MmTJFderUkYeHhzp27Kjk5OSHjuPu3bu6fv16gRcAAAAAPKoKFcQvX76sjRs3atSoUapSpUqBef7+/oqOjtbq1atljCnR+m7duqVu3bqpatWq2rFjh77++mtVrVpVUVFRunfvnu7fv6++ffsqIiJCBw8e1O7du/Xaa6/JZrNpwIABmjRpkpo3b66srCxlZWVpwIABRW4jKipK1apVU0pKij755BNt2bJFY8aMKdBu27ZtOnXqlLZt26bly5crPj7eHuy/+eYbjRs3Tv/1X/+lY8eOacOGDerSpcsj1S6/Xj/88IPS09MVGRmpfv366eDBg1q9erW+/vrrQn367//+b7Vo0UL79+/XW2+9Vez6hw4dqri4OPv7jz/+WMOGDStR3xYsWKCwsDAdOHBAo0aN0h/+8AcdPXq0RMt27txZ7777rry8vOyfw+TJk+192rlzpxISEnTw4EH97ne/U1RUlE6cOFHkuubOnStvb2/7KzAwsER9AAAAAIAHVXZ0Bx6nEydOyBijpk2bFjm/adOmunLlir777jv5+fn97PoSEhJUqVIlffjhh7LZbJKkuLg4+fj4KDk5WWFhYbp27Zr69Omjhg0b2reRr2rVqqpcubL8/f0fuo2VK1fq9u3bWrFihTw8PCRJixcv1vPPP6/58+erVq1akqRq1app8eLFcnJyUpMmTdS7d29t3bpVI0aM0Llz5+Th4aE+ffrI09NT9erVK3SkuTiXLl3SrFmz5OnpqQ4dOmjy5Ml69dVX7Uemg4ODtWjRIkVERGjp0qVyc3OTJHXv3t0ean/OoEGDNG3aNJ05c0Y2m80egIs7Ap3vt7/9rUaNGiVJmjp1qv76178qOTlZTZo0+dllXVxc5O3tLZvNVuBzOHXqlFatWqULFy4oICBAkjR58mRt2LBBcXFxmjNnTqF1TZs2TRMnTrS/v379OmEcAAAAwCOrUEH85+QfCXdxcSlR+/379+vkyZOFrlm+c+eOTp06peeee04xMTGKjIxUz5491aNHD/Xv31+1a9cucZ8yMjLUunVrewiXpKefflp5eXk6duyYPYg3b95cTk5O9ja1a9dWenq6JKlnz56qV6+eGjRooKioKEVFRek//uM/5O7uXuy2n3rqKUnS999/r+DgYH3yySfy8/Ozj3vlypX2tsYY5eXlKTMz076zISwsrMTjrFmzpnr37q3ly5fLGKPevXurZs2aJVq2VatW9r/zA3VOTk6Jt12U1NRUGWMUEhJSYPrdu3dVo0aNIpdxdXUtF9f2AwAAAHiyVagg3qhRI9lsNh05ckR9+/YtNP/o0aPy9fW130HbZrMVOk39weuu8/Ly1K5duwKBNJ+vr6+kH4+Qjxs3Ths2bNDq1av1pz/9SZs3b1anTp1K1GdjjP1o+089ON3Z2bnQvLy8PEmSp6enUlNTlZycrE2bNmnGjBmKjY1VSkpKsXcL/+qrr+Tl5SVfX195eXkVGPfrr7+ucePGFVrmwZurPbjzoCSGDRtmP739/fffL/FyxY29UqUfr6548HN88DN8mLy8PDk5OWn//v0FdnBIP57JAAAAAABlpUIF8Ro1aqhnz55asmSJ3njjjQLXiWdnZ2vlypUaPXq0fZqvr6+ysrLs70+cOKFbt27Z37dt21arV6+Wn59fgaD6U6GhoQoNDdW0adMUHh6uf/7zn+rUqZNcXFyUm5tbbJ+bNWum5cuX6/vvv7cH2507d6pSpUqFjtYWp3LlyurRo4d69OihmTNnysfHR19++aX69ev30GXq169fZFBv27atDh8+rEaNGpV4+yWRf229JEVGRj6WdebvEMnKylK1atUk/XiztgcV9TmEhoYqNzdXOTk5euaZZx5LXwAAAACgJCrUzdqkH6+vvnv3riIjI7Vjxw6dP39eGzZsUM+ePRUSEqIZM2bY23bv3l2LFy9WamqqvvnmG40cObLA0dfo6GjVrFlTL774or766itlZmZq+/btGj9+vC5cuKDMzExNmzZNu3fv1tmzZ7Vp0yYdP37cfup2UFCQMjMzlZaWposXL+ru3buF+hsdHS03NzcNGTJEhw4d0rZt2zR27FgNGjTIflr6z/n888+1aNEipaWl6ezZs1qxYoXy8vLUuHHjUtVw6tSp2r17t0aPHq20tDSdOHFC69at09ixY0u1vnxOTk7KyMhQRkZGoaPQpdWoUSMFBgYqNjZWx48f1/r167VgwYICbYKCgnTz5k1t3bpVFy9e1K1btxQSEqLo6GgNHjxYSUlJyszMVEpKiubPn68vvvjisfQNAAAAAIpS4YJ4cHCwUlJS1KBBA/Xv31/16tVTr169FBISop07dxY47XjBggUKDAxUly5d9Oqrr2ry5MkFrqt2d3fXjh07VLduXfXr109NmzbVsGHDdPv2bXl5ecnd3V1Hjx7VSy+9pJCQEL322msaM2aMXn/9dUnSSy+9pKioKHXr1k2+vr5atWpVof66u7tr48aNunz5stq3b6+XX35Zzz77rBYvXlziMfv4+CgpKUndu3dX06ZN9cEHH2jVqlVq3rx5qWrYqlUrbd++XSdOnNAzzzyj0NBQvfXWW4907fvDeHl5FXt2waNydnbWqlWrdPToUbVu3Vrz58/Xn//85wJtOnfurJEjR2rAgAHy9fXVO++8I+nHywoGDx6sSZMmqXHjxnrhhRe0d+9ebsAGAAAAoEzZTEmf5fUEmzlzphYuXKhNmzYpPDzc0d1BBXH9+nV5e3vr2rVrj3XnQmntGPzzz45H6XVZ8amjuwAAAIBy6lGzQYW6RvxhZs2apaCgIO3du1cdO3a03+ALAAAAAACr/SqCuCQNHTrU0V0AAAAAAKDiXSMOAAAAAEB5RhAHAAAAAMBCBHEAAAAAACxEEAcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHAAAAAMBCBHEAAAAAACxEEAcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHAAAAAMBCBHEAAAAAACxU2dEdAPB4dFnxqaO7AAAAAKAEOCIOAAAAAICFCOIAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWIibtQGlZIyRJF2/ft3BPQEAAADgSPmZID8j/ByCOFBKN27ckCQFBgY6uCcAAAAAyoMbN27I29v7Z9vZTEkjO4AC8vLy9H//93/y9PSUzWZzSB+uX7+uwMBAnT9/Xl5eXg7pw68BdbYOtbYGdbYOtbYGdbYOtbYGdbbO46q1MUY3btxQQECAKlX6+SvAOSIOlFKlSpX01FNPObobkiQvLy9+pC1Ana1Dra1Bna1Dra1Bna1Dra1Bna3zOGpdkiPh+bhZGwAAAAAAFiKIAwAAAABgIYI48ARzdXXVzJkz5erq6uiuVGjU2TrU2hrU2TrU2hrU2TrU2hrU2TqOqjU3awMAAAAAwEIcEQcAAAAAwEIEcQAAAAAALEQQBwAAAADAQgRxAAAAAAAsRBAHyokrV65o0KBB8vb2lre3twYNGqSrV68Wu4wxRrGxsQoICFCVKlXUtWtXHT58uECbu3fvauzYsapZs6Y8PDz0wgsv6MKFCwXazJ49W507d5a7u7t8fHwe88gcb8mSJapfv77c3NzUrl07ffXVV8W23759u9q1ayc3Nzc1aNBAH3zwQaE2iYmJatasmVxdXdWsWTOtWbPmF2+3InBErXfs2KHnn39eAQEBstlsWrt27eMcUrnkiDrPnTtX7du3l6enp/z8/NS3b18dO3bssY6rPHJErZcuXapWrVrJy8tLXl5eCg8P1//+7/8+1nGVN476nc43d+5c2Ww2TZgw4ZcOpdxzRK1jY2Nls9kKvPz9/R/ruMobR32nv/32W/3+979XjRo15O7urjZt2mj//v2PbVzlkSNqHRQUVOg7bbPZNHr06JJ33AAoF6KiokyLFi3Mrl27zK5du0yLFi1Mnz59il1m3rx5xtPT0yQmJpr09HQzYMAAU7t2bXP9+nV7m5EjR5o6deqYzZs3m9TUVNOtWzfTunVrc//+fXubGTNmmIULF5qJEycab2/vshqiQyQkJBhnZ2ezbNkyc+TIETN+/Hjj4eFhzp49W2T706dPG3d3dzN+/Hhz5MgRs2zZMuPs7Gw+/fRTe5tdu3YZJycnM2fOHJORkWHmzJljKleubPbs2VPq7VYEjqr1F198YaZPn24SExONJLNmzZqyHqpDOarOkZGRJi4uzhw6dMikpaWZ3r17m7p165qbN2+W+ZgdxVG1XrdunVm/fr05duyYOXbsmPnjH/9onJ2dzaFDh8p8zI7gqDrn27dvnwkKCjKtWrUy48ePL6thlguOqvXMmTNN8+bNTVZWlv2Vk5NT5uN1FEfV+fLly6ZevXomJibG7N2712RmZpotW7aYkydPlvmYHcVRtc7JySnwfd68ebORZLZt21bivhPEgXLgyJEjRlKB/8B3795tJJmjR48WuUxeXp7x9/c38+bNs0+7c+eO8fb2Nh988IExxpirV68aZ2dnk5CQYG/z7bffmkqVKpkNGzYUWmdcXFyFC+IdOnQwI0eOLDCtSZMm5s033yyy/ZQpU0yTJk0KTHv99ddNp06d7O/79+9voqKiCrSJjIw0AwcOLPV2KwJH1fpBv4YgXh7qbMyP/xMiyWzfvv1Rh/DEKC+1NsaYatWqmQ8//PBRuv/EcGSdb9y4YYKDg83mzZtNREREhQ/ijqr1zJkzTevWrX9h758cjqrz1KlTzW9+85tf2v0nSnn5nR4/frxp2LChycvLK3HfOTUdKAd2794tb29vdezY0T6tU6dO8vb21q5du4pcJjMzU9nZ2Xruuefs01xdXRUREWFfZv/+/frhhx8KtAkICFCLFi0eut6K5N69e9q/f3+B8UvSc88999Dx7969u1D7yMhIffPNN/rhhx+KbZO/ztJs90nnqFr/2pSnOl+7dk2SVL169Ucex5OgvNQ6NzdXCQkJ+v777xUeHl7a4ZRbjq7z6NGj1bt3b/Xo0eOXDqXcc3StT5w4oYCAANWvX18DBw7U6dOnf+mQyiVH1nndunUKCwvT7373O/n5+Sk0NFTLli17HMMqlxz9nX6wH//4xz80bNgw2Wy2EvefIA6UA9nZ2fLz8ys03c/PT9nZ2Q9dRpJq1apVYHqtWrXs87Kzs+Xi4qJq1ao9tE1FdvHiReXm5hZbo5/Kzs4usv39+/d18eLFYtvkr7M0233SOarWvzblpc7GGE2cOFG/+c1v1KJFi9IOp1xzdK3T09NVtWpVubq6auTIkVqzZo2aNWv2S4dV7jiyzgkJCUpNTdXcuXMfx1DKPUfWumPHjlqxYoU2btyoZcuWKTs7W507d9alS5cex9DKFUfW+fTp01q6dKmCg4O1ceNGjRw5UuPGjdOKFSsex9DKHUf/Tudbu3atrl69qpiYmEfqf+VHag3gkcTGxmrWrFnFtklJSZGkIvegGWN+ds/aT+eXZJmStKlIHrVGRbX/6fSSrLM0n82TzlG1/rVxdJ3HjBmjgwcP6uuvv36kfj+JHFXrxo0bKy0tTVevXlViYqKGDBmi7du3V8gwLllf5/Pnz2v8+PHatGmT3NzcflHfnzSO+E736tXL/nfLli0VHh6uhg0bavny5Zo4ceKjD+IJ4Ig65+XlKSwsTHPmzJEkhYaG6vDhw1q6dKkGDx5cuoE8ARz9b+JHH32kXr16KSAg4JH6TRAHytCYMWM0cODAYtsEBQXp4MGD+ve//11o3nfffVdoj1y+/LuNZmdnq3bt2vbpOTk59mX8/f117949XblypcBR8ZycHHXu3PmRx/OkqVmzppycnArtwXywRj/l7+9fZPvKlSurRo0axbbJX2dptvukc1Stf23KQ53Hjh2rdevWaceOHXrqqad+yXDKNUfX2sXFRY0aNZIkhYWFKSUlRe+9957+9re//aJxlTeOqvP+/fuVk5Ojdu3a2efn5uZqx44dWrx4se7evSsnJ6dfPL7yxNHf6Qd5eHioZcuWOnHiRGmGUq45ss61a9cutLOuadOmSkxMLPV4yrPy8J0+e/astmzZoqSkpEfuP6emA2WoZs2aatKkSbEvNzc3hYeH69q1a9q3b5992b179+ratWsPDcz169eXv7+/Nm/ebJ927949bd++3b5Mu3bt5OzsXKBNVlaWDh069KsI4i4uLmrXrl2B8UvS5s2bHzr+8PDwQu03bdqksLAwOTs7F9smf52l2e6TzlG1/rVxZJ2NMRozZoySkpL05Zdfqn79+o9jSOVWeftOG2N09+7dRx1GueeoOj/77LNKT09XWlqa/RUWFqbo6GilpaVVuBAula/v9N27d5WRkVHgQEJF4cg6P/3004UeK3n8+HHVq1ev1OMpz8rDdzouLk5+fn7q3bv3ow+gxLd1A1CmoqKiTKtWrczu3bvN7t27TcuWLQs9vqxx48YmKSnJ/n7evHnG29vbJCUlmfT0dPPKK68U+fiyp556ymzZssWkpqaa7t27F3p82dmzZ82BAwfMrFmzTNWqVc2BAwfMgQMHzI0bN8p+4GUs/7EWH330kTly5IiZMGGC8fDwMGfOnDHGGPPmm2+aQYMG2dvnP9bijTfeMEeOHDEfffRRocda7Ny50zg5OZl58+aZjIwMM2/evIc+vuxh262IHFXrGzdu2L+zkszChQvNgQMHKuyj4hxV5z/84Q/G29vbJCcnF3hky61bt6wbvMUcVetp06aZHTt2mMzMTHPw4EHzxz/+0VSqVMls2rTJusFbyFF1/qlfw13THVXrSZMmmeTkZHP69GmzZ88e06dPH+Pp6Vlh/010VJ337dtnKleubGbPnm1OnDhhVq5cadzd3c0//vEP6wZvMUf+fuTm5pq6deuaqVOnlqrvBHGgnLh06ZKJjo42np6extPT00RHR5srV64UaCPJxMXF2d/n5eWZmTNnGn9/f+Pq6mq6dOli0tPTCyxz+/ZtM2bMGFO9enVTpUoV06dPH3Pu3LkCbYYMGWIkFXo9yrMQy7P333/f1KtXz7i4uJi2bdsWeNzSkCFDTERERIH2ycnJJjQ01Li4uJigoCCzdOnSQuv85JNPTOPGjY2zs7Np0qSJSUxMfKTtVlSOqPW2bduK/P4OGTKkLIZYLjiizkXV+Ke/SRWRI2o9bNgw+zZ9fX3Ns88+W2FDeD5H/U4/6NcQxI1xTK0HDBhgateubZydnU1AQIDp16+fOXz4cJmMr7xw1Hf6s88+My1atDCurq6mSZMm5u9///tjH1t546hab9y40Ugyx44dK1W/bcb8/1enAwAAAACAMsc14gAAAAAAWIggDgAAAACAhQjiAAAAAABYiCAOAAAAAICFCOIAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWIggDgAAAACAhQjiAACgQsjOzlbPnj3l4eEhHx+fh06z2Wxau3ZtidYZGxurNm3alEl/rfCk9x8AKiqCOAAAKFPZ2dkaO3asGjRoIFdXVwUGBur555/X1q1bH+t2/vrXvyorK0tpaWk6fvz4Q6dlZWWpV69eJVrn5MmTH3s/4+Pj7TsFHmbBggXy9vbWrVu3Cs27c+eOfHx8tHDhwsfaLwCAdQjiAACgzJw5c0bt2rXTl19+qXfeeUfp6enasGGDunXrptGjRz/WbZ06dUrt2rVTcHCw/Pz8HjrN399frq6uJVpn1apVVaNGjcfaz5IYPHiwbt++rcTExELzEhMTdevWLQ0aNMjyfgEAHg+COAAAKDOjRo2SzWbTvn379PLLLyskJETNmzfXxIkTtWfPHnu7c+fO6cUXX1TVqlXl5eWl/v3769///neBdX322Wdq166d3Nzc1KBBA82aNUv379+XJAUFBSkxMVErVqyQzWZTTExMkdOkwqemX7hwQQMHDlT16tXl4eGhsLAw7d27V1LRp3bHxcWpadOmcnNzU5MmTbRkyRL7vDNnzshmsykpKUndunWTu7u7Wrdurd27d0uSkpOTNXToUF27dk02m002m02xsbGF6ubr66vnn39eH3/8caF5H3/8sV544QX5+vpq6tSpCgkJkbu7uxo0aKC33npLP/zww0M/j65du2rChAkFpvXt29deG0m6d++epkyZojp16sjDw0MdO3ZUcnLyQ9cJAHh0lR3dAQAAUDFdvnxZGzZs0OzZs+Xh4VFofv7p2cYY9e3bVx4eHtq+fbvu37+vUaNGacCAAfYAuHHjRv3+97/XokWL9Mwzz+jUqVN67bXXJEkzZ85USkqKBg8eLC8vL7333nuqUqWK7t27V2jaT928eVMRERGqU6eO1q1bJ39/f6WmpiovL6/IMS1btkwzZ87U4sWLFRoaqgMHDmjEiBHy8PDQkCFD7O2mT5+uv/zlLwoODtb06dP1yiuv6OTJk+rcubPeffddzZgxQ8eOHZP041H3ogwfPlx9+vRRZmam6tevL+nHoL9t2zatX79ekuTp6an4+HgFBAQoPT1dI0aMkKenp6ZMmVKCT6hoQ4cO1ZkzZ5SQkKCAgACtWbNGUVFRSk9PV3BwcKnXCwD4fwjiAACgTJw8eVLGGDVp0qTYdlu2bNHBgweVmZmpwMBASdL//M//qHnz5kpJSVH79u01e/Zsvfnmm/aw26BBA7399tuaMmWKZs6cKV9fX7m6uqpKlSry9/e3r7uoaQ/65z//qe+++04pKSmqXr26JKlRo0YP7evbb7+tBQsWqF+/fpKk+vXr68iRI/rb3/5WIIhPnjxZvXv3liTNmjVLzZs318mTJ9WkSRN5e3vLZrM9tE/5IiMjFRAQoPj4eM2aNUvSj0fjAwIC9Nxzz0mS/vSnP9nbBwUFadKkSVq9enWpg/ipU6e0atUqXbhwQQEBAfaxbNiwQXFxcZozZ06p1gsAKIggDgAAyoQxRtKPp4IXJyMjQ4GBgfYQLknNmjWTj4+PMjIy1L59e+3fv18pKSmaPXu2vU1ubq7u3LmjW7duyd3dvVR9TEtLU2hoqD2EF+e7777T+fPnNXz4cI0YMcI+/f79+/L29i7QtlWrVva/a9euLUnKycn52Z0SD3JyctKQIUMUHx+vmTNnymazafny5YqJiZGTk5Mk6dNPP9W7776rkydP6ubNm7p//768vLxKvI2fSk1NlTFGISEhBabfvXvXIdfKA0BFRRAHAABlIjg4WDabTRkZGerbt+9D2xljigzrD07Py8vTrFmz7EeiH+Tm5lbqPhZ1uvrD5J+uvmzZMnXs2LHAvPxgnM/Z2dn+94NjeFTDhg3T3Llz9eWXX0r68Vr6oUOHSpL27NmjgQMHatasWYqMjJS3t7cSEhK0YMGCh66vUqVK9h0k+R68pjwvL09OTk7av39/oTE97BR6AMCjI4gDAIAyUb16dUVGRur999/XuHHjCl0nfvXqVfn4+KhZs2Y6d+6czp8/bz8qfuTIEV27dk1NmzaVJLVt21bHjh0r9rTx0mjVqpU+/PBDXb58+WePiteqVUt16tTR6dOnFR0dXepturi4KDc3t0RtGzZsqIiICMXFxckYo65du6phw4aSpJ07d6pevXqaPn26vf3Zs2eLXZ+vr6+ysrLs73Nzc3Xo0CF169ZNkhQaGqrc3Fzl5OTomWeeedShAQBKiLumAwCAMrNkyRLl5uaqQ4cOSkxM1IkTJ5SRkaFFixYpPDxcktSjRw+1atVK0dHRSk1N1b59+zR48GBFREQoLCxMkjRjxgytWLFCsbGxOnz4sDIyMrR69eoC10iXxiuvvCJ/f3/17dtXO3fu1OnTp5WYmGi/y/lPxcbGau7cuXrvvfd0/PhxpaenKy4u7pGe6R0UFKSbN29q69atunjxYpHPCn/Q8OHDlZSUpDVr1mj48OH26Y0aNdK5c+eUkJCgU6dOadGiRVqzZk2x6+revbvWr1+v9evX6+jRoxo1apSuXr1qnx8SEqLo6GgNHjxYSUlJyszMVEpKiubPn68vvviixGMEABSPIA4AAMpM/fr1lZqaqm7dumnSpElq0aKFevbsqa1bt2rp0qWS/t/jxKpVq6YuXbqoR48eatCggVavXm1fT2RkpD7//HNt3rxZ7du3V6dOnbRw4ULVq1fvF/XPxcVFmzZtkp+fn37729+qZcuWmjdvXqHTsvP953/+pz788EPFx8erZcuWioiIUHx8vP2u5iXRuXNnjRw5UgMGDJCvr6/eeeedYtu/9NJLcnV1laura4FT81988UW98cYbGjNmjNq0aaNdu3bprbfeKnZdw4YN05AhQ+w7OurXr28/Gp4vLi5OgwcP1qRJk9S4cWO98MIL2rt3b4Fr+AEAv4zN/PRCIQAAAAAAUGY4Ig4AAAAAgIUI4gAAAAAAWIggDgAAAACAhQjiAAAAAABYiCAOAAAAAICFCOIAAAAAAFiIIA4AAAAAgIUI4gAAAAAAWIggDgAAAACAhQjiAAAAAABYiCAOAAAAAICF/j9Qvg6BDDXZVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "name_mapping = {\n",
    "    'laughs_per_minute': 'Laughs Per Minute',\n",
    "    'ted_mainstage': 'TED Mainstage',\n",
    "    'num_question_marks': '# of Question Marks',\n",
    "    'comments': '# of Website Comments',\n",
    "    'word_count': 'Total Words Spoken',\n",
    "    'duration': 'Duration of Talk',\n",
    "    'num_laughs': '# of Laughs',\n",
    "    'words_per_minute': 'Talking Speed',\n",
    "    'multiple_speakers': 'Multiple Speakers',\n",
    "    'questions_per_minute': 'Questions Per Minute'\n",
    "}\n",
    "\n",
    "# Assuming 'coefficients_reset' is your DataFrame from before\n",
    "# Rename the columns based on your mapping\n",
    "coefficients_reset['Feature'] = coefficients_reset['Feature'].map(name_mapping).fillna(coefficients_reset['Feature'])\n",
    "\n",
    "# Now create the bar plot with updated feature names\n",
    "plt.figure(figsize=(10, 8))  # Set figure size for better visibility\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefficients_reset, palette='coolwarm')\n",
    "plt.title('Linear Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee2f25",
   "metadata": {},
   "source": [
    "# LogReg Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "703a189f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Determining the top 20 coefficient words for positive reviews\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This code was adapted from BrainStation's Text Data lecture notebook\u001b[39;00m\n\u001b[1;32m      3\u001b[0m word_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m----> 4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefficients\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mlogreg\u001b[49m\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]},\n\u001b[1;32m      5\u001b[0m     index\u001b[38;5;241m=\u001b[39mbagofwords_transcript\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[1;32m      6\u001b[0m )\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefficients\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m word_counts\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m), legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe top 10 positive model coefficients indicating higher ratings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "# Determining the top 20 coefficient words for positive reviews\n",
    "# This code was adapted from BrainStation's Text Data lecture notebook\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"coefficients\": logreg.coef_[0]},\n",
    "    index=bagofwords_transcript.get_feature_names_out()\n",
    ").sort_values(\"coefficients\", ascending=False)\n",
    "\n",
    "word_counts.head(10).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "plt.title(\"The top 10 positive model coefficients indicating higher ratings\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66109dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the top 20 coefficient words for positive reviews\n",
    "# This code was adapted from BrainStation's Text Data lecture notebook\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"coefficients\": logreg.coef_[0]},\n",
    "    index=bagofwords_transcript.get_feature_names_out()\n",
    ").sort_values(\"coefficients\", ascending=True)\n",
    "\n",
    "word_counts.head(10).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "plt.title(\"The top 10 negative model coefficients indicating higher ratings\")\n",
    "plt.ylabel(\"Coefficients\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f15c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd43952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b6030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60254091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix_train_df = pd.DataFrame(data=sparse_matrix_train.toarray(), columns=bagofwords_transcript.get_feature_names_out(), index=X_train.index)\n",
    "sparse_matrix_test_df = pd.DataFrame(data=sparse_matrix_test.toarray(), columns=bagofwords_transcript.get_feature_names_out(), index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3a268",
   "metadata": {},
   "source": [
    "#### Addressing 'object' columns - changing them into numerical values, or dropping them altogether.\n",
    "\n",
    "- all_speakers      3331 non-null   object **DROPPED**\n",
    "- occupations       3331 non-null   object **ready for dummy variables**\n",
    "- about_speakers    3331 non-null   object **ready for vectorization**\n",
    "- native_lang       3331 non-null   object **DROPPED**\n",
    "- available_lang    3331 non-null   object **Create dummies?**\n",
    "- comments          3331 non-null   float64 **Ready for analysis**\n",
    "- topics            3331 non-null   object **Create dummies?**\n",
    "- related_talks     3331 non-null   object **CountVectorize?**\n",
    "- url               3331 non-null   object **Dropped**\n",
    "- description       3331 non-null   object **CountVectorize?**\n",
    "- transcript        3331 non-null   object **CountVectorize?**\n",
    "- title             3331 non-null   object **Dummy OR CountVectorize**?\n",
    "- speaker           3331 non-null   object **Dummy OR CountVectorize**?\n",
    "- recorded_date     3331 non-null   object **Changed to DateTime**\n",
    "- published_date    3331 non-null   object **Changed to DateTime**\n",
    "####  - event             3331 non-null   object **Ready for Dummies**\n",
    "\n",
    "#### Additional Columns Created:\n",
    "- published_year **ready for dummy variables**\n",
    "- published_month **ready for dummy variables**\n",
    "- recorded_year **ready for dummy variables**\n",
    "- recorded_month **ready for dummy variables**\n",
    "- percent_likes\n",
    "- ted_mainstage \n",
    "- multiple_speakers \n",
    "- word_count\n",
    "- words_minute\n",
    "- transformed_occupations **ready for dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc5bec",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "Create dummy variables where possible.\n",
    "- event  **Ready for Dummies**\n",
    "- published_year **ready for dummy variables**\n",
    "- published_month **ready for dummy variables**\n",
    "- recorded_year **ready for dummy variables**\n",
    "- recorded_month **ready for dummy variables**\n",
    "- transformed_occupations **ready for dummy variables**\n",
    "\n",
    "\n",
    "Scale my dependent variable of \"percent-likes\"\n",
    "scale other non-dummy-variable columns\n",
    "- comments\n",
    "- views\n",
    "- duration\n",
    "- word_count\n",
    "- words_minute\n",
    "\n",
    "Drop the \"likes\" column, as it will correlate too strongly with 'percent_likes'.\n",
    "\n",
    "\n",
    "\n",
    "For Future Consideration:\n",
    "- available_lang    3331 non-null   object **Create dummies?** *temporarily drop*\n",
    "- topics            3331 non-null   object **Create dummies?**\n",
    "- related_talks     3331 non-null   object **CountVectorize?**\n",
    "- description       3331 non-null   object **CountVectorize?**\n",
    "- transcript        3331 non-null   object **CountVectorize?**\n",
    "- title             3331 non-null   object **Dummy OR CountVectorize**?\n",
    "- speaker           3331 non-null   object **Dummy OR CountVectorize**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93473634",
   "metadata": {},
   "source": [
    "## Creating Dummy Variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for which to create dummy variables\n",
    "columns_to_dummify = [\n",
    "    'event',\n",
    "    'published_year',\n",
    "    'published_month',\n",
    "    'recorded_year',\n",
    "    'recorded_month',\n",
    "    'transformed_occupations'\n",
    "]\n",
    "\n",
    "# Creating dummy variables\n",
    "for column in columns_to_dummify:\n",
    "    dummies = pd.get_dummies(merged_cleaved_df[column], prefix=column)\n",
    "    merged_cleaved_df = pd.concat([merged_cleaved_df, dummies], axis=1)\n",
    "    merged_cleaved_df.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cleaved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f421c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the \"likes\" column\n",
    "merged_cleaved_df.drop([\"likes\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b29c9",
   "metadata": {},
   "source": [
    "# Creating a Temporary EDA DataFrame for only the numerical values that we have thus far:\n",
    "\n",
    "This means dropping the following columns:\n",
    "    'talk_id',\n",
    "    'occupations',\n",
    "    'about_speakers',\n",
    "    'available_lang',\n",
    "    'topics',\n",
    "    'related_talks',\n",
    "    'description',\n",
    "    'transcript',\n",
    "    'title',\n",
    "    'speaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    'talk_id',\n",
    "    'occupations',\n",
    "    'about_speakers',\n",
    "    'available_lang',\n",
    "    'topics',\n",
    "    'related_talks',\n",
    "    'description',\n",
    "    'transcript',\n",
    "    'title',\n",
    "    'speaker',\n",
    "    'published_date',\n",
    "    'recorded_date'\n",
    "]\n",
    "\n",
    "# Creating a new DataFrame by dropping specified columns\n",
    "numeric_temp_df = merged_cleaved_df.drop(columns=columns_to_drop)\n",
    "numeric_temp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27086d00",
   "metadata": {},
   "source": [
    "We now have a temporary dataframe called \"numeric_temp_df\" with which we can run a linear regression against our dependent variable \"percent_likes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329edee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named numeric_temp_df and 'percent_likes' is your target variable\n",
    "X = numeric_temp_df.drop('percent_likes', axis=1)  # Features (all columns except 'percent_likes')\n",
    "y = numeric_temp_df['percent_likes']  # Target variable\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data (do not fit the scaler again!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "\n",
    "# Fit the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Now you can use model.predict(X_test_scaled) to make predictions on your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Accuracy Scores\n",
    "# Predict on training and testing data\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate R² score for training and testing sets\n",
    "r2_score_train = r2_score(y_train, y_train_pred)\n",
    "r2_score_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"R² score for training set:\", r2_score_train)\n",
    "print(\"R² score for testing set:\", r2_score_test)\n",
    "\n",
    "# 2. Identify Top 50 Positive and Negative Coefficients\n",
    "# Get the coefficients from the model and create a Series with column names\n",
    "coefficients = pd.Series(model.coef_, index=X.columns)\n",
    "\n",
    "# Sort the coefficients\n",
    "sorted_coefficients = coefficients.sort_values()\n",
    "\n",
    "# Top 50 negative coefficients\n",
    "top_50_negative = sorted_coefficients.head(50)\n",
    "\n",
    "# Top 50 positive coefficients\n",
    "top_50_positive = sorted_coefficients.tail(50).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 50 positive coefficients:\\n\", top_50_positive)\n",
    "print(\"\\nTop 50 negative coefficients:\\n\", top_50_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf7dc0",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "Let's look at the distribution of the column \"percent_likes\" to see if we can determine which talks are \"great\" talks and which ones are not.\n",
    "\n",
    "We will then create a binary variable at this level, and then run a logistic regression against this target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'percent_likes' column\n",
    "percent_likes = numeric_temp_df[['percent_likes']]\n",
    "\n",
    "# Initialize the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the 'percent_likes' column\n",
    "percent_likes_scaled = scaler.fit_transform(percent_likes)\n",
    "\n",
    "# Now, percent_likes_scaled contains the scaled values of the 'percent_likes' column\n",
    "\n",
    "# Plotting the histogram of the scaled 'percent_likes' data\n",
    "plt.hist(percent_likes_scaled, bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Scaled Percent Likes')\n",
    "plt.xlabel('Scaled (Std Scaler) Percent Likes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'percent_likes' column\n",
    "percent_likes = numeric_temp_df[['percent_likes']]\n",
    "\n",
    "# Initialize the Standard Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the 'percent_likes' column\n",
    "percent_likes_scaled = scaler.fit_transform(percent_likes)\n",
    "\n",
    "# Now, percent_likes_scaled contains the scaled values of the 'percent_likes' column\n",
    "\n",
    "# Plotting the histogram of the scaled 'percent_likes' data\n",
    "plt.hist(percent_likes_scaled, bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Scaled Percent Likes')\n",
    "plt.xlabel('Scaled (Min/Max) Percent Likes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'percent_likes' column\n",
    "percent_likes = numeric_temp_df[['percent_likes']]\n",
    "\n",
    "# Initialize the Standard Scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Scale the 'percent_likes' column\n",
    "percent_likes_scaled = scaler.fit_transform(percent_likes)\n",
    "\n",
    "# Now, percent_likes_scaled contains the scaled values of the 'percent_likes' column\n",
    "\n",
    "# Plotting the histogram of the scaled 'percent_likes' data\n",
    "plt.hist(percent_likes_scaled, bins=30, edgecolor='black')\n",
    "plt.title('Histogram of Scaled Percent Likes')\n",
    "plt.xlabel('Scaled (Robust) Percent Likes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSTN_cap_env",
   "language": "python",
   "name": "bstn_cap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
